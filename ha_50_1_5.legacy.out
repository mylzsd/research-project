{'dataset': 'human_activity', 'algorithm': 'ptdqn', 'num_clf': 50, 'num_training': 400000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 3084, 'portion': 0.5, 'sequential': False}
(10299, 562)
reading data takes 1.820 sec
number of labels: 6

Running iteration 1 of 10 fold...
[17, 0, 9, 46, 1, 14, 49, 34]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.979072, 0.979101, 0.979437, 0.979353

    accuracy, precision, recall, f_score
max3: 0.977989, 0.977999, 0.978148, 0.978210

    accuracy, precision, recall, f_score
max1: 0.981553, 0.981537, 0.982407, 0.982253


min loss: 0.005, episode: 296000
max accu: 0.982, episode: 10000

12.54 classifiers used
    accuracy, precision, recall, f_score
mv: 0.989320, 0.989368, 0.989217, 0.989294
wv: 0.988350, 0.988419, 0.988612, 0.988641
fs: 0.983495, 0.983472, 0.984822, 0.984719
rl: 0.981553, 0.981537, 0.982407, 0.982253

0.8850442286947141
0.82, 0.97, 0.94, 0.76, 0.88, 0.97, 0.94, 0.77, 0.87, 0.97, 0.94, 0.77, 0.88, 0.96, 0.94, 0.70, 0.86, 0.97, 0.94, 0.74, 0.88, 0.97, 0.94, 0.81, 0.83, 0.97, 0.93, 0.77, 0.86, 0.97, 0.93, 0.76, 0.84, 0.97, 0.94, 0.73, 0.86, 0.97, 0.93, 0.66, 0.86, 0.97, 0.94, 0.78, 0.88, 0.97, 0.94, 0.74, 0.88, 0.97

0.8860250323694433
0.82, 0.97, 0.93, 0.76, 0.88, 0.97, 0.93, 0.77, 0.87, 0.97, 0.94, 0.77, 0.88, 0.97, 0.94, 0.70, 0.87, 0.97, 0.94, 0.75, 0.87, 0.97, 0.94, 0.81, 0.82, 0.97, 0.93, 0.77, 0.86, 0.97, 0.93, 0.76, 0.85, 0.97, 0.93, 0.74, 0.86, 0.97, 0.93, 0.67, 0.87, 0.97, 0.93, 0.78, 0.89, 0.97, 0.93, 0.75, 0.88, 0.97

0.8826601941747572
0.83, 0.97, 0.93, 0.74, 0.87, 0.97, 0.93, 0.77, 0.88, 0.97, 0.93, 0.78, 0.87, 0.96, 0.93, 0.67, 0.88, 0.97, 0.94, 0.72, 0.86, 0.97, 0.94, 0.82, 0.82, 0.97, 0.94, 0.78, 0.86, 0.97, 0.94, 0.76, 0.85, 0.96, 0.94, 0.71, 0.85, 0.97, 0.93, 0.65, 0.85, 0.96, 0.94, 0.77, 0.86, 0.97, 0.93, 0.73, 0.88, 0.97

0.8884271844660193
0.88, 0.98, 0.95, 0.69, 0.91, 0.98, 0.95, 0.77, 0.87, 0.98, 0.95, 0.76, 0.91, 0.98, 0.95, 0.73, 0.89, 0.97, 0.95, 0.71, 0.90, 0.97, 0.96, 0.70, 0.91, 0.98, 0.95, 0.71, 0.89, 0.98, 0.95, 0.66, 0.88, 0.98, 0.95, 0.69, 0.88, 0.98, 0.95, 0.72, 0.86, 0.98, 0.95, 0.63, 0.86, 0.98, 0.95, 0.76, 0.88, 0.98


Running iteration 2 of 10 fold...
[9, 0, 37, 24, 17, 12, 1, 4, 13, 38, 5, 48, 6, 35, 45, 30]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.979504, 0.979517, 0.979858, 0.979979

    accuracy, precision, recall, f_score
max3: 0.974536, 0.974590, 0.974775, 0.974970

    accuracy, precision, recall, f_score
max1: 0.982524, 0.982531, 0.982958, 0.983066


min loss: 0.008, episode: 272000
max accu: 0.983, episode: 380000

47.89 classifiers used
    accuracy, precision, recall, f_score
mv: 0.981553, 0.981899, 0.982628, 0.982421
wv: 0.983495, 0.983765, 0.984381, 0.984057
fs: 0.978641, 0.978673, 0.979194, 0.979191
rl: 0.982524, 0.982531, 0.982958, 0.983066

0.8867745415318231
0.85, 0.97, 0.93, 0.73, 0.86, 0.97, 0.93, 0.72, 0.84, 0.97, 0.93, 0.72, 0.88, 0.97, 0.93, 0.75, 0.86, 0.97, 0.93, 0.78, 0.88, 0.97, 0.93, 0.79, 0.87, 0.97, 0.93, 0.82, 0.85, 0.97, 0.93, 0.82, 0.82, 0.97, 0.93, 0.73, 0.87, 0.97, 0.93, 0.77, 0.85, 0.97, 0.93, 0.73, 0.87, 0.97, 0.93, 0.79, 0.88, 0.97

0.8875183426845058
0.85, 0.97, 0.93, 0.74, 0.86, 0.97, 0.92, 0.72, 0.84, 0.97, 0.93, 0.73, 0.88, 0.97, 0.93, 0.74, 0.86, 0.97, 0.93, 0.78, 0.88, 0.97, 0.93, 0.80, 0.87, 0.97, 0.93, 0.82, 0.85, 0.97, 0.93, 0.82, 0.83, 0.97, 0.93, 0.72, 0.88, 0.97, 0.92, 0.77, 0.85, 0.97, 0.93, 0.73, 0.88, 0.97, 0.93, 0.79, 0.88, 0.97

0.8898058252427183
0.85, 0.97, 0.93, 0.74, 0.86, 0.96, 0.94, 0.72, 0.87, 0.97, 0.93, 0.74, 0.87, 0.96, 0.93, 0.75, 0.85, 0.97, 0.95, 0.79, 0.86, 0.97, 0.94, 0.80, 0.88, 0.97, 0.95, 0.83, 0.84, 0.96, 0.94, 0.82, 0.83, 0.97, 0.94, 0.73, 0.87, 0.96, 0.94, 0.78, 0.84, 0.97, 0.95, 0.73, 0.88, 0.96, 0.94, 0.80, 0.88, 0.97

0.8919805825242719
0.87, 0.97, 0.95, 0.73, 0.88, 0.98, 0.94, 0.72, 0.89, 0.97, 0.95, 0.76, 0.89, 0.97, 0.94, 0.72, 0.89, 0.97, 0.95, 0.73, 0.88, 0.97, 0.95, 0.75, 0.89, 0.97, 0.94, 0.72, 0.90, 0.97, 0.94, 0.76, 0.90, 0.97, 0.95, 0.71, 0.9, 0.97, 0.95, 0.67, 0.88, 0.96, 0.94, 0.72, 0.89, 0.97, 0.95, 0.81, 0.90, 0.97


Running iteration 3 of 10 fold...
[37, 0, 45, 48, 9, 28, 21, 44, 24, 26]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.975620, 0.975671, 0.975861, 0.976091

    accuracy, precision, recall, f_score
max3: 0.974104, 0.974172, 0.974164, 0.974293

    accuracy, precision, recall, f_score
max1: 0.986408, 0.986422, 0.986829, 0.986522


min loss: 0.012, episode: 253000
max accu: 0.986, episode: 360000

45.64 classifiers used
    accuracy, precision, recall, f_score
mv: 0.985437, 0.985502, 0.985898, 0.985396
wv: 0.983495, 0.983594, 0.983723, 0.983302
fs: 0.979612, 0.979569, 0.980387, 0.980041
rl: 0.986408, 0.986422, 0.986829, 0.986522

0.8907831715210355
0.88, 0.96, 0.93, 0.74, 0.86, 0.97, 0.93, 0.83, 0.85, 0.97, 0.93, 0.78, 0.89, 0.96, 0.93, 0.78, 0.88, 0.97, 0.93, 0.74, 0.87, 0.97, 0.93, 0.75, 0.87, 0.96, 0.93, 0.76, 0.88, 0.97, 0.93, 0.75, 0.88, 0.97, 0.93, 0.82, 0.89, 0.97, 0.93, 0.73, 0.85, 0.96, 0.93, 0.78, 0.88, 0.97, 0.93, 0.74, 0.88, 0.97

0.8921450151057401
0.89, 0.97, 0.93, 0.74, 0.87, 0.97, 0.93, 0.84, 0.84, 0.97, 0.93, 0.78, 0.89, 0.97, 0.94, 0.78, 0.88, 0.97, 0.93, 0.74, 0.88, 0.97, 0.93, 0.74, 0.88, 0.96, 0.93, 0.76, 0.89, 0.97, 0.93, 0.76, 0.88, 0.97, 0.92, 0.82, 0.89, 0.97, 0.92, 0.73, 0.86, 0.96, 0.93, 0.78, 0.88, 0.97, 0.93, 0.74, 0.88, 0.97

0.8926990291262136
0.88, 0.97, 0.93, 0.74, 0.86, 0.96, 0.95, 0.83, 0.85, 0.97, 0.94, 0.78, 0.89, 0.96, 0.94, 0.79, 0.87, 0.97, 0.93, 0.75, 0.86, 0.97, 0.93, 0.75, 0.87, 0.96, 0.94, 0.77, 0.90, 0.97, 0.93, 0.75, 0.88, 0.97, 0.94, 0.82, 0.89, 0.97, 0.93, 0.74, 0.85, 0.96, 0.93, 0.77, 0.87, 0.97, 0.93, 0.75, 0.87, 0.97

0.8987766990291263
0.89, 0.98, 0.95, 0.64, 0.89, 0.97, 0.95, 0.69, 0.90, 0.97, 0.95, 0.76, 0.91, 0.97, 0.96, 0.82, 0.87, 0.98, 0.94, 0.82, 0.89, 0.98, 0.95, 0.73, 0.88, 0.97, 0.95, 0.76, 0.88, 0.97, 0.95, 0.82, 0.88, 0.97, 0.95, 0.82, 0.90, 0.97, 0.95, 0.75, 0.89, 0.97, 0.96, 0.74, 0.89, 0.97, 0.95, 0.72, 0.89, 0.97

    accuracy, precision, recall, f_score
mv: 0.985437, 0.985590, 0.985914, 0.985704
wv: 0.985113, 0.985259, 0.985572, 0.985333
fs: 0.980583, 0.980571, 0.981468, 0.981317
rl: 0.983495, 0.983496, 0.984065, 0.983947

fs avg size: 11.33333, rl avg size: 35.35663
full test avg accu: 0.89306, test avg accu: 0.88839

training takes 25943.810 sec
