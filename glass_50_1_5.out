{'dataset': 'glass', 'algorithm': 'ptdqn', 'num_clf': 50, 'num_training': 350000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 5973, 'portion': 0.5, 'sequential': False}
(214, 10)
reading data takes 0.008 sec
number of labels: 6

Running iteration 1 of 10 fold...
[28, 0, 9, 39, 27, 20]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.677083, 0.687464, 0.535187, 0.527552

    accuracy, precision, recall, f_score
max3: 0.666667, 0.707755, 0.483135, 0.470588

    accuracy, precision, recall, f_score
max1: 0.500000, 0.398601, 0.427778, 0.394152


min loss: 0.005, episode: 265000
max accu: 0.500, episode: 220000

25.45 classifiers used
    accuracy, precision, recall, f_score
mv: 0.454545, 0.371212, 0.400000, 0.375421
wv: 0.500000, 0.398601, 0.427778, 0.385686
fs: 0.545455, 0.444215, 0.461111, 0.430778
rl: 0.500000, 0.398601, 0.427778, 0.394152

0.5485416666666666
0.61, 0.45, 0.62, 0.47, 0.64, 0.47, 0.64, 0.5, 0.58, 0.63, 0.62, 0.43, 0.54, 0.52, 0.58, 0.55, 0.60, 0.30, 0.63, 0.54, 0.58, 0.38, 0.63, 0.54, 0.65, 0.34, 0.64, 0.31, 0.67, 0.51, 0.59, 0.57, 0.61, 0.65, 0.61, 0.43, 0.61, 0.43, 0.62, 0.66, 0.5, 0.38, 0.61, 0.5, 0.56, 0.45, 0.62, 0.46, 0.56, 0.61

0.5608333333333333
0.60, 0.45, 0.64, 0.5, 0.66, 0.47, 0.66, 0.54, 0.64, 0.68, 0.70, 0.45, 0.60, 0.56, 0.62, 0.54, 0.62, 0.29, 0.66, 0.54, 0.54, 0.37, 0.66, 0.58, 0.72, 0.39, 0.66, 0.29, 0.72, 0.43, 0.64, 0.64, 0.52, 0.64, 0.66, 0.39, 0.66, 0.47, 0.70, 0.62, 0.5, 0.33, 0.64, 0.47, 0.5, 0.43, 0.66, 0.41, 0.5, 0.62

0.43727272727272726
0.40, 0.27, 0.45, 0.54, 0.63, 0.40, 0.40, 0.5, 0.72, 0.40, 0.45, 0.45, 0.54, 0.27, 0.45, 0.45, 0.54, 0.27, 0.36, 0.54, 0.40, 0.18, 0.36, 0.59, 0.59, 0.22, 0.40, 0.27, 0.54, 0.36, 0.31, 0.5, 0.59, 0.36, 0.45, 0.40, 0.59, 0.27, 0.45, 0.54, 0.36, 0.18, 0.45, 0.5, 0.45, 0.40, 0.40, 0.5, 0.59, 0.40

0.4563636363636363
0.45, 0.18, 0.40, 0.54, 0.59, 0.45, 0.40, 0.54, 0.5, 0.40, 0.45, 0.5, 0.54, 0.45, 0.40, 0.40, 0.59, 0.45, 0.36, 0.5, 0.5, 0.31, 0.45, 0.45, 0.59, 0.45, 0.40, 0.54, 0.68, 0.5, 0.45, 0.5, 0.59, 0.31, 0.40, 0.40, 0.59, 0.31, 0.40, 0.5, 0.5, 0.22, 0.36, 0.40, 0.5, 0.36, 0.36, 0.59, 0.5, 0.40


Running iteration 2 of 10 fold...
[6, 0, 8, 3, 29, 5, 7, 47, 20]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.666667, 0.628520, 0.488973, 0.456888

    accuracy, precision, recall, f_score
max3: 0.708333, 0.705107, 0.555556, 0.535270

    accuracy, precision, recall, f_score
max1: 0.545455, 0.541958, 0.657407, 0.625926


min loss: 0.010, episode: 228000
max accu: 0.545, episode: 300000

38.59 classifiers used
    accuracy, precision, recall, f_score
mv: 0.590909, 0.594697, 0.675926, 0.598039
wv: 0.590909, 0.594697, 0.675926, 0.598039
fs: 0.590909, 0.568723, 0.675926, 0.646650
rl: 0.545455, 0.541958, 0.657407, 0.625926

0.5320833333333334
0.62, 0.48, 0.59, 0.40, 0.52, 0.5, 0.67, 0.34, 0.61, 0.45, 0.58, 0.47, 0.57, 0.44, 0.56, 0.5, 0.61, 0.54, 0.58, 0.43, 0.64, 0.40, 0.67, 0.27, 0.60, 0.59, 0.61, 0.53, 0.57, 0.62, 0.59, 0.47, 0.60, 0.39, 0.58, 0.40, 0.57, 0.53, 0.62, 0.39, 0.64, 0.47, 0.63, 0.51, 0.62, 0.48, 0.57, 0.51, 0.51, 0.34

0.5670833333333333
0.64, 0.5, 0.60, 0.35, 0.60, 0.5, 0.72, 0.31, 0.64, 0.39, 0.66, 0.54, 0.66, 0.45, 0.66, 0.54, 0.68, 0.56, 0.66, 0.45, 0.75, 0.37, 0.75, 0.25, 0.66, 0.58, 0.68, 0.58, 0.54, 0.68, 0.62, 0.54, 0.75, 0.41, 0.60, 0.39, 0.64, 0.52, 0.66, 0.45, 0.66, 0.5, 0.66, 0.54, 0.64, 0.52, 0.66, 0.56, 0.56, 0.31

0.43363636363636365
0.5, 0.27, 0.5, 0.31, 0.68, 0.40, 0.54, 0.22, 0.54, 0.31, 0.54, 0.40, 0.45, 0.22, 0.59, 0.36, 0.59, 0.31, 0.5, 0.36, 0.59, 0.27, 0.59, 0.22, 0.68, 0.36, 0.59, 0.36, 0.40, 0.40, 0.59, 0.31, 0.45, 0.40, 0.40, 0.40, 0.54, 0.27, 0.5, 0.45, 0.59, 0.31, 0.54, 0.36, 0.54, 0.18, 0.54, 0.40, 0.40, 0.22

0.4836363636363636
0.59, 0.36, 0.54, 0.31, 0.68, 0.27, 0.54, 0.31, 0.72, 0.31, 0.72, 0.36, 0.45, 0.09, 0.54, 0.40, 0.77, 0.59, 0.63, 0.36, 0.63, 0.27, 0.54, 0.31, 0.54, 0.22, 0.72, 0.36, 0.45, 0.54, 0.54, 0.63, 0.68, 0.5, 0.45, 0.31, 0.63, 0.31, 0.5, 0.27, 0.59, 0.40, 0.5, 0.31, 0.72, 0.5, 0.59, 0.40, 0.63, 0.36


Running iteration 3 of 10 fold...
[5, 0, 4, 28, 27, 7, 48]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.697917, 0.661518, 0.520322, 0.477900

    accuracy, precision, recall, f_score
max3: 0.729167, 0.730884, 0.566667, 0.549402

    accuracy, precision, recall, f_score
max1: 0.818182, 0.925620, 0.781250, 0.667179


min loss: 0.007, episode: 259000
max accu: 0.818, episode: 270000

48.23 classifiers used
    accuracy, precision, recall, f_score
mv: 0.863636, 0.902597, 0.909722, 0.737778
wv: 0.909091, 0.954545, 0.940972, 0.763235
fs: 0.818182, 0.890909, 0.885417, 0.715556
rl: 0.818182, 0.925620, 0.781250, 0.667179

0.53875
0.62, 0.5, 0.65, 0.45, 0.67, 0.68, 0.57, 0.5, 0.56, 0.64, 0.65, 0.55, 0.5, 0.53, 0.57, 0.47, 0.41, 0.51, 0.52, 0.42, 0.56, 0.48, 0.56, 0.47, 0.51, 0.51, 0.61, 0.51, 0.59, 0.56, 0.64, 0.36, 0.48, 0.53, 0.62, 0.56, 0.56, 0.39, 0.60, 0.48, 0.60, 0.59, 0.54, 0.33, 0.63, 0.48, 0.59, 0.53, 0.58, 0.31

0.5579166666666666
0.66, 0.47, 0.64, 0.43, 0.72, 0.77, 0.64, 0.5, 0.52, 0.64, 0.64, 0.5, 0.54, 0.56, 0.62, 0.47, 0.45, 0.52, 0.54, 0.39, 0.54, 0.43, 0.58, 0.47, 0.47, 0.5, 0.68, 0.47, 0.64, 0.60, 0.70, 0.39, 0.56, 0.56, 0.68, 0.56, 0.62, 0.5, 0.68, 0.45, 0.64, 0.60, 0.56, 0.29, 0.68, 0.47, 0.64, 0.52, 0.64, 0.31

0.5718181818181819
0.72, 0.54, 0.63, 0.63, 0.81, 0.59, 0.54, 0.72, 0.68, 0.68, 0.59, 0.59, 0.59, 0.54, 0.54, 0.63, 0.36, 0.45, 0.5, 0.54, 0.36, 0.59, 0.59, 0.45, 0.45, 0.5, 0.72, 0.63, 0.45, 0.45, 0.68, 0.40, 0.5, 0.63, 0.63, 0.59, 0.81, 0.31, 0.72, 0.72, 0.72, 0.5, 0.63, 0.31, 0.5, 0.36, 0.54, 0.5, 0.86, 0.40

0.6245454545454545
0.59, 0.63, 0.81, 0.31, 0.72, 0.45, 0.81, 0.36, 0.77, 0.5, 0.77, 0.59, 0.63, 0.54, 0.72, 0.59, 0.81, 0.63, 0.72, 0.54, 0.77, 0.45, 0.68, 0.63, 0.81, 0.77, 0.72, 0.59, 0.81, 0.45, 0.68, 0.31, 0.68, 0.59, 0.68, 0.27, 0.86, 0.36, 0.72, 0.31, 0.81, 0.40, 0.81, 0.59, 0.81, 0.54, 0.81, 0.45, 0.81, 0.31

    accuracy, precision, recall, f_score
mv: 0.727273, 0.622835, 0.661883, 0.667909
wv: 0.755695, 0.649281, 0.681559, 0.680637
fs: 0.704546, 0.634616, 0.674151, 0.681103
rl: 0.681819, 0.622060, 0.622145, 0.646553

fs avg size: 7.33333, rl avg size: 37.42424
full test avg accu: 0.52152, test avg accu: 0.48091

training takes 12408.112 sec
