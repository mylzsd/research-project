{'dataset': 'breast_w', 'algorithm': 'ptdqn', 'num_clf': 50, 'num_training': 350000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 2224, 'portion': 0.5, 'sequential': False}
(699, 10)
reading data takes 0.284 sec
number of labels: 2

Running iteration 1 of 10 fold...
[18, 0, 2, 1, 3, 4, 5, 6, 7, 8, 11, 9, 14, 10, 15, 12, 19, 13, 23, 16, 27, 17, 28, 20, 31, 21, 32, 22, 35, 24, 36, 25, 39, 26, 40, 29, 41, 30, 43, 33, 47, 34, 48, 37]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.965079, 0.965293, 0.958733, 0.962541

    accuracy, precision, recall, f_score
max3: 0.955414, 0.955762, 0.949679, 0.953220

    accuracy, precision, recall, f_score
max1: 0.971429, 0.971429, 0.968297, 0.968297


min loss: 0.008, episode: 241000
max accu: 0.971, episode: 350000

44.73 classifiers used
    accuracy, precision, recall, f_score
mv: 0.985714, 0.986286, 0.989130, 0.984301
wv: 0.971429, 0.973626, 0.978261, 0.968889
fs: 0.971429, 0.971429, 0.968297, 0.968297
rl: 0.971429, 0.971429, 0.968297, 0.968297

0.9431746031746031
0.92, 0.94, 0.96, 0.93, 0.94, 0.96, 0.94, 0.95, 0.91, 0.92, 0.96, 0.95, 0.91, 0.93, 0.93, 0.95, 0.90, 0.93, 0.96, 0.95, 0.92, 0.92, 0.91, 0.95, 0.90, 0.93, 0.96, 0.96, 0.92, 0.94, 0.95, 0.95, 0.94, 0.95, 0.94, 0.95, 0.94, 0.94, 0.95, 0.94, 0.93, 0.93, 0.96, 0.95, 0.93, 0.93, 0.94, 0.95, 0.91, 0.95

0.9329936305732486
0.92, 0.94, 0.95, 0.93, 0.92, 0.95, 0.93, 0.94, 0.86, 0.91, 0.95, 0.94, 0.89, 0.92, 0.92, 0.94, 0.89, 0.91, 0.96, 0.94, 0.89, 0.90, 0.89, 0.94, 0.91, 0.91, 0.95, 0.94, 0.93, 0.93, 0.94, 0.94, 0.94, 0.92, 0.93, 0.94, 0.94, 0.92, 0.94, 0.94, 0.92, 0.94, 0.96, 0.94, 0.92, 0.92, 0.91, 0.96, 0.90, 0.93

0.9454285714285714
0.97, 0.95, 0.95, 0.94, 0.91, 0.91, 0.94, 0.94, 0.92, 0.94, 0.95, 0.95, 0.88, 0.95, 0.94, 0.94, 0.92, 0.94, 0.95, 0.94, 0.92, 0.91, 0.92, 0.94, 0.95, 0.95, 0.95, 0.94, 0.95, 0.97, 0.94, 0.94, 0.95, 0.95, 0.94, 0.94, 0.95, 0.95, 0.95, 0.94, 0.92, 0.94, 0.95, 0.94, 0.97, 0.97, 0.95, 0.94, 0.91, 0.95

0.9471428571428571
0.94, 0.95, 0.92, 0.94, 0.94, 0.97, 0.92, 0.94, 0.94, 0.92, 0.92, 0.94, 0.98, 0.97, 0.94, 0.94, 0.94, 0.95, 0.95, 0.94, 0.91, 0.94, 0.95, 0.94, 0.94, 0.97, 0.94, 0.94, 0.95, 0.95, 0.94, 0.94, 0.94, 0.94, 0.95, 0.94, 0.94, 0.97, 0.92, 0.94, 0.94, 0.98, 0.95, 0.94, 0.92, 0.95, 0.92, 0.94, 0.95, 0.94


Running iteration 2 of 10 fold...
[18, 0, 3, 14, 28, 1, 48, 4, 44, 2]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.958730, 0.959240, 0.950641, 0.955730

    accuracy, precision, recall, f_score
max3: 0.955414, 0.955803, 0.950669, 0.953724

    accuracy, precision, recall, f_score
max1: 0.942857, 0.943143, 0.921402, 0.931973


min loss: 0.008, episode: 281000
max accu: 0.943, episode: 260000

17.81 classifiers used
    accuracy, precision, recall, f_score
mv: 0.957143, 0.957046, 0.944129, 0.949652
wv: 0.957143, 0.957046, 0.944129, 0.949652
fs: 0.942857, 0.943143, 0.921402, 0.931973
rl: 0.942857, 0.943143, 0.921402, 0.931973

0.9440634920634919
0.88, 0.95, 0.93, 0.96, 0.94, 0.94, 0.94, 0.95, 0.93, 0.94, 0.95, 0.96, 0.92, 0.94, 0.95, 0.96, 0.93, 0.93, 0.97, 0.96, 0.95, 0.94, 0.92, 0.95, 0.89, 0.93, 0.94, 0.96, 0.93, 0.93, 0.94, 0.96, 0.93, 0.94, 0.93, 0.96, 0.92, 0.92, 0.96, 0.96, 0.91, 0.94, 0.94, 0.96, 0.92, 0.93, 0.94, 0.95, 0.92, 0.94

0.9365605095541403
0.87, 0.94, 0.92, 0.96, 0.94, 0.94, 0.93, 0.94, 0.94, 0.92, 0.95, 0.96, 0.90, 0.92, 0.96, 0.96, 0.92, 0.93, 0.96, 0.96, 0.94, 0.93, 0.91, 0.94, 0.88, 0.92, 0.94, 0.96, 0.91, 0.94, 0.94, 0.95, 0.92, 0.94, 0.92, 0.96, 0.87, 0.91, 0.96, 0.96, 0.89, 0.92, 0.94, 0.95, 0.91, 0.91, 0.93, 0.94, 0.93, 0.93

0.9205714285714286
0.91, 0.92, 0.92, 0.92, 0.91, 0.92, 0.94, 0.88, 0.87, 0.94, 0.94, 0.92, 0.92, 0.91, 0.91, 0.92, 0.94, 0.9, 0.92, 0.92, 0.88, 0.91, 0.92, 0.91, 0.91, 0.92, 0.91, 0.92, 0.92, 0.9, 0.92, 0.92, 0.91, 0.91, 0.92, 0.92, 0.92, 0.9, 0.92, 0.92, 0.9, 0.92, 0.95, 0.92, 0.9, 0.9, 0.94, 0.91, 0.92, 0.9

0.9451428571428572
0.92, 0.92, 0.95, 0.94, 0.94, 0.94, 0.95, 0.92, 0.97, 0.94, 0.95, 0.92, 0.94, 0.95, 0.94, 0.92, 0.94, 0.94, 0.95, 0.94, 0.98, 0.92, 0.95, 0.92, 0.92, 0.95, 0.95, 0.94, 0.91, 0.94, 0.97, 0.92, 0.95, 0.94, 0.92, 0.94, 0.92, 0.92, 0.95, 0.94, 0.95, 0.95, 0.97, 0.94, 0.94, 0.95, 0.95, 0.92, 0.92, 0.95


Running iteration 3 of 10 fold...
[7, 0, 26, 9, 3, 4, 11, 8, 40, 10, 19, 18, 15, 22, 23, 25, 27, 28, 31, 33, 35, 36, 39, 38]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.965079, 0.965407, 0.965511, 0.963476

    accuracy, precision, recall, f_score
max3: 0.961783, 0.961783, 0.961215, 0.961215

    accuracy, precision, recall, f_score
max1: 0.971429, 0.972507, 0.947368, 0.962607


min loss: 0.009, episode: 272000
max accu: 0.971, episode: 10000

1.00 classifiers used
    accuracy, precision, recall, f_score
mv: 0.971429, 0.972507, 0.947368, 0.962607
wv: 0.971429, 0.972507, 0.947368, 0.962607
fs: 0.971429, 0.972507, 0.947368, 0.962607
rl: 0.971429, 0.972507, 0.947368, 0.962607

0.9393650793650792
0.87, 0.92, 0.95, 0.95, 0.92, 0.94, 0.92, 0.96, 0.90, 0.95, 0.94, 0.95, 0.89, 0.93, 0.94, 0.96, 0.91, 0.94, 0.93, 0.95, 0.91, 0.95, 0.92, 0.96, 0.93, 0.94, 0.95, 0.96, 0.92, 0.93, 0.95, 0.96, 0.94, 0.94, 0.93, 0.96, 0.93, 0.94, 0.92, 0.95, 0.89, 0.92, 0.96, 0.96, 0.89, 0.94, 0.94, 0.96, 0.90, 0.93

0.9313375796178343
0.83, 0.90, 0.94, 0.94, 0.91, 0.94, 0.91, 0.96, 0.88, 0.94, 0.93, 0.94, 0.89, 0.94, 0.94, 0.96, 0.89, 0.92, 0.92, 0.94, 0.91, 0.94, 0.91, 0.96, 0.93, 0.92, 0.95, 0.96, 0.94, 0.92, 0.94, 0.96, 0.93, 0.93, 0.93, 0.96, 0.92, 0.93, 0.91, 0.94, 0.91, 0.89, 0.95, 0.95, 0.87, 0.93, 0.92, 0.96, 0.88, 0.92

0.9545714285714287
0.94, 0.94, 0.97, 0.94, 0.97, 0.97, 0.94, 0.97, 0.9, 0.98, 0.94, 0.94, 0.92, 0.94, 0.95, 0.97, 0.94, 0.97, 0.95, 0.94, 0.95, 0.97, 0.94, 0.97, 0.94, 0.94, 0.94, 0.97, 0.94, 0.95, 0.94, 0.97, 0.95, 0.94, 0.95, 0.97, 0.97, 0.94, 0.97, 0.94, 0.94, 0.92, 0.95, 0.97, 0.92, 0.95, 0.97, 0.97, 0.98, 0.95

0.9620000000000001
0.94, 0.95, 0.95, 0.97, 0.98, 0.94, 0.94, 0.97, 0.92, 0.98, 0.94, 0.97, 0.97, 0.97, 0.95, 0.97, 0.97, 0.95, 0.95, 0.97, 0.91, 0.98, 0.95, 0.97, 0.95, 0.95, 0.95, 0.97, 0.94, 0.97, 0.98, 0.97, 0.94, 0.97, 0.97, 0.97, 0.94, 0.95, 0.95, 0.97, 0.95, 0.98, 0.95, 0.97, 0.95, 0.98, 0.94, 0.97, 0.95, 0.95

    accuracy, precision, recall, f_score
mv: 0.971429, 0.971946, 0.960209, 0.965520
wv: 0.966667, 0.967726, 0.956586, 0.960383
fs: 0.961905, 0.962359, 0.945689, 0.954292
rl: 0.961905, 0.962359, 0.945689, 0.954292

fs avg size: 26.00000, rl avg size: 21.18095
full test avg accu: 0.95143, test avg accu: 0.94019

training takes 15687.753 sec
