{'dataset': 'cmc', 'algorithm': 'ptdqn', 'num_clf': 50, 'num_training': 500000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 5353, 'portion': 0.5, 'sequential': False}
(1473, 22)
reading data takes 3.433 sec
number of labels: 3

Running iteration 1 of 10 fold...
[3, 0, 32, 8, 5, 12, 14, 19, 34, 2, 37, 38, 33]
using cpu
using cpu
    accuracy, precision, recall, f_score
rl: 0.574324, 0.576725, 0.558369, 0.555610


min loss: 0.006, episode: 204000
max accu: 0.574, episode: 440000

2.79 classifiers used
    accuracy, precision, recall, f_score
mv: 0.486486, 0.491771, 0.463514, 0.456408
wv: 0.493243, 0.494884, 0.462188, 0.458901
fs: 0.486486, 0.494376, 0.472204, 0.464672
rl: 0.574324, 0.576725, 0.558369, 0.555610

0.44874811463046754
0.43, 0.42, 0.43, 0.48, 0.47, 0.47, 0.42, 0.44, 0.48, 0.45, 0.43, 0.42, 0.44, 0.46, 0.45, 0.43, 0.42, 0.47, 0.42, 0.44, 0.42, 0.46, 0.43, 0.44, 0.44, 0.46, 0.45, 0.44, 0.43, 0.47, 0.45, 0.48, 0.46, 0.43, 0.46, 0.45, 0.46, 0.46, 0.43, 0.42, 0.41, 0.46, 0.46, 0.41, 0.44, 0.42, 0.43, 0.45, 0.44, 0.44

0.4616216216216217
0.47, 0.43, 0.46, 0.46, 0.49, 0.45, 0.42, 0.47, 0.45, 0.45, 0.47, 0.45, 0.41, 0.48, 0.43, 0.45, 0.47, 0.52, 0.43, 0.48, 0.44, 0.49, 0.48, 0.47, 0.50, 0.45, 0.44, 0.50, 0.48, 0.5, 0.43, 0.47, 0.47, 0.40, 0.53, 0.47, 0.46, 0.44, 0.49, 0.41, 0.42, 0.43, 0.41, 0.35, 0.46, 0.43, 0.49, 0.46, 0.46, 0.43

0.46324324324324323
0.39, 0.48, 0.51, 0.47, 0.51, 0.48, 0.44, 0.39, 0.5, 0.45, 0.49, 0.45, 0.48, 0.50, 0.42, 0.45, 0.47, 0.48, 0.48, 0.43, 0.52, 0.42, 0.43, 0.44, 0.45, 0.43, 0.44, 0.45, 0.48, 0.49, 0.43, 0.41, 0.48, 0.53, 0.52, 0.48, 0.46, 0.42, 0.45, 0.46, 0.44, 0.38, 0.42, 0.45, 0.39, 0.43, 0.52, 0.5, 0.43, 0.47


Running iteration 2 of 10 fold...
[38, 0, 8, 36, 35, 45, 26, 25, 30, 31]
using cpu
using cpu
    accuracy, precision, recall, f_score
rl: 0.554054, 0.554220, 0.530556, 0.535097


min loss: 0.007, episode: 197000
max accu: 0.554, episode: 170000

35.98 classifiers used
    accuracy, precision, recall, f_score
mv: 0.520270, 0.523689, 0.511717, 0.516783
wv: 0.520270, 0.523725, 0.515393, 0.520882
fs: 0.500000, 0.499081, 0.486821, 0.489097
rl: 0.554054, 0.554220, 0.530556, 0.535097

0.4507390648567119
0.47, 0.45, 0.43, 0.44, 0.46, 0.44, 0.44, 0.46, 0.48, 0.45, 0.43, 0.45, 0.45, 0.45, 0.43, 0.44, 0.44, 0.44, 0.47, 0.46, 0.49, 0.46, 0.44, 0.44, 0.44, 0.46, 0.43, 0.42, 0.44, 0.47, 0.47, 0.43, 0.45, 0.44, 0.42, 0.43, 0.44, 0.43, 0.49, 0.43, 0.43, 0.44, 0.47, 0.44, 0.41, 0.45, 0.43, 0.43, 0.42, 0.46

0.47189189189189185
0.57, 0.43, 0.5, 0.5, 0.52, 0.51, 0.44, 0.44, 0.40, 0.43, 0.46, 0.47, 0.56, 0.48, 0.42, 0.53, 0.44, 0.44, 0.41, 0.49, 0.47, 0.47, 0.47, 0.46, 0.48, 0.48, 0.44, 0.48, 0.47, 0.41, 0.52, 0.46, 0.49, 0.52, 0.43, 0.5, 0.46, 0.50, 0.37, 0.45, 0.5, 0.45, 0.36, 0.47, 0.48, 0.45, 0.45, 0.43, 0.51, 0.44

0.4545945945945946
0.44, 0.43, 0.43, 0.44, 0.57, 0.50, 0.41, 0.47, 0.45, 0.46, 0.52, 0.49, 0.5, 0.44, 0.43, 0.47, 0.48, 0.47, 0.43, 0.45, 0.41, 0.44, 0.40, 0.41, 0.45, 0.44, 0.45, 0.39, 0.46, 0.38, 0.41, 0.36, 0.47, 0.42, 0.46, 0.41, 0.44, 0.42, 0.47, 0.45, 0.50, 0.51, 0.43, 0.41, 0.48, 0.41, 0.5, 0.47, 0.43, 0.48


Running iteration 3 of 10 fold...
[42, 0, 32]
using cpu
using cpu
    accuracy, precision, recall, f_score
rl: 0.547297, 0.551677, 0.473611, 0.468056


min loss: 0.007, episode: 199000
max accu: 0.547, episode: 170000

32.17 classifiers used
    accuracy, precision, recall, f_score
mv: 0.506757, 0.534850, 0.431759, 0.425199
wv: 0.500000, 0.539281, 0.425093, 0.418007
fs: 0.405405, 0.444914, 0.340556, 0.339047
rl: 0.547297, 0.551677, 0.473611, 0.468056

0.44425339366515837
0.41, 0.42, 0.44, 0.43, 0.45, 0.43, 0.46, 0.45, 0.46, 0.45, 0.44, 0.43, 0.41, 0.46, 0.41, 0.43, 0.44, 0.45, 0.43, 0.43, 0.44, 0.45, 0.41, 0.45, 0.47, 0.43, 0.44, 0.43, 0.45, 0.41, 0.45, 0.44, 0.46, 0.41, 0.46, 0.47, 0.46, 0.42, 0.44, 0.43, 0.44, 0.46, 0.47, 0.41, 0.42, 0.42, 0.42, 0.46, 0.47, 0.42

0.4608108108108108
0.38, 0.50, 0.44, 0.36, 0.41, 0.47, 0.50, 0.40, 0.5, 0.45, 0.49, 0.5, 0.44, 0.48, 0.5, 0.50, 0.47, 0.41, 0.42, 0.55, 0.41, 0.5, 0.50, 0.47, 0.54, 0.45, 0.47, 0.44, 0.42, 0.42, 0.49, 0.53, 0.41, 0.49, 0.39, 0.47, 0.45, 0.45, 0.5, 0.39, 0.39, 0.43, 0.44, 0.45, 0.43, 0.45, 0.42, 0.50, 0.47, 0.45

0.45648648648648643
0.43, 0.47, 0.44, 0.43, 0.45, 0.49, 0.39, 0.36, 0.43, 0.49, 0.47, 0.42, 0.47, 0.39, 0.47, 0.41, 0.45, 0.48, 0.48, 0.52, 0.48, 0.52, 0.45, 0.48, 0.47, 0.37, 0.50, 0.47, 0.42, 0.44, 0.43, 0.39, 0.45, 0.5, 0.44, 0.42, 0.43, 0.33, 0.39, 0.50, 0.47, 0.43, 0.42, 0.45, 0.45, 0.51, 0.50, 0.47, 0.5, 0.53


Running iteration 4 of 10 fold...
[14, 0, 47, 3, 40]
using cpu
using cpu
    accuracy, precision, recall, f_score
rl: 0.517007, 0.515823, 0.483516, 0.479690


min loss: 0.007, episode: 188000
max accu: 0.517, episode: 170000

43.42 classifiers used
    accuracy, precision, recall, f_score
mv: 0.503401, 0.501515, 0.462412, 0.456714
wv: 0.517007, 0.516790, 0.479956, 0.471792
fs: 0.476190, 0.487127, 0.447150, 0.442083
rl: 0.517007, 0.515823, 0.483516, 0.479690

0.4477526395173454
0.44, 0.44, 0.41, 0.49, 0.43, 0.47, 0.45, 0.45, 0.44, 0.41, 0.46, 0.41, 0.44, 0.43, 0.49, 0.42, 0.45, 0.44, 0.44, 0.41, 0.44, 0.47, 0.43, 0.42, 0.42, 0.45, 0.39, 0.44, 0.44, 0.43, 0.45, 0.48, 0.45, 0.44, 0.46, 0.47, 0.46, 0.44, 0.43, 0.44, 0.44, 0.46, 0.45, 0.42, 0.47, 0.44, 0.43, 0.48, 0.43, 0.45

0.45088435374149655
0.41, 0.40, 0.46, 0.47, 0.44, 0.44, 0.46, 0.44, 0.48, 0.38, 0.50, 0.44, 0.44, 0.49, 0.51, 0.36, 0.48, 0.46, 0.42, 0.45, 0.46, 0.49, 0.43, 0.48, 0.42, 0.44, 0.36, 0.42, 0.42, 0.48, 0.47, 0.48, 0.46, 0.47, 0.44, 0.42, 0.43, 0.46, 0.46, 0.44, 0.40, 0.47, 0.48, 0.45, 0.37, 0.48, 0.38, 0.41, 0.48, 0.48

0.44503401360544215
0.43, 0.47, 0.47, 0.40, 0.38, 0.45, 0.53, 0.39, 0.43, 0.36, 0.48, 0.40, 0.48, 0.37, 0.42, 0.48, 0.44, 0.40, 0.43, 0.42, 0.48, 0.44, 0.42, 0.44, 0.45, 0.44, 0.40, 0.40, 0.39, 0.46, 0.45, 0.48, 0.44, 0.46, 0.46, 0.47, 0.41, 0.42, 0.44, 0.48, 0.43, 0.41, 0.46, 0.44, 0.48, 0.48, 0.40, 0.44, 0.48, 0.47


Running iteration 5 of 10 fold...
[5, 0, 27, 21, 37, 34, 19]
using cpu
using cpu
    accuracy, precision, recall, f_score
rl: 0.530612, 0.532986, 0.526696, 0.511497


min loss: 0.006, episode: 220000
max accu: 0.531, episode: 320000

18.49 classifiers used
    accuracy, precision, recall, f_score
mv: 0.503401, 0.495239, 0.498173, 0.484211
wv: 0.510204, 0.501120, 0.506184, 0.490430
fs: 0.476190, 0.481673, 0.473790, 0.465438
rl: 0.530612, 0.532986, 0.526696, 0.511497

0.4499245852187028
0.45, 0.44, 0.45, 0.43, 0.44, 0.49, 0.43, 0.46, 0.44, 0.47, 0.43, 0.44, 0.43, 0.45, 0.42, 0.42, 0.43, 0.44, 0.42, 0.47, 0.42, 0.46, 0.44, 0.46, 0.42, 0.43, 0.47, 0.47, 0.48, 0.44, 0.40, 0.47, 0.44, 0.44, 0.44, 0.43, 0.47, 0.46, 0.45, 0.41, 0.47, 0.44, 0.45, 0.42, 0.48, 0.42, 0.46, 0.48, 0.46, 0.42

0.44122448979591833
0.42, 0.42, 0.44, 0.40, 0.45, 0.40, 0.38, 0.47, 0.45, 0.42, 0.46, 0.38, 0.43, 0.43, 0.46, 0.44, 0.52, 0.45, 0.42, 0.44, 0.46, 0.42, 0.45, 0.51, 0.40, 0.44, 0.42, 0.46, 0.46, 0.40, 0.43, 0.42, 0.49, 0.44, 0.42, 0.40, 0.48, 0.44, 0.40, 0.34, 0.44, 0.52, 0.44, 0.40, 0.48, 0.44, 0.43, 0.46, 0.44, 0.39

0.43251700680272104
0.42, 0.37, 0.44, 0.38, 0.43, 0.40, 0.47, 0.48, 0.42, 0.44, 0.48, 0.39, 0.44, 0.42, 0.35, 0.46, 0.40, 0.42, 0.41, 0.45, 0.43, 0.44, 0.45, 0.46, 0.44, 0.36, 0.45, 0.40, 0.39, 0.36, 0.42, 0.40, 0.44, 0.42, 0.42, 0.41, 0.44, 0.36, 0.52, 0.44, 0.42, 0.50, 0.45, 0.41, 0.44, 0.40, 0.50, 0.44, 0.47, 0.42


Running iteration 6 of 10 fold...
[25, 0, 3, 12, 18, 15]
using cpu
using cpu
    accuracy, precision, recall, f_score
rl: 0.537415, 0.511853, 0.499980, 0.478144


min loss: 0.008, episode: 175000
max accu: 0.537, episode: 150000

8.15 classifiers used
    accuracy, precision, recall, f_score
mv: 0.510204, 0.504714, 0.499264, 0.488625
wv: 0.503401, 0.492603, 0.489740, 0.479081
fs: 0.489796, 0.477865, 0.468549, 0.461580
rl: 0.537415, 0.511853, 0.499980, 0.478144

0.4495927601809954
0.42, 0.43, 0.42, 0.49, 0.41, 0.40, 0.45, 0.45, 0.44, 0.44, 0.43, 0.41, 0.47, 0.43, 0.44, 0.47, 0.44, 0.44, 0.48, 0.46, 0.45, 0.46, 0.42, 0.44, 0.49, 0.50, 0.44, 0.47, 0.46, 0.46, 0.46, 0.47, 0.43, 0.44, 0.47, 0.41, 0.45, 0.42, 0.44, 0.46, 0.42, 0.41, 0.46, 0.46, 0.43, 0.45, 0.47, 0.41, 0.46, 0.42

0.44693877551020406
0.46, 0.45, 0.47, 0.41, 0.49, 0.44, 0.41, 0.43, 0.45, 0.47, 0.42, 0.48, 0.51, 0.42, 0.45, 0.44, 0.49, 0.44, 0.45, 0.38, 0.46, 0.45, 0.46, 0.47, 0.48, 0.49, 0.40, 0.46, 0.45, 0.51, 0.40, 0.44, 0.42, 0.36, 0.43, 0.48, 0.48, 0.38, 0.40, 0.44, 0.40, 0.46, 0.43, 0.42, 0.40, 0.46, 0.38, 0.41, 0.44, 0.42

0.45115646258503406
0.42, 0.44, 0.42, 0.44, 0.43, 0.44, 0.44, 0.43, 0.48, 0.44, 0.42, 0.42, 0.43, 0.44, 0.46, 0.39, 0.48, 0.48, 0.47, 0.46, 0.51, 0.44, 0.48, 0.44, 0.43, 0.45, 0.42, 0.46, 0.50, 0.42, 0.48, 0.40, 0.40, 0.43, 0.42, 0.44, 0.39, 0.50, 0.46, 0.46, 0.40, 0.48, 0.48, 0.42, 0.51, 0.44, 0.44, 0.42, 0.45, 0.51


Running iteration 7 of 10 fold...
[3, 0, 12, 47, 14, 42]
using cpu
using cpu
    accuracy, precision, recall, f_score
rl: 0.503401, 0.518367, 0.463175, 0.448465


min loss: 0.007, episode: 213000
max accu: 0.503, episode: 320000

15.71 classifiers used
    accuracy, precision, recall, f_score
mv: 0.489796, 0.497139, 0.450159, 0.445620
wv: 0.496599, 0.499854, 0.458095, 0.452818
fs: 0.489796, 0.518375, 0.466984, 0.458202
rl: 0.503401, 0.518367, 0.463175, 0.448465

0.4579487179487179
0.47, 0.46, 0.46, 0.54, 0.45, 0.48, 0.46, 0.47, 0.46, 0.47, 0.49, 0.46, 0.49, 0.48, 0.45, 0.40, 0.40, 0.47, 0.46, 0.41, 0.45, 0.44, 0.46, 0.46, 0.49, 0.41, 0.44, 0.44, 0.44, 0.45, 0.42, 0.45, 0.48, 0.45, 0.41, 0.48, 0.44, 0.46, 0.46, 0.46, 0.41, 0.47, 0.47, 0.42, 0.45, 0.45, 0.41, 0.46, 0.46, 0.46

0.41891156462585033
0.46, 0.38, 0.40, 0.43, 0.41, 0.45, 0.46, 0.42, 0.44, 0.42, 0.43, 0.41, 0.44, 0.44, 0.43, 0.39, 0.41, 0.35, 0.40, 0.39, 0.42, 0.35, 0.42, 0.38, 0.43, 0.37, 0.40, 0.44, 0.44, 0.47, 0.38, 0.44, 0.46, 0.40, 0.37, 0.44, 0.38, 0.31, 0.46, 0.48, 0.38, 0.45, 0.49, 0.39, 0.39, 0.44, 0.40, 0.42, 0.40, 0.34

0.45659863945578233
0.48, 0.44, 0.40, 0.46, 0.49, 0.50, 0.43, 0.46, 0.44, 0.44, 0.47, 0.45, 0.45, 0.43, 0.44, 0.40, 0.44, 0.44, 0.47, 0.43, 0.45, 0.46, 0.45, 0.46, 0.44, 0.50, 0.46, 0.50, 0.48, 0.48, 0.42, 0.40, 0.43, 0.41, 0.43, 0.51, 0.44, 0.49, 0.45, 0.42, 0.40, 0.44, 0.42, 0.44, 0.48, 0.46, 0.46, 0.46, 0.47, 0.48


Running iteration 8 of 10 fold...
[44, 0, 35, 26, 15]
using cpu
using cpu
    accuracy, precision, recall, f_score
rl: 0.523810, 0.515560, 0.462410, 0.457899


min loss: 0.006, episode: 205000
max accu: 0.524, episode: 320000

11.20 classifiers used
    accuracy, precision, recall, f_score
mv: 0.482993, 0.488127, 0.430709, 0.430830
wv: 0.476190, 0.483070, 0.425879, 0.425966
fs: 0.442177, 0.445155, 0.387389, 0.387561
rl: 0.523810, 0.515560, 0.462410, 0.457899

0.45692307692307677
0.47, 0.46, 0.47, 0.48, 0.44, 0.45, 0.45, 0.48, 0.47, 0.44, 0.44, 0.43, 0.39, 0.41, 0.44, 0.43, 0.44, 0.43, 0.47, 0.41, 0.46, 0.45, 0.45, 0.44, 0.49, 0.44, 0.49, 0.45, 0.43, 0.45, 0.42, 0.45, 0.49, 0.47, 0.46, 0.49, 0.48, 0.40, 0.47, 0.42, 0.47, 0.45, 0.45, 0.46, 0.50, 0.44, 0.46, 0.47, 0.45, 0.47

0.4402721088435374
0.42, 0.40, 0.44, 0.47, 0.40, 0.42, 0.42, 0.38, 0.45, 0.42, 0.51, 0.42, 0.46, 0.47, 0.46, 0.43, 0.45, 0.44, 0.40, 0.46, 0.42, 0.47, 0.44, 0.46, 0.42, 0.45, 0.33, 0.45, 0.35, 0.44, 0.47, 0.48, 0.42, 0.45, 0.42, 0.46, 0.50, 0.46, 0.46, 0.46, 0.46, 0.38, 0.51, 0.38, 0.42, 0.39, 0.38, 0.42, 0.41, 0.49

0.45401360544217684
0.46, 0.42, 0.49, 0.48, 0.44, 0.50, 0.48, 0.47, 0.44, 0.46, 0.48, 0.44, 0.40, 0.40, 0.48, 0.46, 0.47, 0.48, 0.38, 0.48, 0.46, 0.43, 0.49, 0.38, 0.46, 0.47, 0.45, 0.48, 0.40, 0.44, 0.46, 0.42, 0.46, 0.40, 0.43, 0.55, 0.47, 0.40, 0.46, 0.48, 0.46, 0.46, 0.44, 0.44, 0.36, 0.42, 0.42, 0.42, 0.42, 0.48


Running iteration 9 of 10 fold...
[2, 0, 14, 47, 32, 8, 6, 37]
using cpu
using cpu
    accuracy, precision, recall, f_score
rl: 0.489796, 0.480473, 0.465988, 0.456543


min loss: 0.006, episode: 202000
max accu: 0.490, episode: 340000

13.18 classifiers used
    accuracy, precision, recall, f_score
mv: 0.442177, 0.429667, 0.426467, 0.420788
wv: 0.435374, 0.418461, 0.419841, 0.412050
fs: 0.469388, 0.455994, 0.453096, 0.444645
rl: 0.489796, 0.480473, 0.465988, 0.456543

0.4657315233785821
0.42, 0.46, 0.50, 0.49, 0.45, 0.47, 0.47, 0.47, 0.48, 0.45, 0.43, 0.45, 0.49, 0.48, 0.46, 0.46, 0.44, 0.44, 0.45, 0.49, 0.46, 0.49, 0.45, 0.47, 0.45, 0.47, 0.46, 0.48, 0.48, 0.46, 0.42, 0.47, 0.47, 0.46, 0.47, 0.44, 0.46, 0.48, 0.45, 0.42, 0.44, 0.45, 0.48, 0.47, 0.44, 0.45, 0.45, 0.48, 0.42, 0.48

0.42272108843537415
0.43, 0.38, 0.46, 0.40, 0.44, 0.41, 0.46, 0.47, 0.45, 0.44, 0.42, 0.43, 0.43, 0.42, 0.39, 0.47, 0.40, 0.30, 0.42, 0.41, 0.44, 0.44, 0.46, 0.36, 0.39, 0.40, 0.39, 0.37, 0.50, 0.38, 0.34, 0.36, 0.39, 0.43, 0.44, 0.44, 0.46, 0.44, 0.39, 0.42, 0.45, 0.45, 0.44, 0.39, 0.33, 0.43, 0.44, 0.43, 0.42, 0.43

0.4164625850340136
0.43, 0.43, 0.39, 0.40, 0.43, 0.42, 0.45, 0.44, 0.33, 0.45, 0.41, 0.40, 0.40, 0.40, 0.44, 0.41, 0.42, 0.40, 0.40, 0.42, 0.45, 0.36, 0.38, 0.46, 0.33, 0.42, 0.37, 0.41, 0.38, 0.40, 0.40, 0.44, 0.40, 0.46, 0.40, 0.44, 0.42, 0.43, 0.43, 0.43, 0.37, 0.38, 0.40, 0.40, 0.37, 0.40, 0.44, 0.47, 0.45, 0.41


Running iteration 10 of 10 fold...
[40, 0, 13, 21, 5, 7, 36, 42]
using cpu
using cpu
    accuracy, precision, recall, f_score
rl: 0.551020, 0.552781, 0.528632, 0.532426


min loss: 0.007, episode: 181000
max accu: 0.551, episode: 260000

47.78 classifiers used
    accuracy, precision, recall, f_score
mv: 0.557823, 0.554046, 0.545940, 0.546499
wv: 0.551020, 0.547367, 0.537393, 0.538251
fs: 0.530612, 0.526173, 0.504380, 0.504912
rl: 0.551020, 0.552781, 0.528632, 0.532426

0.46184012066365
0.43, 0.43, 0.46, 0.46, 0.45, 0.47, 0.47, 0.47, 0.44, 0.47, 0.43, 0.45, 0.47, 0.47, 0.42, 0.44, 0.43, 0.49, 0.46, 0.45, 0.45, 0.46, 0.46, 0.48, 0.45, 0.44, 0.46, 0.46, 0.48, 0.45, 0.43, 0.46, 0.46, 0.46, 0.42, 0.46, 0.49, 0.47, 0.48, 0.47, 0.49, 0.46, 0.45, 0.46, 0.47, 0.45, 0.45, 0.47, 0.48, 0.45

0.45877551020408164
0.42, 0.44, 0.40, 0.50, 0.45, 0.44, 0.41, 0.49, 0.50, 0.42, 0.48, 0.46, 0.46, 0.50, 0.42, 0.46, 0.41, 0.47, 0.44, 0.52, 0.45, 0.48, 0.46, 0.49, 0.46, 0.51, 0.45, 0.42, 0.47, 0.40, 0.39, 0.43, 0.46, 0.45, 0.44, 0.48, 0.51, 0.47, 0.45, 0.40, 0.44, 0.40, 0.35, 0.46, 0.36, 0.42, 0.49, 0.50, 0.57, 0.51

0.48571428571428577
0.50, 0.48, 0.50, 0.40, 0.48, 0.48, 0.48, 0.51, 0.40, 0.52, 0.39, 0.48, 0.45, 0.46, 0.45, 0.53, 0.48, 0.46, 0.48, 0.48, 0.43, 0.53, 0.46, 0.44, 0.48, 0.46, 0.44, 0.46, 0.51, 0.45, 0.43, 0.48, 0.50, 0.51, 0.50, 0.50, 0.54, 0.47, 0.51, 0.54, 0.48, 0.53, 0.51, 0.43, 0.50, 0.50, 0.48, 0.46, 0.54, 0.54

    accuracy, precision, recall, f_score
mv: 0.500331, 0.502076, 0.472011, 0.467168
wv: 0.500331, 0.501716, 0.471976, 0.466818
fs: 0.476604, 0.483073, 0.450092, 0.445724
rl: 0.532874, 0.531047, 0.499293, 0.492343

fs avg size: 7.10000, rl avg size: 22.88700
full test avg accu: 0.45158, test avg accu: 0.44740

training takes 37719.905 sec
