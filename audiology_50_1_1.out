{'dataset': 'audiology', 'algorithm': 'ptdqn', 'num_clf': 50, 'num_training': 500000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 1483, 'portion': 0.5, 'sequential': False}
(226, 95)
reading data takes 6.388 sec
number of labels: 24

Running iteration 1 of 10 fold...
[34, 0, 37, 43]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.633663, 0.582140, 0.307986, 0.277731

    accuracy, precision, recall, f_score
max3: 0.627451, 0.592810, 0.283333, 0.254365

    accuracy, precision, recall, f_score
max1: 0.826087, 0.823671, 0.202381, 0.197173


min loss: 0.011, episode: 225000
max accu: 0.826, episode: 390000

5.74 classifiers used
    accuracy, precision, recall, f_score
mv: 0.782609, 0.772947, 0.167659, 0.166617
wv: 0.782609, 0.772947, 0.167659, 0.166617
fs: 0.739130, 0.771014, 0.176587, 0.159921
rl: 0.826087, 0.823671, 0.202381, 0.197173

0.5497029702970297
0.62, 0.63, 0.49, 0.48, 0.61, 0.56, 0.57, 0.45, 0.57, 0.58, 0.45, 0.58, 0.62, 0.45, 0.59, 0.48, 0.45, 0.54, 0.60, 0.53, 0.58, 0.62, 0.60, 0.60, 0.62, 0.45, 0.56, 0.62, 0.52, 0.50, 0.51, 0.62, 0.48, 0.53, 0.67, 0.55, 0.56, 0.52, 0.59, 0.56, 0.56, 0.58, 0.54, 0.52, 0.49, 0.60, 0.55, 0.45, 0.37, 0.49

0.5439215686274509
0.62, 0.62, 0.52, 0.43, 0.66, 0.50, 0.58, 0.43, 0.62, 0.58, 0.41, 0.60, 0.64, 0.50, 0.52, 0.49, 0.47, 0.52, 0.56, 0.58, 0.56, 0.54, 0.66, 0.54, 0.60, 0.47, 0.54, 0.60, 0.49, 0.47, 0.49, 0.60, 0.45, 0.52, 0.70, 0.50, 0.56, 0.54, 0.58, 0.56, 0.56, 0.52, 0.52, 0.58, 0.49, 0.60, 0.54, 0.39, 0.37, 0.49

0.5721739130434783
0.65, 0.65, 0.52, 0.47, 0.73, 0.39, 0.65, 0.65, 0.69, 0.56, 0.47, 0.73, 0.78, 0.43, 0.56, 0.43, 0.60, 0.56, 0.73, 0.65, 0.65, 0.60, 0.52, 0.73, 0.73, 0.56, 0.60, 0.73, 0.52, 0.56, 0.43, 0.69, 0.39, 0.34, 0.78, 0.60, 0.65, 0.43, 0.73, 0.60, 0.47, 0.69, 0.43, 0.47, 0.21, 0.65, 0.43, 0.52, 0.39, 0.34

0.6173913043478261
0.52, 0.82, 0.56, 0.73, 0.69, 0.60, 0.82, 0.56, 0.34, 0.69, 0.65, 0.78, 0.47, 0.56, 0.56, 0.56, 0.47, 0.69, 0.52, 0.82, 0.56, 0.65, 0.52, 0.34, 0.73, 0.65, 0.47, 0.43, 0.56, 0.52, 0.43, 0.60, 0.69, 0.78, 0.69, 0.60, 0.73, 0.73, 0.60, 0.65, 0.56, 0.60, 0.65, 0.69, 0.56, 0.39, 0.65, 0.65, 0.73, 0.78


Running iteration 2 of 10 fold...
[12, 0, 14, 17, 39, 6, 46, 2, 3, 13]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.722772, 0.658688, 0.303125, 0.274564

    accuracy, precision, recall, f_score
max3: 0.725490, 0.687463, 0.300694, 0.275740

    accuracy, precision, recall, f_score
max1: 0.782609, 0.723913, 0.224537, 0.218950


min loss: 0.007, episode: 312000
max accu: 0.783, episode: 290000

26.35 classifiers used
    accuracy, precision, recall, f_score
mv: 0.826087, 0.750000, 0.229167, 0.216270
wv: 0.869565, 0.815217, 0.270833, 0.271825
fs: 0.695652, 0.661594, 0.215278, 0.205106
rl: 0.782609, 0.723913, 0.224537, 0.218950

0.5255445544554455
0.50, 0.68, 0.39, 0.46, 0.39, 0.64, 0.67, 0.54, 0.50, 0.58, 0.62, 0.43, 0.70, 0.54, 0.56, 0.55, 0.47, 0.64, 0.55, 0.43, 0.59, 0.35, 0.56, 0.41, 0.56, 0.51, 0.61, 0.39, 0.54, 0.45, 0.48, 0.56, 0.45, 0.52, 0.58, 0.33, 0.49, 0.36, 0.59, 0.57, 0.44, 0.58, 0.61, 0.56, 0.59, 0.40, 0.43, 0.60, 0.60, 0.49

0.5211764705882352
0.45, 0.70, 0.35, 0.43, 0.31, 0.68, 0.64, 0.49, 0.49, 0.64, 0.66, 0.39, 0.72, 0.49, 0.54, 0.56, 0.50, 0.60, 0.56, 0.47, 0.56, 0.27, 0.58, 0.43, 0.60, 0.56, 0.64, 0.29, 0.54, 0.47, 0.41, 0.58, 0.43, 0.50, 0.54, 0.37, 0.47, 0.35, 0.58, 0.58, 0.41, 0.58, 0.62, 0.60, 0.58, 0.39, 0.43, 0.66, 0.62, 0.49

0.5182608695652174
0.56, 0.60, 0.52, 0.47, 0.39, 0.43, 0.39, 0.52, 0.56, 0.30, 0.56, 0.43, 0.39, 0.56, 0.56, 0.43, 0.47, 0.52, 0.56, 0.30, 0.56, 0.65, 0.69, 0.47, 0.52, 0.52, 0.56, 0.47, 0.65, 0.52, 0.69, 0.47, 0.47, 0.52, 0.52, 0.39, 0.52, 0.52, 0.60, 0.65, 0.43, 0.56, 0.65, 0.60, 0.65, 0.26, 0.47, 0.39, 0.47, 0.73

0.5452173913043478
0.60, 0.30, 0.69, 0.65, 0.47, 0.65, 0.47, 0.47, 0.43, 0.73, 0.56, 0.52, 0.60, 0.65, 0.47, 0.47, 0.47, 0.69, 0.47, 0.73, 0.60, 0.52, 0.78, 0.39, 0.65, 0.52, 0.43, 0.52, 0.56, 0.43, 0.56, 0.60, 0.21, 0.34, 0.52, 0.43, 0.56, 0.56, 0.34, 0.65, 0.56, 0.39, 0.56, 0.60, 0.82, 0.65, 0.56, 0.43, 0.56, 0.60


Running iteration 3 of 10 fold...
[8, 0, 4, 30, 12, 26, 6, 23, 29]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.702970, 0.599157, 0.305208, 0.274646

    accuracy, precision, recall, f_score
max3: 0.705882, 0.648921, 0.292361, 0.262281

    accuracy, precision, recall, f_score
max1: 0.782609, 0.704348, 0.191667, 0.170034


min loss: 0.006, episode: 304000
max accu: 0.783, episode: 480000

9.65 classifiers used
    accuracy, precision, recall, f_score
mv: 0.869565, 0.894410, 0.220833, 0.224537
wv: 0.869565, 0.894410, 0.220833, 0.224537
fs: 0.739130, 0.807453, 0.193750, 0.200000
rl: 0.782609, 0.704348, 0.191667, 0.170034

0.5126732673267326
0.56, 0.48, 0.54, 0.56, 0.49, 0.52, 0.47, 0.45, 0.66, 0.31, 0.45, 0.41, 0.60, 0.41, 0.42, 0.58, 0.49, 0.62, 0.60, 0.54, 0.49, 0.58, 0.44, 0.47, 0.61, 0.50, 0.57, 0.52, 0.48, 0.45, 0.46, 0.41, 0.44, 0.61, 0.35, 0.56, 0.54, 0.52, 0.52, 0.62, 0.60, 0.48, 0.59, 0.48, 0.50, 0.44, 0.52, 0.46, 0.49, 0.53

0.49372549019607836
0.54, 0.41, 0.47, 0.52, 0.45, 0.50, 0.47, 0.49, 0.66, 0.31, 0.41, 0.39, 0.62, 0.39, 0.39, 0.54, 0.54, 0.68, 0.60, 0.50, 0.50, 0.56, 0.41, 0.41, 0.62, 0.56, 0.54, 0.52, 0.41, 0.47, 0.39, 0.33, 0.45, 0.58, 0.31, 0.50, 0.52, 0.49, 0.54, 0.56, 0.60, 0.37, 0.54, 0.47, 0.50, 0.45, 0.54, 0.45, 0.47, 0.49

0.5443478260869564
0.60, 0.69, 0.43, 0.60, 0.52, 0.39, 0.52, 0.60, 0.56, 0.56, 0.52, 0.30, 0.56, 0.34, 0.47, 0.78, 0.52, 0.78, 0.43, 0.56, 0.56, 0.52, 0.56, 0.34, 0.65, 0.56, 0.52, 0.34, 0.82, 0.43, 0.56, 0.43, 0.39, 0.60, 0.65, 0.52, 0.52, 0.65, 0.56, 0.69, 0.69, 0.47, 0.47, 0.56, 0.56, 0.47, 0.43, 0.52, 0.65, 0.56

0.5730434782608697
0.60, 0.56, 0.65, 0.56, 0.78, 0.56, 0.52, 0.52, 0.52, 0.52, 0.69, 0.60, 0.65, 0.52, 0.47, 0.69, 0.52, 0.52, 0.26, 0.69, 0.65, 0.60, 0.39, 0.73, 0.56, 0.43, 0.52, 0.69, 0.52, 0.52, 0.65, 0.47, 0.39, 0.69, 0.60, 0.69, 0.78, 0.60, 0.56, 0.60, 0.47, 0.65, 0.39, 0.73, 0.52, 0.69, 0.69, 0.47, 0.43, 0.34


Running iteration 4 of 10 fold...
[44, 0, 10, 1, 2, 5, 26, 3, 16, 46, 4, 6, 7, 9, 11, 8, 21, 25, 12, 17, 14, 34, 29, 19]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.544554, 0.470172, 0.212028, 0.177946

    accuracy, precision, recall, f_score
max3: 0.411765, 0.362325, 0.193056, 0.155420

    accuracy, precision, recall, f_score
max1: 0.434783, 0.325052, 0.201389, 0.159722


min loss: 0.007, episode: 276000
max accu: 0.435, episode: 210000

2.91 classifiers used
    accuracy, precision, recall, f_score
mv: 0.521739, 0.502484, 0.270833, 0.251389
wv: 0.521739, 0.519565, 0.270833, 0.263763
fs: 0.391304, 0.385507, 0.187500, 0.179167
rl: 0.434783, 0.325052, 0.201389, 0.159722

0.5087128712871287
0.37, 0.47, 0.58, 0.39, 0.64, 0.51, 0.49, 0.44, 0.40, 0.60, 0.59, 0.62, 0.60, 0.41, 0.57, 0.58, 0.62, 0.59, 0.60, 0.54, 0.48, 0.54, 0.39, 0.45, 0.56, 0.42, 0.42, 0.59, 0.47, 0.54, 0.56, 0.53, 0.54, 0.53, 0.48, 0.56, 0.43, 0.49, 0.44, 0.46, 0.30, 0.45, 0.41, 0.57, 0.65, 0.39, 0.53, 0.41, 0.50, 0.49

0.4749019607843136
0.29, 0.45, 0.58, 0.37, 0.58, 0.56, 0.43, 0.43, 0.45, 0.60, 0.56, 0.64, 0.56, 0.41, 0.50, 0.52, 0.58, 0.60, 0.58, 0.49, 0.45, 0.52, 0.31, 0.35, 0.58, 0.39, 0.41, 0.56, 0.39, 0.54, 0.52, 0.54, 0.50, 0.37, 0.35, 0.66, 0.33, 0.49, 0.37, 0.43, 0.19, 0.47, 0.39, 0.49, 0.64, 0.37, 0.52, 0.39, 0.39, 0.41

0.29043478260869565
0.17, 0.21, 0.26, 0.34, 0.43, 0.17, 0.30, 0.30, 0.30, 0.21, 0.17, 0.34, 0.30, 0.21, 0.26, 0.34, 0.34, 0.26, 0.30, 0.30, 0.21, 0.34, 0.26, 0.17, 0.30, 0.30, 0.13, 0.39, 0.34, 0.26, 0.34, 0.39, 0.26, 0.34, 0.21, 0.43, 0.39, 0.26, 0.30, 0.30, 0.08, 0.34, 0.17, 0.30, 0.30, 0.34, 0.39, 0.26, 0.34, 0.34

0.4130434782608696
0.47, 0.47, 0.39, 0.34, 0.43, 0.39, 0.30, 0.17, 0.34, 0.39, 0.43, 0.47, 0.43, 0.43, 0.47, 0.56, 0.39, 0.47, 0.47, 0.39, 0.39, 0.43, 0.39, 0.43, 0.47, 0.39, 0.43, 0.52, 0.34, 0.47, 0.34, 0.30, 0.43, 0.52, 0.30, 0.43, 0.34, 0.34, 0.34, 0.43, 0.47, 0.39, 0.30, 0.52, 0.47, 0.30, 0.47, 0.30, 0.43, 0.52


Running iteration 5 of 10 fold...
[15, 0, 21, 3, 1, 4, 9, 18]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.702970, 0.614119, 0.299711, 0.266647

    accuracy, precision, recall, f_score
max3: 0.705882, 0.663611, 0.263521, 0.232881

    accuracy, precision, recall, f_score
max1: 0.478261, 0.457971, 0.208333, 0.171032


min loss: 0.007, episode: 318000
max accu: 0.478, episode: 270000

18.52 classifiers used
    accuracy, precision, recall, f_score
mv: 0.565217, 0.579710, 0.281250, 0.280060
wv: 0.521739, 0.536232, 0.239583, 0.238393
fs: 0.304348, 0.346791, 0.135417, 0.120707
rl: 0.478261, 0.457971, 0.208333, 0.171032

0.5336633663366337
0.49, 0.46, 0.58, 0.63, 0.61, 0.46, 0.50, 0.47, 0.52, 0.50, 0.50, 0.55, 0.45, 0.46, 0.47, 0.69, 0.51, 0.63, 0.50, 0.48, 0.61, 0.63, 0.62, 0.39, 0.48, 0.56, 0.37, 0.60, 0.44, 0.56, 0.56, 0.43, 0.47, 0.50, 0.49, 0.56, 0.44, 0.54, 0.50, 0.67, 0.58, 0.60, 0.63, 0.58, 0.46, 0.60, 0.54, 0.54, 0.60, 0.44

0.5203921568627451
0.43, 0.49, 0.58, 0.66, 0.62, 0.39, 0.52, 0.47, 0.52, 0.45, 0.47, 0.54, 0.49, 0.39, 0.49, 0.64, 0.50, 0.62, 0.52, 0.43, 0.62, 0.58, 0.62, 0.33, 0.49, 0.58, 0.29, 0.62, 0.47, 0.50, 0.56, 0.39, 0.50, 0.52, 0.47, 0.54, 0.39, 0.52, 0.45, 0.64, 0.56, 0.58, 0.64, 0.58, 0.45, 0.64, 0.52, 0.50, 0.58, 0.39

0.2669565217391305
0.34, 0.08, 0.13, 0.21, 0.30, 0.26, 0.30, 0.39, 0.21, 0.30, 0.30, 0.13, 0.34, 0.17, 0.26, 0.21, 0.26, 0.39, 0.34, 0.17, 0.30, 0.43, 0.26, 0.17, 0.30, 0.26, 0.21, 0.34, 0.30, 0.26, 0.26, 0.26, 0.21, 0.34, 0.21, 0.21, 0.34, 0.21, 0.39, 0.26, 0.26, 0.21, 0.30, 0.26, 0.30, 0.47, 0.17, 0.26, 0.13, 0.17

0.37652173913043485
0.39, 0.52, 0.39, 0.39, 0.34, 0.43, 0.34, 0.39, 0.26, 0.30, 0.39, 0.43, 0.39, 0.39, 0.52, 0.43, 0.47, 0.34, 0.30, 0.26, 0.56, 0.47, 0.39, 0.34, 0.26, 0.34, 0.39, 0.43, 0.34, 0.52, 0.43, 0.30, 0.34, 0.34, 0.30, 0.30, 0.30, 0.26, 0.43, 0.26, 0.34, 0.30, 0.30, 0.47, 0.34, 0.39, 0.43, 0.34, 0.34, 0.39


Running iteration 6 of 10 fold...
[11, 0, 1, 7, 28, 4, 46, 23, 48, 21, 24, 12, 17, 41, 35, 10, 49]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.574257, 0.643994, 0.300782, 0.288555

    accuracy, precision, recall, f_score
max3: 0.588235, 0.600552, 0.229861, 0.216912

    accuracy, precision, recall, f_score
max1: 0.782609, 0.692029, 0.250000, 0.226371


min loss: 0.006, episode: 276000
max accu: 0.783, episode: 460000

1.26 classifiers used
    accuracy, precision, recall, f_score
mv: 0.826087, 0.771739, 0.291667, 0.271825
wv: 0.826087, 0.771739, 0.291667, 0.271825
fs: 0.739130, 0.681159, 0.208333, 0.190657
rl: 0.782609, 0.692029, 0.250000, 0.226371

0.5047524752475249
0.51, 0.61, 0.50, 0.57, 0.55, 0.34, 0.42, 0.50, 0.45, 0.49, 0.48, 0.64, 0.53, 0.42, 0.51, 0.45, 0.54, 0.42, 0.51, 0.54, 0.46, 0.53, 0.40, 0.47, 0.52, 0.57, 0.63, 0.56, 0.57, 0.54, 0.42, 0.46, 0.48, 0.59, 0.43, 0.50, 0.45, 0.57, 0.59, 0.50, 0.45, 0.61, 0.55, 0.54, 0.48, 0.44, 0.50, 0.48, 0.30, 0.42

0.5003921568627451
0.49, 0.60, 0.62, 0.54, 0.60, 0.31, 0.45, 0.56, 0.45, 0.45, 0.58, 0.58, 0.56, 0.41, 0.50, 0.37, 0.52, 0.39, 0.52, 0.54, 0.45, 0.52, 0.35, 0.41, 0.54, 0.58, 0.68, 0.60, 0.58, 0.56, 0.45, 0.47, 0.49, 0.56, 0.47, 0.45, 0.41, 0.58, 0.54, 0.52, 0.43, 0.58, 0.62, 0.56, 0.43, 0.37, 0.49, 0.41, 0.27, 0.35

0.5834782608695652
0.43, 0.78, 0.65, 0.69, 0.69, 0.34, 0.65, 0.60, 0.47, 0.69, 0.56, 0.69, 0.47, 0.73, 0.65, 0.56, 0.73, 0.52, 0.73, 0.56, 0.52, 0.73, 0.47, 0.39, 0.47, 0.78, 0.60, 0.60, 0.60, 0.56, 0.34, 0.65, 0.52, 0.56, 0.43, 0.39, 0.34, 0.65, 0.60, 0.65, 0.30, 0.78, 0.86, 0.65, 0.52, 0.47, 0.69, 0.43, 0.56, 0.60

0.7052173913043479
0.78, 0.65, 0.69, 0.52, 0.47, 0.73, 0.69, 0.82, 0.73, 0.73, 0.65, 0.73, 0.78, 0.69, 0.73, 0.73, 0.86, 0.78, 0.47, 0.82, 0.78, 0.82, 0.65, 0.52, 0.82, 0.56, 0.73, 0.73, 0.65, 0.47, 0.78, 0.60, 0.73, 0.73, 0.78, 0.73, 0.69, 0.69, 0.73, 0.82, 0.60, 0.69, 0.65, 0.78, 0.78, 0.78, 0.69, 0.69, 0.69, 0.56


Running iteration 7 of 10 fold...
[33, 0, 27, 18, 8, 47, 41, 26, 12, 35]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.598039, 0.441411, 0.250027, 0.223088

    accuracy, precision, recall, f_score
max3: 0.666667, 0.548209, 0.171875, 0.145516

    accuracy, precision, recall, f_score
max1: 0.636364, 0.486364, 0.166667, 0.127315


min loss: 0.012, episode: 270000
max accu: 0.636, episode: 320000

3.77 classifiers used
    accuracy, precision, recall, f_score
mv: 0.909091, 0.939394, 0.263889, 0.265657
wv: 0.909091, 0.939394, 0.263889, 0.265657
fs: 0.545455, 0.512987, 0.166667, 0.141414
rl: 0.636364, 0.486364, 0.166667, 0.127315

0.4713725490196078
0.51, 0.43, 0.42, 0.46, 0.51, 0.48, 0.47, 0.50, 0.52, 0.46, 0.47, 0.48, 0.46, 0.52, 0.45, 0.39, 0.50, 0.48, 0.35, 0.46, 0.45, 0.52, 0.42, 0.47, 0.43, 0.52, 0.34, 0.58, 0.49, 0.40, 0.5, 0.53, 0.53, 0.63, 0.32, 0.51, 0.48, 0.47, 0.54, 0.50, 0.53, 0.43, 0.33, 0.34, 0.5, 0.45, 0.54, 0.44, 0.46, 0.40

0.5368627450980392
0.64, 0.45, 0.52, 0.50, 0.54, 0.49, 0.50, 0.56, 0.56, 0.56, 0.56, 0.50, 0.60, 0.60, 0.50, 0.47, 0.60, 0.56, 0.45, 0.49, 0.45, 0.52, 0.50, 0.54, 0.43, 0.60, 0.41, 0.70, 0.60, 0.43, 0.62, 0.62, 0.60, 0.68, 0.29, 0.62, 0.50, 0.58, 0.64, 0.56, 0.60, 0.45, 0.41, 0.35, 0.54, 0.56, 0.60, 0.50, 0.58, 0.39

0.4881818181818181
0.59, 0.31, 0.31, 0.5, 0.54, 0.5, 0.54, 0.45, 0.31, 0.40, 0.54, 0.27, 0.45, 0.63, 0.31, 0.54, 0.59, 0.54, 0.54, 0.45, 0.59, 0.59, 0.45, 0.45, 0.54, 0.68, 0.45, 0.40, 0.59, 0.45, 0.59, 0.59, 0.36, 0.40, 0.36, 0.5, 0.54, 0.59, 0.5, 0.54, 0.59, 0.59, 0.45, 0.5, 0.45, 0.45, 0.45, 0.45, 0.5, 0.31

0.6509090909090908
0.45, 0.45, 0.45, 0.63, 0.5, 0.77, 0.59, 0.72, 0.72, 0.77, 0.63, 0.81, 0.81, 0.68, 0.68, 0.5, 0.63, 0.81, 0.63, 0.54, 0.72, 0.77, 0.77, 0.68, 0.54, 0.81, 0.54, 0.81, 0.59, 0.81, 0.63, 0.77, 0.72, 0.59, 0.54, 0.63, 0.59, 0.63, 0.54, 0.27, 0.72, 0.72, 0.63, 0.63, 0.59, 0.54, 0.68, 0.72, 0.72, 0.63


Running iteration 8 of 10 fold...
[49, 0, 8, 6, 23, 20, 9, 47, 7, 3]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.627451, 0.544060, 0.280456, 0.253760

    accuracy, precision, recall, f_score
max3: 0.666667, 0.592449, 0.196759, 0.164014

    accuracy, precision, recall, f_score
max1: 0.863636, 0.886364, 0.198495, 0.186785


min loss: 0.005, episode: 364000
max accu: 0.864, episode: 350000

31.14 classifiers used
    accuracy, precision, recall, f_score
mv: 0.727273, 0.920455, 0.183449, 0.168510
wv: 0.727273, 0.920455, 0.183449, 0.168510
fs: 0.727273, 0.840909, 0.183449, 0.175570
rl: 0.863636, 0.886364, 0.198495, 0.186785

0.4637254901960784
0.42, 0.39, 0.37, 0.42, 0.38, 0.44, 0.37, 0.53, 0.57, 0.53, 0.57, 0.5, 0.40, 0.32, 0.52, 0.42, 0.49, 0.41, 0.40, 0.5, 0.39, 0.55, 0.47, 0.59, 0.46, 0.55, 0.46, 0.48, 0.49, 0.40, 0.5, 0.42, 0.48, 0.54, 0.45, 0.49, 0.41, 0.52, 0.5, 0.48, 0.40, 0.48, 0.48, 0.35, 0.24, 0.46, 0.40, 0.48, 0.50, 0.66

0.5227450980392158
0.50, 0.45, 0.41, 0.50, 0.33, 0.52, 0.47, 0.56, 0.68, 0.58, 0.58, 0.58, 0.45, 0.35, 0.50, 0.49, 0.50, 0.52, 0.45, 0.54, 0.43, 0.62, 0.50, 0.64, 0.49, 0.58, 0.56, 0.41, 0.60, 0.50, 0.54, 0.47, 0.56, 0.62, 0.54, 0.54, 0.54, 0.60, 0.54, 0.56, 0.49, 0.52, 0.56, 0.41, 0.23, 0.50, 0.49, 0.50, 0.62, 0.70

0.5427272727272728
0.54, 0.72, 0.45, 0.86, 0.63, 0.77, 0.59, 0.36, 0.45, 0.45, 0.59, 0.45, 0.54, 0.45, 0.54, 0.45, 0.81, 0.40, 0.54, 0.31, 0.77, 0.68, 0.72, 0.59, 0.54, 0.59, 0.77, 0.59, 0.54, 0.45, 0.72, 0.54, 0.5, 0.81, 0.27, 0.54, 0.54, 0.54, 0.54, 0.40, 0.31, 0.36, 0.36, 0.31, 0.45, 0.40, 0.5, 0.45, 0.54, 0.68

0.5609090909090909
0.31, 0.5, 0.54, 0.59, 0.68, 0.45, 0.5, 0.63, 0.40, 0.59, 0.59, 0.68, 0.63, 0.68, 0.59, 0.54, 0.45, 0.59, 0.5, 0.59, 0.54, 0.72, 0.40, 0.68, 0.40, 0.45, 0.72, 0.5, 0.72, 0.40, 0.59, 0.63, 0.31, 0.45, 0.59, 0.5, 0.27, 0.77, 0.54, 0.63, 0.54, 0.59, 0.81, 0.5, 0.59, 0.59, 0.68, 0.5, 0.72, 0.5


Running iteration 9 of 10 fold...
[7, 0, 48, 47, 18, 31]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.627451, 0.560496, 0.258681, 0.242203

    accuracy, precision, recall, f_score
max3: 0.666667, 0.634559, 0.212384, 0.194435

    accuracy, precision, recall, f_score
max1: 0.863636, 0.789256, 0.239583, 0.235417


min loss: 0.005, episode: 256000
max accu: 0.864, episode: 330000

23.23 classifiers used
    accuracy, precision, recall, f_score
mv: 0.772727, 0.749126, 0.218750, 0.211472
wv: 0.772727, 0.749126, 0.218750, 0.211472
fs: 0.772727, 0.727273, 0.187500, 0.182540
rl: 0.863636, 0.789256, 0.239583, 0.235417

0.46215686274509793
0.51, 0.50, 0.52, 0.40, 0.53, 0.54, 0.32, 0.62, 0.47, 0.57, 0.42, 0.28, 0.55, 0.47, 0.46, 0.44, 0.55, 0.44, 0.42, 0.58, 0.49, 0.49, 0.50, 0.45, 0.36, 0.49, 0.51, 0.36, 0.48, 0.36, 0.33, 0.38, 0.33, 0.49, 0.36, 0.40, 0.5, 0.42, 0.44, 0.36, 0.45, 0.34, 0.5, 0.50, 0.47, 0.53, 0.52, 0.61, 0.49, 0.41

0.5129411764705882
0.64, 0.62, 0.56, 0.45, 0.62, 0.64, 0.39, 0.74, 0.54, 0.60, 0.47, 0.29, 0.64, 0.47, 0.54, 0.47, 0.62, 0.52, 0.45, 0.70, 0.56, 0.52, 0.58, 0.47, 0.33, 0.58, 0.58, 0.35, 0.54, 0.39, 0.37, 0.39, 0.29, 0.56, 0.41, 0.43, 0.58, 0.47, 0.47, 0.33, 0.50, 0.41, 0.52, 0.54, 0.47, 0.56, 0.56, 0.72, 0.50, 0.43

0.6336363636363636
0.63, 0.81, 0.77, 0.59, 0.68, 0.63, 0.68, 0.77, 0.77, 0.68, 0.68, 0.40, 0.81, 0.63, 0.59, 0.5, 0.63, 0.77, 0.81, 0.63, 0.68, 0.63, 0.63, 0.45, 0.54, 0.72, 0.54, 0.54, 0.45, 0.59, 0.40, 0.63, 0.68, 0.63, 0.45, 0.59, 0.68, 0.59, 0.54, 0.45, 0.81, 0.54, 0.81, 0.63, 0.63, 0.68, 0.63, 0.77, 0.45, 0.63

0.6609090909090909
0.77, 0.72, 0.68, 0.81, 0.81, 0.63, 0.59, 0.63, 0.59, 0.63, 0.72, 0.45, 0.72, 0.63, 0.54, 0.68, 0.63, 0.63, 0.68, 0.72, 0.63, 0.72, 0.54, 0.54, 0.54, 0.72, 0.68, 0.72, 0.77, 0.63, 0.68, 0.77, 0.68, 0.59, 0.59, 0.68, 0.68, 0.59, 0.63, 0.59, 0.63, 0.59, 0.68, 0.77, 0.68, 0.68, 0.68, 0.68, 0.68, 0.54


Running iteration 10 of 10 fold...
[46, 0, 31, 48, 36, 5, 39, 28, 13, 4, 17]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.627451, 0.559248, 0.412051, 0.352498

    accuracy, precision, recall, f_score
max3: 0.666667, 0.644538, 0.293692, 0.265745

    accuracy, precision, recall, f_score
max1: 0.818182, 0.909091, 0.172454, 0.179097


min loss: 0.012, episode: 369000
max accu: 0.818, episode: 300000

3.09 classifiers used
    accuracy, precision, recall, f_score
mv: 0.772727, 0.818182, 0.156250, 0.152778
wv: 0.772727, 0.818182, 0.156250, 0.152778
fs: 0.772727, 0.818182, 0.162037, 0.163624
rl: 0.818182, 0.909091, 0.172454, 0.179097

0.4505882352941176
0.50, 0.49, 0.43, 0.56, 0.52, 0.50, 0.36, 0.35, 0.56, 0.38, 0.56, 0.48, 0.38, 0.38, 0.38, 0.47, 0.40, 0.48, 0.38, 0.40, 0.28, 0.50, 0.47, 0.43, 0.56, 0.33, 0.42, 0.48, 0.52, 0.41, 0.44, 0.49, 0.31, 0.5, 0.44, 0.42, 0.45, 0.52, 0.48, 0.33, 0.40, 0.38, 0.5, 0.54, 0.53, 0.5, 0.58, 0.42, 0.39, 0.37

0.4992156862745098
0.58, 0.52, 0.54, 0.60, 0.54, 0.54, 0.41, 0.41, 0.60, 0.43, 0.64, 0.47, 0.45, 0.37, 0.47, 0.54, 0.47, 0.54, 0.41, 0.45, 0.39, 0.64, 0.54, 0.47, 0.60, 0.37, 0.43, 0.52, 0.60, 0.43, 0.50, 0.52, 0.35, 0.52, 0.45, 0.41, 0.49, 0.60, 0.50, 0.35, 0.47, 0.45, 0.50, 0.58, 0.62, 0.54, 0.64, 0.43, 0.39, 0.43

0.5636363636363636
0.63, 0.59, 0.54, 0.72, 0.68, 0.68, 0.81, 0.36, 0.68, 0.59, 0.68, 0.45, 0.63, 0.13, 0.54, 0.45, 0.45, 0.5, 0.59, 0.40, 0.27, 0.77, 0.59, 0.59, 0.40, 0.45, 0.59, 0.59, 0.77, 0.54, 0.5, 0.5, 0.5, 0.54, 0.40, 0.63, 0.54, 0.77, 0.63, 0.31, 0.59, 0.5, 0.54, 0.72, 0.59, 0.68, 0.77, 0.45, 0.59, 0.59

0.6127272727272728
0.77, 0.45, 0.68, 0.68, 0.63, 0.63, 0.63, 0.68, 0.59, 0.59, 0.40, 0.54, 0.63, 0.5, 0.45, 0.5, 0.72, 0.45, 0.68, 0.68, 0.63, 0.77, 0.59, 0.54, 0.59, 0.68, 0.68, 0.54, 0.81, 0.68, 0.59, 0.77, 0.72, 0.54, 0.54, 0.81, 0.59, 0.45, 0.63, 0.68, 0.68, 0.59, 0.54, 0.59, 0.68, 0.59, 0.5, 0.40, 0.5, 0.68

    accuracy, precision, recall, f_score
mv: 0.757312, 0.769845, 0.228375, 0.220911
wv: 0.757312, 0.773727, 0.228375, 0.223538
fs: 0.642688, 0.655287, 0.181652, 0.171871
rl: 0.726877, 0.679806, 0.205551, 0.187189

fs avg size: 10.90000, rl avg size: 12.56621
full test avg accu: 0.57159, test avg accu: 0.50038

training takes 34458.600 sec
