{'dataset': 'cmc', 'algorithm': 'dqn', 'num_clf': 10, 'num_training': 2, 'learning_rate': 0.01, 'discount_factor': 0.99, 'epsilon': 0.1, 'random_state': 5076, 'portion': 0.5, 'sequential': False}
(663, 22)
(663, 22)
(147, 22)
epoch: 0 row: 0
	 ['visit 9', 'visit 8', 'visit 2', 'visit 0', 'visit 1', 'visit 5', 'visit 4', 'evaluation']

	state: None None None None None None None None None None -> action:  visit 9
	state_p: None None None None None None None None None 3 -> reward:  0.0
	target_q: 0.4218111424211167 index: 9
	q_values: [-0.063998    0.23122223 -0.05753052 -0.18197284  0.02824096  0.02214151
 -0.0956636  -0.5169458   0.31648487  0.5992021  -0.48327662] (11,)
	target_qs: [-0.063998    0.23122223 -0.05753052 -0.18197284  0.02824096  0.02214151
 -0.0956636  -0.5169458   0.31648487  0.42181114 -0.48327662] (11,)
	trained q_values: [-0.17022551 -0.08003703  0.36898967 -0.7117287   0.15846119  0.74767658
  0.41382204 -0.70449764  0.57952269 -3.13938473  0.10852653] (11,)

	state: None None None None None None None None None 3 -> action:  visit 8
	state_p: None None None None None None None None 2 3 -> reward:  0.0
	target_q: 0.8294414922692686 index: 8
	q_values: [-0.0161713  -0.16341529  0.38501366 -0.89896362 -0.36531124  0.76209608
  0.20494755 -0.57898054  0.65622701 -2.47423317  0.02283647] (11,)
	target_qs: [-0.0161713  -0.16341529  0.38501366 -0.89896362 -0.36531124  0.76209608
  0.20494755 -0.57898054  0.82944149 -2.47423317  0.02283647] (11,)
	trained q_values: [-0.5518767  -0.80514081 -0.06094968 -1.34729483  0.15480736  1.02648665
  0.29771274 -0.70807425  4.53550939 -4.1632863   1.76165473] (11,)

	state: None None None None None None None None 2 3 -> action:  visit 2
	state_p: None None 2 None None None None None 2 3 -> reward:  0.0
	target_q: 1.3989697226719724 index: 2
	q_values: [-0.67676311 -0.96443184  0.24478685 -1.44878646  0.4425953   1.09708609
  0.12226205 -1.10194399  4.88952883 -4.67155002  1.8803412 ] (11,)
	target_qs: [-0.67676311 -0.96443184  1.39896972 -1.44878646  0.4425953   1.09708609
  0.12226205 -1.10194399  4.88952883 -4.67155002  1.8803412 ] (11,)
	trained q_values: [-1.12025059 -0.74960676  4.39255838 -2.19623265  0.12343171  0.99348022
 -0.55545673 -0.78676983  5.71981661 -5.8596707   1.9845333 ] (11,)

	state: None None 2 None None None None None 2 3 -> action:  visit 0
	state_p: 3 None 2 None None None None None 2 3 -> reward:  0.0
	target_q: 1.9867798792137485 index: 0
	q_values: [-0.88483059 -0.79487077  4.28403012 -1.84353231 -0.17759314  0.75683818
 -0.3826092  -0.70022004  5.42543873 -5.36662567  1.52439422] (11,)
	target_qs: [ 1.98677988 -0.79487077  4.28403012 -1.84353231 -0.17759314  0.75683818
 -0.3826092  -0.70022004  5.42543873 -5.36662567  1.52439422] (11,)
	trained q_values: [ 3.64567658 -0.52546028  5.74321621 -2.5911965  -0.10229355  0.27961343
 -0.10566968 -0.43135239  5.4904296  -5.34184976  0.71327578] (11,)

	state: 3 None 2 None None None None None 2 3 -> action:  visit 1
	state_p: 3 3 2 None None None None None 2 3 -> reward:  0.0
	target_q: 1.406227786305658 index: 1
	q_values: [ 3.11704653 -0.56600111  5.82093678 -2.63030817  0.09206018  0.2611135
 -0.28212359 -0.24358166  5.72130955 -5.34580126  1.22212089] (11,)
	target_qs: [ 3.11704653  1.40622779  5.82093678 -2.63030817  0.09206018  0.2611135
 -0.28212359 -0.24358166  5.72130955 -5.34580126  1.22212089] (11,)
	trained q_values: [ 6.16417674  3.62490607  6.93118583 -2.92085408  0.04864195 -0.02162166
 -0.6511534  -0.07011421  4.8807011  -4.85904332  0.33378715] (11,)

	state: 3 3 2 None None None None None 2 3 -> action:  visit 5
	state_p: 3 3 2 None None 2 None None 2 3 -> reward:  0.0
	target_q: 0.40756487590593904 index: 5
	q_values: [ 6.07990603  3.98333498  7.04824814 -2.91959474  0.28319108  0.06712002
 -1.06254138  0.02831307  4.82464089 -4.6408899   0.51776869] (11,)
	target_qs: [ 6.07990603  3.98333498  7.04824814 -2.91959474  0.28319108  0.40756488
 -1.06254138  0.02831307  4.82464089 -4.6408899   0.51776869] (11,)
	trained q_values: [ 8.54079186  7.78801449  8.0327619  -3.27224501  0.2561836   1.54733598
 -1.30892098  0.27048917  4.30310732 -4.39347503 -0.16623528] (11,)

	state: 3 3 2 None None 2 None None 2 3 -> action:  visit 4
	state_p: 3 3 2 None 2 2 None None 2 3 -> reward:  0.0
	target_q: 0.228991522483741 index: 4
	q_values: [ 9.2805132   8.17010495  8.33620313 -3.54326563 -0.01311102  1.8240448
 -1.36022545  0.16214083  4.57411963 -4.68584419 -0.30132359] (11,)
	target_qs: [ 9.2805132   8.17010495  8.33620313 -3.54326563  0.22899152  1.8240448
 -1.36022545  0.16214083  4.57411963 -4.68584419 -0.30132359] (11,)
	trained q_values: [11.51323287 11.72689128  9.23070037 -4.0396835   1.94942879  3.40599382
 -1.52964221  0.43370699  4.19416614 -4.6111436  -0.66114201] (11,)

	state: 3 3 2 None 2 2 None None 2 3 -> action:  evaluation
	state_p: None -> reward:  -1.0
	target_q: -1.0 index: -1
	q_values: [11.65897878 11.57539821  9.14203034 -4.09727349  1.89676603  3.30668926
 -1.36003442  0.50062239  3.97553012 -4.61757454 -0.667485  ] (11,)
	target_qs: [11.65897878 11.57539821  9.14203034 -4.09727349  1.89676603  3.30668926
 -1.36003442  0.50062239  3.97553012 -4.61757454 -1.        ] (11,)
	trained q_values: [13.6900519  14.68960621  9.74361731 -4.73963225  3.46214952  4.75963296
 -1.3072091   0.31054312  2.68046069 -3.90508299 -3.51921158] (11,)
epoch: 1 row: 1
	 ['visit 0', 'visit 1', 'visit 2', 'visit 5', 'visit 8', 'visit 4', 'visit 7', 'visit 6', 'evaluation']

	state: None None None None None None None None None None -> action:  visit 0
	state_p: 1 None None None None None None None None None -> reward:  0.0
	target_q: 8.216981889762883 index: 0
	q_values: [ 7.575297    6.77589541  6.89128253 -3.21024021  1.85619213  2.52750826
 -0.14925005  0.12902803  3.8950587  -5.72194684 -0.56537405] (11,)
	target_qs: [ 8.21698189  6.77589541  6.89128253 -3.21024021  1.85619213  2.52750826
 -0.14925005  0.12902803  3.8950587  -5.72194684 -0.56537405] (11,)
	trained q_values: [10.26324958  8.82827982  8.12019389 -3.92958235  2.76935013  3.35291238
 -0.13314962  0.23638404  3.94083436 -5.97021213 -1.7593306 ] (11,)

	state: 1 None None None None None None None None None -> action:  visit 1
	state_p: 1 1 None None None None None None None None -> reward:  0.0
	target_q: 8.479857662274226 index: 1
	q_values: [ 9.16187808 10.58120315  8.32784597 -3.9308412   3.05118358  4.07918654
 -0.66287033  0.39940129  3.82540785 -5.96859917 -1.57091635] (11,)
	target_qs: [ 9.16187808  8.47985766  8.32784597 -3.9308412   3.05118358  4.07918654
 -0.66287033  0.39940129  3.82540785 -5.96859917 -1.57091635] (11,)
	trained q_values: [ 8.4946196   7.748774    6.94729667 -3.63001578  3.09191743  3.97113439
 -0.24491667  0.12691841  3.30652576 -5.18217322 -1.96028199] (11,)

	state: 1 1 None None None None None None None None -> action:  visit 2
	state_p: 1 1 1 None None None None None None None -> reward:  0.0
	target_q: 4.92276584488734 index: 2
	q_values: [ 8.50346998  8.23030084  7.07310483 -3.79028713  3.88586275  5.04753926
 -0.52798071  0.16472875  3.09478035 -4.95380514 -2.40405631] (11,)
	target_qs: [ 8.50346998  8.23030084  4.92276584 -3.79028713  3.88586275  5.04753926
 -0.52798071  0.16472875  3.09478035 -4.95380514 -2.40405631] (11,)
	trained q_values: [ 4.90593394  4.33548592  2.57891767 -2.30964716  3.24438429  4.00813236
  0.14635503 -0.22884102  1.72925732 -3.05482555 -1.96834138] (11,)

	state: 1 1 1 None None None None None None None -> action:  visit 5
	state_p: 1 1 1 None None 1 None None None None -> reward:  0.0
	target_q: 3.9490088788970286 index: 5
	q_values: [ 5.90084475  5.14028589  0.96157877 -1.90615797  3.39550707  4.01853918
  0.4932206  -0.46608309  0.62447418 -1.84516514 -3.34903192] (11,)
	target_qs: [ 5.90084475  5.14028589  0.96157877 -1.90615797  3.39550707  3.94900888
  0.4932206  -0.46608309  0.62447418 -1.84516514 -3.34903192] (11,)
	trained q_values: [ 2.25322702  2.14604353 -2.45324134 -0.59507732  2.61750946  2.79102913
  0.94843779 -0.8178563  -0.57579721 -0.28382849 -2.76337416] (11,)

	state: 1 1 1 None None 1 None None None None -> action:  visit 8
	state_p: 1 1 1 None None 1 None None 1 None -> reward:  0.0
	target_q: 4.890663529957543 index: 8
	q_values: [ 3.3234928   2.36195265 -2.81944122 -0.88810628  3.24859588  3.20886483
  1.16629287 -1.1219369  -0.91292067 -0.06676697 -3.83811944] (11,)
	target_qs: [ 3.3234928   2.36195265 -2.81944122 -0.88810628  3.24859588  3.20886483
  1.16629287 -1.1219369   4.89066353 -0.06676697 -3.83811944] (11,)
	trained q_values: [ 3.62116074  1.12457494 -3.13623996 -1.38912881  3.54708916  3.70127473
  1.29071264 -1.4251657   3.59618138 -1.3126929  -2.49161211] (11,)

	state: 1 1 1 None None 1 None None 1 None -> action:  visit 4
	state_p: 1 1 1 None 1 1 None None 1 None -> reward:  0.0
	target_q: 1.466132310105606 index: 4
	q_values: [ 7.96086282  3.9479407  -1.98195584 -2.42914252  5.44666524  5.02476371
  1.22839384 -1.85655272  2.41640293 -1.09191864 -5.36570669] (11,)
	target_qs: [ 7.96086282  3.9479407  -1.98195584 -2.42914252  1.46613231  5.02476371
  1.22839384 -1.85655272  2.41640293 -1.09191864 -5.36570669] (11,)
	trained q_values: [ 5.15762376  1.65053796 -2.8183982  -1.72672689  1.52189059  4.43443309
  1.2456693  -2.2384119   5.09792457 -1.48817278 -3.69794919] (11,)

	state: 1 1 1 None 1 1 None None 1 None -> action:  visit 7
	state_p: 1 1 1 None 1 1 None 1 1 None -> reward:  0.0
	target_q: 1.7219880711162754 index: 7
	q_values: [ 5.58097011  1.80953368 -2.91229021 -1.78013881  1.28961068  4.40331396
  1.49633708 -2.38708846  4.4818223  -1.19351244 -4.71268672] (11,)
	target_qs: [ 5.58097011  1.80953368 -2.91229021 -1.78013881  1.28961068  4.40331396
  1.49633708  1.72198807  4.4818223  -1.19351244 -4.71268672] (11,)
	trained q_values: [ 3.80356848  0.54498688 -2.92656193 -1.52091769 -0.9572594   4.19705152
  1.80860947  0.30086242  5.99111224 -1.12777105 -2.92550594] (11,)

	state: 1 1 1 None 1 1 None 1 1 None -> action:  visit 6
	state_p: 1 1 1 None 1 1 1 1 1 None -> reward:  0.0
	target_q: -0.99 index: 6
	q_values: [ 4.1171679   0.77338213 -2.83590314 -1.46948029 -0.87522613  4.1922899
  2.05617093  0.30187396  5.9440376  -1.18578983 -2.97729447] (11,)
	target_qs: [ 4.1171679   0.77338213 -2.83590314 -1.46948029 -0.87522613  4.1922899
 -0.99        0.30187396  5.9440376  -1.18578983 -2.97729447] (11,)
	trained q_values: [ 2.10993732  0.23338898 -2.54963355 -0.95959026 -2.20333448  3.82207254
  0.15674706  1.76149692  6.547097   -0.52340271 -1.34275685] (11,)

	state: 1 1 1 None 1 1 1 1 1 None -> action:  evaluation
	state_p: None -> reward:  1.0
	target_q: 1.0 index: -1
	q_values: [ 1.96822526 -0.59187871 -2.68048473 -1.04391766 -2.30927347  3.63660582
  0.27674401  1.78396082  7.70981646 -1.5087405  -0.60843781] (11,)
	target_qs: [ 1.96822526 -0.59187871 -2.68048473 -1.04391766 -2.30927347  3.63660582
  0.27674401  1.78396082  7.70981646 -1.5087405   1.        ] (11,)
	trained q_values: [-2.61945027 -2.10161182 -3.02428819  0.20308318 -2.75409991  2.45264684
 -1.23918723  2.39555686  7.71372501 -0.91226275  3.07876317] (11,)
[[38  8 16]
 [10  8 22]
 [15  9 21]]
[[38  8 16]
 [10  8 22]
 [16  8 21]]
[[37  8 17]
 [11  8 21]
 [12  8 25]]
(0.4557823129251701, 0.42636893552147787, 0.4265232974910395, 0.41933333333333334)
(0.4557823129251701, 0.4276718455743879, 0.4265232974910395, 0.419006919006919)
(0.47619047619047616, 0.4489417989417989, 0.45077658303464757, 0.4398401133373811)
