{'dataset': 'lymphography', 'algorithm': 'ptdqn', 'num_clf': 50, 'num_training': 500000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 6335, 'portion': 0.5, 'sequential': False}
(148, 39)
reading data takes 0.450 sec
number of labels: 4

Running iteration 1 of 10 fold...
[27, 0, 2, 10, 49, 1, 16, 4, 21, 8]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.761194, 0.729438, 0.857143, 0.738619

    accuracy, precision, recall, f_score
max3: 0.696970, 0.680441, 0.704762, 0.690476

    accuracy, precision, recall, f_score
max1: 0.800000, 0.748148, 0.854167, 0.828431


min loss: 0.006, episode: 265000
max accu: 0.800, episode: 480000

2.47 classifiers used
    accuracy, precision, recall, f_score
mv: 0.800000, 0.748148, 0.854167, 0.828431
wv: 0.800000, 0.748148, 0.854167, 0.828431
fs: 0.800000, 0.787879, 0.833333, 0.821053
rl: 0.800000, 0.748148, 0.854167, 0.828431

0.6576119402985074
0.67, 0.67, 0.74, 0.64, 0.68, 0.58, 0.55, 0.56, 0.65, 0.65, 0.70, 0.74, 0.70, 0.58, 0.64, 0.55, 0.70, 0.67, 0.67, 0.55, 0.67, 0.67, 0.73, 0.65, 0.58, 0.65, 0.73, 0.77, 0.61, 0.53, 0.61, 0.65, 0.67, 0.67, 0.64, 0.71, 0.65, 0.67, 0.68, 0.62, 0.70, 0.58, 0.77, 0.70, 0.68, 0.61, 0.70, 0.58, 0.73, 0.61

0.6018181818181818
0.51, 0.63, 0.69, 0.60, 0.66, 0.51, 0.45, 0.45, 0.60, 0.54, 0.54, 0.72, 0.60, 0.45, 0.66, 0.51, 0.60, 0.66, 0.57, 0.42, 0.66, 0.63, 0.66, 0.54, 0.48, 0.66, 0.69, 0.72, 0.51, 0.48, 0.57, 0.63, 0.57, 0.69, 0.57, 0.63, 0.66, 0.63, 0.69, 0.60, 0.69, 0.54, 0.72, 0.63, 0.57, 0.60, 0.69, 0.48, 0.66, 0.57

0.6386666666666667
0.8, 0.66, 0.73, 0.8, 0.66, 0.46, 0.66, 0.46, 0.46, 0.73, 0.73, 0.6, 0.6, 0.46, 0.66, 0.53, 0.6, 0.66, 0.73, 0.6, 0.6, 0.8, 0.66, 0.53, 0.53, 0.66, 0.66, 0.73, 0.66, 0.66, 0.53, 0.53, 0.73, 0.6, 0.73, 0.66, 0.53, 0.73, 0.66, 0.73, 0.66, 0.46, 0.8, 0.6, 0.66, 0.6, 0.6, 0.6, 0.6, 0.66

0.7280000000000001
0.66, 0.8, 0.8, 0.66, 0.73, 0.8, 0.86, 0.73, 0.73, 0.6, 0.8, 0.53, 0.6, 0.8, 0.73, 0.73, 0.8, 0.8, 0.8, 0.93, 0.8, 0.6, 0.8, 0.8, 0.66, 0.8, 0.86, 0.6, 0.6, 0.6, 0.66, 0.66, 0.6, 0.8, 0.66, 0.73, 0.73, 0.73, 0.66, 0.66, 0.73, 0.86, 0.53, 0.73, 0.73, 0.73, 0.66, 0.86, 0.66, 0.86


Running iteration 2 of 10 fold...
[3, 0]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.716418, 0.673641, 0.762121, 0.738615

    accuracy, precision, recall, f_score
max3: 0.575758, 0.555556, 0.615546, 0.593750

    accuracy, precision, recall, f_score
max1: 1.000000, 1.000000, 1.000000, 1.000000


min loss: 0.008, episode: 219000
max accu: 1.000, episode: 400000

4.13 classifiers used
    accuracy, precision, recall, f_score
mv: 0.866667, 0.893333, 0.857143, 0.861111
wv: 0.866667, 0.893333, 0.857143, 0.861111
fs: 0.933333, 0.940741, 0.928571, 0.932127
rl: 1.000000, 1.000000, 1.000000, 1.000000

0.6432835820895523
0.59, 0.67, 0.56, 0.76, 0.64, 0.67, 0.50, 0.59, 0.70, 0.61, 0.65, 0.59, 0.61, 0.59, 0.71, 0.65, 0.55, 0.67, 0.62, 0.62, 0.68, 0.67, 0.47, 0.61, 0.55, 0.73, 0.67, 0.71, 0.76, 0.67, 0.70, 0.55, 0.64, 0.65, 0.62, 0.64, 0.62, 0.74, 0.65, 0.67, 0.68, 0.65, 0.64, 0.58, 0.70, 0.58, 0.62, 0.61, 0.74, 0.61

0.6096969696969697
0.60, 0.54, 0.57, 0.75, 0.54, 0.60, 0.48, 0.57, 0.66, 0.48, 0.66, 0.60, 0.51, 0.60, 0.60, 0.60, 0.45, 0.57, 0.60, 0.63, 0.69, 0.54, 0.42, 0.60, 0.57, 0.69, 0.63, 0.75, 0.72, 0.60, 0.66, 0.54, 0.69, 0.66, 0.57, 0.60, 0.60, 0.72, 0.60, 0.66, 0.75, 0.60, 0.60, 0.54, 0.66, 0.63, 0.45, 0.57, 0.63, 0.63

0.7319999999999999
0.8, 1.0, 0.73, 0.93, 0.6, 0.8, 0.6, 0.8, 0.93, 0.86, 0.6, 0.8, 0.8, 0.46, 0.93, 0.86, 0.6, 0.6, 0.46, 0.93, 0.8, 0.73, 0.66, 0.73, 0.73, 0.8, 0.93, 0.73, 0.86, 0.93, 0.6, 0.73, 0.53, 0.73, 0.4, 0.73, 0.66, 0.93, 0.53, 0.6, 0.6, 0.73, 0.73, 0.46, 0.86, 0.73, 0.8, 0.66, 0.93, 0.53

0.7533333333333333
0.8, 0.8, 0.73, 0.73, 0.53, 0.73, 0.73, 0.4, 0.6, 0.66, 0.93, 0.93, 0.8, 0.86, 0.86, 0.86, 0.66, 0.73, 0.93, 0.73, 0.66, 0.66, 0.6, 1.0, 0.93, 0.73, 0.8, 0.73, 0.6, 0.86, 0.8, 0.8, 0.86, 0.73, 0.8, 0.6, 0.46, 0.86, 0.66, 0.73, 0.73, 0.73, 0.8, 0.66, 0.73, 0.86, 0.8, 0.6, 0.93, 0.8


Running iteration 3 of 10 fold...
[48, 0, 39, 1, 16, 46, 38, 4]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.776119, 0.755416, 0.800663, 0.787684

    accuracy, precision, recall, f_score
max3: 0.757576, 0.752563, 0.786275, 0.769450

    accuracy, precision, recall, f_score
max1: 0.800000, 0.700000, 0.928571, 0.857143


min loss: 0.007, episode: 229000
max accu: 0.800, episode: 460000

2.33 classifiers used
    accuracy, precision, recall, f_score
mv: 0.733333, 0.840000, 0.690476, 0.714646
wv: 0.733333, 0.840000, 0.690476, 0.714646
fs: 0.800000, 0.733333, 0.928571, 0.861538
rl: 0.800000, 0.700000, 0.928571, 0.857143

0.6701492537313434
0.62, 0.77, 0.61, 0.47, 0.62, 0.68, 0.70, 0.77, 0.62, 0.70, 0.64, 0.73, 0.73, 0.65, 0.62, 0.62, 0.70, 0.71, 0.61, 0.59, 0.68, 0.71, 0.64, 0.65, 0.67, 0.59, 0.71, 0.61, 0.70, 0.68, 0.53, 0.68, 0.71, 0.61, 0.67, 0.68, 0.68, 0.67, 0.68, 0.79, 0.76, 0.59, 0.64, 0.65, 0.70, 0.65, 0.61, 0.61, 0.82, 0.76

0.6072727272727272
0.51, 0.72, 0.54, 0.51, 0.57, 0.60, 0.63, 0.66, 0.63, 0.60, 0.51, 0.72, 0.54, 0.57, 0.48, 0.60, 0.69, 0.66, 0.57, 0.63, 0.57, 0.66, 0.48, 0.54, 0.60, 0.45, 0.72, 0.66, 0.57, 0.60, 0.54, 0.60, 0.60, 0.51, 0.63, 0.57, 0.63, 0.54, 0.57, 0.72, 0.63, 0.60, 0.57, 0.63, 0.81, 0.60, 0.60, 0.48, 0.75, 0.69

0.6133333333333334
0.86, 0.53, 0.53, 0.46, 0.73, 0.73, 0.8, 0.6, 0.53, 0.6, 0.66, 0.66, 0.6, 0.8, 0.66, 0.73, 0.93, 0.33, 0.6, 0.6, 0.53, 0.46, 0.53, 0.6, 0.6, 0.6, 0.53, 0.53, 0.6, 0.53, 0.46, 0.53, 0.73, 0.6, 0.46, 0.66, 0.46, 0.53, 0.8, 0.6, 0.6, 0.53, 0.33, 0.66, 0.8, 0.6, 0.6, 0.6, 0.73, 0.8

0.6519999999999999
0.6, 0.73, 0.66, 0.73, 0.53, 0.93, 0.53, 0.73, 0.66, 0.8, 0.73, 0.53, 0.73, 0.66, 0.8, 0.6, 0.6, 0.46, 0.6, 0.53, 0.73, 0.66, 0.6, 0.66, 0.53, 0.6, 0.66, 0.66, 0.8, 0.66, 0.73, 0.66, 0.66, 0.6, 0.66, 0.4, 0.6, 0.53, 0.66, 0.53, 0.73, 0.6, 0.8, 0.73, 0.73, 0.66, 0.73, 0.46, 0.6, 0.66


Running iteration 4 of 10 fold...
[15, 0, 22, 37]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.761194, 0.742249, 0.854167, 0.845569

    accuracy, precision, recall, f_score
max3: 0.666667, 0.645022, 0.714583, 0.682540

    accuracy, precision, recall, f_score
max1: 1.000000, 1.000000, 1.000000, 1.000000


min loss: 0.008, episode: 231000
max accu: 1.000, episode: 470000

3.13 classifiers used
    accuracy, precision, recall, f_score
mv: 1.000000, 1.000000, 1.000000, 1.000000
wv: 0.933333, 0.939394, 0.900000, 0.920635
fs: 0.800000, 0.795455, 0.750000, 0.761905
rl: 1.000000, 1.000000, 1.000000, 1.000000

0.66
0.62, 0.71, 0.68, 0.70, 0.65, 0.55, 0.59, 0.65, 0.73, 0.67, 0.68, 0.68, 0.62, 0.71, 0.64, 0.74, 0.73, 0.62, 0.67, 0.70, 0.65, 0.67, 0.70, 0.67, 0.73, 0.68, 0.62, 0.52, 0.59, 0.61, 0.55, 0.67, 0.58, 0.74, 0.65, 0.68, 0.64, 0.58, 0.74, 0.67, 0.68, 0.62, 0.73, 0.62, 0.74, 0.58, 0.59, 0.70, 0.59, 0.65

0.6066666666666667
0.60, 0.63, 0.69, 0.63, 0.72, 0.45, 0.39, 0.63, 0.66, 0.69, 0.57, 0.63, 0.45, 0.66, 0.51, 0.66, 0.66, 0.51, 0.66, 0.60, 0.57, 0.60, 0.75, 0.63, 0.66, 0.60, 0.54, 0.45, 0.51, 0.60, 0.54, 0.60, 0.51, 0.72, 0.57, 0.63, 0.66, 0.51, 0.66, 0.63, 0.66, 0.54, 0.69, 0.51, 0.72, 0.63, 0.48, 0.66, 0.57, 0.63

0.7506666666666666
0.86, 0.8, 0.6, 0.53, 0.73, 0.73, 0.73, 0.73, 0.8, 0.66, 0.8, 0.8, 0.8, 0.8, 0.73, 0.73, 0.73, 0.86, 0.8, 0.53, 0.8, 0.8, 0.8, 0.6, 0.8, 0.73, 0.73, 0.93, 0.73, 0.66, 0.6, 0.73, 0.8, 0.86, 0.6, 0.66, 0.8, 0.6, 0.86, 0.73, 0.8, 0.86, 0.66, 0.8, 0.8, 0.8, 0.73, 0.8, 0.8, 0.8

0.8013333333333331
0.6, 0.86, 0.73, 0.8, 0.73, 0.93, 0.8, 0.66, 0.73, 0.8, 0.8, 0.86, 0.73, 0.53, 0.8, 0.93, 0.93, 0.8, 0.86, 0.73, 0.8, 0.8, 0.86, 0.8, 0.8, 1.0, 0.8, 0.8, 0.8, 0.8, 0.8, 0.86, 0.86, 0.8, 0.93, 0.73, 0.66, 0.73, 0.6, 1.0, 0.73, 0.86, 0.86, 0.66, 0.8, 0.93, 0.73, 0.8, 0.93, 0.8


Running iteration 5 of 10 fold...
[5, 0, 16, 7, 13, 3, 19]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.746269, 0.747933, 0.680624, 0.724747

    accuracy, precision, recall, f_score
max3: 0.636364, 0.672963, 0.600000, 0.641975

    accuracy, precision, recall, f_score
max1: 0.800000, 0.866667, 0.833333, 0.800000


min loss: 0.008, episode: 211000
max accu: 0.800, episode: 450000

1.93 classifiers used
    accuracy, precision, recall, f_score
mv: 0.800000, 0.866667, 0.833333, 0.800000
wv: 0.800000, 0.866667, 0.833333, 0.800000
fs: 0.666667, 0.818182, 0.722222, 0.660633
rl: 0.800000, 0.866667, 0.833333, 0.800000

0.6826865671641792
0.62, 0.68, 0.68, 0.67, 0.73, 0.77, 0.61, 0.62, 0.61, 0.58, 0.68, 0.67, 0.68, 0.74, 0.65, 0.71, 0.68, 0.71, 0.73, 0.62, 0.70, 0.61, 0.73, 0.70, 0.76, 0.71, 0.67, 0.70, 0.65, 0.64, 0.71, 0.76, 0.64, 0.68, 0.68, 0.71, 0.64, 0.70, 0.68, 0.71, 0.73, 0.59, 0.67, 0.71, 0.65, 0.70, 0.71, 0.67, 0.64, 0.64

0.6284848484848484
0.57, 0.60, 0.57, 0.66, 0.69, 0.75, 0.63, 0.57, 0.63, 0.54, 0.63, 0.60, 0.72, 0.63, 0.57, 0.66, 0.63, 0.60, 0.72, 0.54, 0.72, 0.51, 0.72, 0.69, 0.69, 0.69, 0.63, 0.63, 0.57, 0.60, 0.60, 0.75, 0.57, 0.60, 0.63, 0.69, 0.57, 0.57, 0.60, 0.57, 0.75, 0.48, 0.66, 0.60, 0.54, 0.60, 0.72, 0.66, 0.54, 0.45

0.6986666666666668
0.26, 0.8, 0.66, 0.53, 0.86, 0.86, 0.46, 0.46, 0.66, 0.8, 0.66, 0.8, 0.73, 0.8, 0.86, 0.6, 0.4, 0.8, 0.86, 0.73, 0.66, 0.66, 0.73, 0.73, 0.8, 0.73, 0.6, 0.73, 0.73, 0.6, 0.6, 0.73, 0.8, 0.66, 0.73, 0.73, 0.73, 0.66, 0.6, 0.8, 0.6, 0.73, 0.73, 0.66, 0.66, 0.8, 0.73, 0.53, 0.73, 1.0

0.7813333333333332
0.86, 0.66, 1.0, 0.8, 0.66, 0.93, 0.66, 0.73, 0.93, 0.86, 0.73, 0.8, 0.8, 0.8, 0.73, 0.73, 0.66, 0.86, 0.73, 0.8, 0.73, 0.6, 0.86, 0.8, 0.8, 0.8, 0.73, 0.8, 0.8, 0.8, 0.8, 0.73, 0.73, 0.66, 0.8, 0.8, 0.6, 0.8, 0.86, 0.8, 0.8, 0.8, 0.73, 0.8, 0.66, 0.8, 0.86, 0.73, 0.86, 0.86


Running iteration 6 of 10 fold...
[28, 0, 30, 12, 39, 4, 3, 2, 6, 1, 11, 5]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.850746, 0.863184, 0.734921, 0.788199

    accuracy, precision, recall, f_score
max3: 0.848485, 0.865152, 0.744444, 0.790123

    accuracy, precision, recall, f_score
max1: 1.000000, 1.000000, 1.000000, 1.000000


min loss: 0.006, episode: 287000
max accu: 1.000, episode: 500000

7.20 classifiers used
    accuracy, precision, recall, f_score
mv: 0.933333, 0.874074, 1.000000, 0.970588
wv: 0.933333, 0.874074, 1.000000, 0.970588
fs: 0.666667, 0.622222, 0.708333, 0.686275
rl: 1.000000, 1.000000, 1.000000, 1.000000

0.713731343283582
0.76, 0.65, 0.68, 0.71, 0.74, 0.62, 0.68, 0.65, 0.64, 0.68, 0.74, 0.79, 0.74, 0.71, 0.71, 0.64, 0.68, 0.62, 0.68, 0.70, 0.74, 0.73, 0.80, 0.80, 0.71, 0.76, 0.70, 0.70, 0.86, 0.71, 0.73, 0.80, 0.76, 0.71, 0.74, 0.59, 0.64, 0.68, 0.67, 0.64, 0.61, 0.70, 0.67, 0.82, 0.76, 0.65, 0.77, 0.74, 0.71, 0.74

0.6478787878787878
0.75, 0.48, 0.66, 0.66, 0.72, 0.54, 0.63, 0.54, 0.54, 0.63, 0.66, 0.75, 0.63, 0.66, 0.63, 0.60, 0.57, 0.54, 0.63, 0.69, 0.60, 0.63, 0.72, 0.75, 0.69, 0.69, 0.63, 0.63, 0.81, 0.63, 0.69, 0.72, 0.75, 0.60, 0.69, 0.51, 0.51, 0.51, 0.60, 0.60, 0.48, 0.60, 0.63, 0.78, 0.72, 0.69, 0.69, 0.75, 0.63, 0.63

0.7026666666666667
0.46, 0.66, 0.53, 0.73, 0.53, 0.6, 0.73, 0.66, 0.8, 0.8, 0.66, 0.66, 0.53, 0.66, 0.8, 0.66, 0.6, 0.8, 0.86, 0.8, 0.73, 0.73, 0.73, 0.8, 0.73, 0.86, 0.73, 0.73, 0.8, 0.66, 0.73, 0.73, 0.66, 0.73, 0.46, 0.73, 0.8, 0.86, 0.8, 0.53, 0.73, 0.66, 0.73, 0.8, 0.66, 0.6, 0.73, 0.73, 0.6, 0.66

0.7239999999999999
0.93, 0.53, 0.53, 0.6, 0.4, 0.73, 0.66, 0.53, 0.6, 0.8, 0.73, 0.73, 0.73, 0.66, 0.53, 0.86, 0.53, 0.53, 0.8, 0.86, 0.8, 0.73, 0.73, 0.93, 0.73, 0.93, 0.6, 0.8, 0.6, 0.8, 0.73, 0.86, 0.8, 0.8, 0.93, 0.8, 0.66, 0.8, 0.66, 0.8, 0.8, 0.73, 0.73, 0.86, 0.53, 0.8, 0.86, 0.6, 0.8, 0.6


Running iteration 7 of 10 fold...
[8, 0, 21, 3, 11, 5, 10, 14, 9, 6, 26, 19, 22, 25, 12, 15, 1, 30, 2, 35, 7, 16, 13, 39, 4]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.805970, 0.792040, 0.823810, 0.815584

    accuracy, precision, recall, f_score
max3: 0.878788, 0.827751, 0.934874, 0.908730

    accuracy, precision, recall, f_score
max1: 0.933333, 0.938889, 0.875000, 0.906832


min loss: 0.007, episode: 245000
max accu: 0.933, episode: 210000

2.00 classifiers used
    accuracy, precision, recall, f_score
mv: 0.733333, 0.785185, 0.738636, 0.700000
wv: 0.733333, 0.785185, 0.738636, 0.700000
fs: 0.866667, 0.911111, 0.909091, 0.850000
rl: 0.933333, 0.938889, 0.875000, 0.906832

0.7292537313432835
0.68, 0.70, 0.76, 0.71, 0.67, 0.76, 0.73, 0.70, 0.86, 0.70, 0.68, 0.76, 0.73, 0.71, 0.65, 0.80, 0.68, 0.70, 0.76, 0.74, 0.68, 0.82, 0.82, 0.83, 0.74, 0.77, 0.73, 0.65, 0.73, 0.76, 0.76, 0.79, 0.70, 0.65, 0.70, 0.73, 0.65, 0.74, 0.74, 0.83, 0.73, 0.82, 0.65, 0.74, 0.58, 0.73, 0.70, 0.68, 0.62, 0.73

0.6666666666666667
0.66, 0.63, 0.69, 0.60, 0.57, 0.72, 0.60, 0.66, 0.78, 0.66, 0.54, 0.75, 0.60, 0.63, 0.54, 0.75, 0.66, 0.63, 0.69, 0.63, 0.69, 0.72, 0.75, 0.78, 0.72, 0.63, 0.66, 0.60, 0.69, 0.69, 0.69, 0.69, 0.75, 0.57, 0.63, 0.57, 0.57, 0.72, 0.72, 0.78, 0.69, 0.75, 0.72, 0.69, 0.48, 0.66, 0.63, 0.69, 0.45, 0.63

0.7293333333333334
0.6, 0.8, 0.8, 0.73, 0.8, 0.73, 0.53, 0.73, 0.8, 0.6, 0.6, 0.66, 0.73, 1.0, 0.66, 0.8, 0.73, 0.86, 0.73, 0.73, 0.86, 0.8, 0.8, 0.66, 0.73, 0.53, 0.66, 0.8, 0.73, 0.66, 0.8, 0.8, 0.8, 0.73, 0.73, 0.73, 0.86, 0.73, 0.73, 0.8, 0.73, 0.8, 0.8, 0.73, 0.4, 0.66, 0.8, 0.73, 0.46, 0.66

0.7066666666666666
0.6, 0.46, 0.6, 0.66, 0.73, 0.73, 0.86, 0.73, 0.93, 0.8, 0.86, 0.53, 0.86, 0.86, 0.66, 0.66, 0.86, 0.73, 0.86, 0.6, 0.73, 0.73, 0.73, 0.6, 0.73, 0.73, 0.6, 0.4, 0.73, 0.66, 0.6, 0.66, 0.73, 0.73, 0.6, 0.8, 0.53, 0.8, 0.8, 0.86, 0.73, 0.53, 0.73, 0.66, 0.6, 0.73, 0.8, 0.6, 0.66, 0.8


Running iteration 8 of 10 fold...
[8, 0, 46, 26, 38, 22, 4]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.791045, 0.792617, 0.690708, 0.744293

    accuracy, precision, recall, f_score
max3: 0.696970, 0.716210, 0.634503, 0.679603

    accuracy, precision, recall, f_score
max1: 0.866667, 0.900000, 0.888889, 0.866071


min loss: 0.005, episode: 282000
max accu: 0.867, episode: 460000

6.00 classifiers used
    accuracy, precision, recall, f_score
mv: 0.866667, 0.900000, 0.888889, 0.866071
wv: 0.866667, 0.900000, 0.888889, 0.866071
fs: 0.800000, 0.810714, 0.805556, 0.796380
rl: 0.866667, 0.900000, 0.888889, 0.866071

0.7011940298507463
0.74, 0.61, 0.70, 0.70, 0.71, 0.65, 0.74, 0.79, 0.83, 0.62, 0.79, 0.67, 0.77, 0.53, 0.67, 0.70, 0.62, 0.73, 0.77, 0.79, 0.67, 0.71, 0.79, 0.64, 0.68, 0.76, 0.70, 0.79, 0.70, 0.56, 0.71, 0.68, 0.79, 0.73, 0.68, 0.65, 0.56, 0.61, 0.77, 0.71, 0.61, 0.64, 0.70, 0.70, 0.73, 0.67, 0.80, 0.68, 0.67, 0.65

0.6333333333333333
0.75, 0.66, 0.69, 0.54, 0.63, 0.57, 0.72, 0.75, 0.75, 0.57, 0.66, 0.57, 0.72, 0.45, 0.57, 0.60, 0.48, 0.54, 0.75, 0.69, 0.69, 0.69, 0.69, 0.57, 0.54, 0.69, 0.66, 0.78, 0.66, 0.54, 0.63, 0.48, 0.66, 0.66, 0.66, 0.60, 0.51, 0.72, 0.69, 0.51, 0.57, 0.54, 0.63, 0.54, 0.54, 0.60, 0.84, 0.66, 0.63, 0.51

0.708
0.93, 0.53, 0.73, 0.66, 0.86, 0.53, 0.73, 0.66, 0.73, 0.66, 0.93, 0.66, 1.0, 0.53, 0.6, 0.86, 0.6, 0.93, 0.73, 0.8, 0.53, 0.73, 0.73, 0.6, 0.73, 0.73, 0.66, 0.8, 0.73, 0.6, 0.73, 0.53, 0.93, 0.46, 0.53, 0.8, 0.66, 0.6, 0.66, 0.8, 0.73, 0.73, 0.8, 0.8, 0.66, 0.66, 0.6, 0.66, 0.66, 0.73

0.7519999999999999
0.8, 0.73, 0.8, 0.8, 0.8, 0.66, 0.8, 0.8, 0.66, 0.86, 0.66, 0.86, 0.66, 0.86, 0.8, 0.53, 0.8, 0.73, 0.86, 0.86, 0.93, 0.8, 0.73, 0.73, 0.8, 0.66, 0.6, 0.6, 0.6, 0.66, 0.73, 0.8, 0.6, 0.73, 0.8, 0.8, 0.6, 0.66, 0.66, 0.6, 0.6, 0.86, 0.86, 0.86, 0.93, 0.73, 0.73, 0.86, 0.8, 0.8


Running iteration 9 of 10 fold...
[3, 0, 13, 12, 19, 1]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.805970, 0.796384, 0.799812, 0.799378

    accuracy, precision, recall, f_score
max3: 0.787879, 0.762704, 0.801587, 0.791423

    accuracy, precision, recall, f_score
max1: 0.928571, 0.942857, 0.950000, 0.918129


min loss: 0.006, episode: 279000
max accu: 0.929, episode: 390000

7.00 classifiers used
    accuracy, precision, recall, f_score
mv: 1.000000, 1.000000, 1.000000, 1.000000
wv: 1.000000, 1.000000, 1.000000, 1.000000
fs: 0.785714, 0.877551, 0.850000, 0.775401
rl: 0.928571, 0.942857, 0.950000, 0.918129

0.72
0.77, 0.73, 0.70, 0.82, 0.68, 0.61, 0.67, 0.67, 0.80, 0.67, 0.70, 0.58, 0.62, 0.80, 0.77, 0.79, 0.74, 0.71, 0.61, 0.73, 0.67, 0.67, 0.79, 0.59, 0.67, 0.71, 0.71, 0.64, 0.77, 0.79, 0.76, 0.70, 0.79, 0.73, 0.79, 0.65, 0.70, 0.65, 0.79, 0.77, 0.71, 0.68, 0.76, 0.70, 0.76, 0.76, 0.68, 0.77, 0.71, 0.79

0.6733333333333333
0.75, 0.69, 0.63, 0.78, 0.72, 0.66, 0.72, 0.57, 0.69, 0.72, 0.60, 0.45, 0.60, 0.69, 0.78, 0.75, 0.69, 0.66, 0.48, 0.63, 0.57, 0.69, 0.72, 0.54, 0.63, 0.66, 0.66, 0.60, 0.78, 0.69, 0.72, 0.63, 0.75, 0.66, 0.72, 0.54, 0.63, 0.48, 0.81, 0.69, 0.69, 0.66, 0.66, 0.69, 0.63, 0.75, 0.66, 0.78, 0.66, 0.72

0.79
0.78, 0.92, 0.85, 0.64, 0.92, 0.71, 0.78, 0.64, 0.78, 0.71, 0.71, 0.78, 0.64, 0.78, 0.78, 0.92, 0.92, 0.71, 0.85, 0.78, 0.71, 0.71, 0.92, 0.71, 0.71, 0.92, 0.71, 0.85, 0.92, 0.71, 0.71, 0.78, 0.92, 0.92, 0.71, 0.57, 0.85, 0.71, 0.71, 0.78, 0.85, 0.71, 0.85, 0.78, 0.78, 0.78, 0.92, 0.85, 0.85, 0.71

0.8014285714285715
0.78, 0.57, 0.85, 0.64, 0.85, 0.92, 0.71, 0.71, 0.71, 0.92, 0.57, 0.85, 0.85, 0.71, 1.0, 1.0, 0.92, 0.64, 0.57, 0.57, 0.85, 0.92, 0.71, 1.0, 0.78, 0.92, 0.71, 0.57, 0.78, 0.85, 0.85, 0.85, 0.71, 1.0, 0.92, 0.92, 0.78, 0.92, 0.78, 0.64, 0.85, 0.92, 0.71, 0.85, 0.78, 0.64, 0.64, 1.0, 0.64, 1.0


Running iteration 10 of 10 fold...
[32, 0, 12, 17, 6, 39]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.776119, 0.764421, 0.786111, 0.780594

    accuracy, precision, recall, f_score
max3: 0.727273, 0.705882, 0.750000, 0.738636

    accuracy, precision, recall, f_score
max1: 0.714286, 0.714286, 0.812500, 0.812500


min loss: 0.006, episode: 285000
max accu: 0.714, episode: 490000

4.00 classifiers used
    accuracy, precision, recall, f_score
mv: 0.714286, 0.658730, 0.791667, 0.774510
wv: 0.714286, 0.658730, 0.791667, 0.774510
fs: 0.642857, 0.595238, 0.750000, 0.735294
rl: 0.714286, 0.714286, 0.812500, 0.812500

0.7223880597014926
0.61, 0.61, 0.62, 0.74, 0.71, 0.70, 0.67, 0.79, 0.73, 0.80, 0.67, 0.79, 0.79, 0.80, 0.77, 0.67, 0.80, 0.74, 0.79, 0.76, 0.53, 0.74, 0.80, 0.73, 0.67, 0.79, 0.70, 0.83, 0.73, 0.79, 0.64, 0.83, 0.88, 0.64, 0.70, 0.65, 0.74, 0.67, 0.80, 0.68, 0.61, 0.71, 0.68, 0.68, 0.62, 0.62, 0.74, 0.73, 0.70, 0.74

0.6818181818181815
0.54, 0.60, 0.63, 0.72, 0.66, 0.63, 0.63, 0.75, 0.66, 0.81, 0.63, 0.72, 0.75, 0.75, 0.72, 0.60, 0.75, 0.75, 0.72, 0.72, 0.51, 0.69, 0.78, 0.75, 0.57, 0.72, 0.57, 0.78, 0.75, 0.72, 0.60, 0.72, 0.87, 0.60, 0.66, 0.63, 0.63, 0.66, 0.75, 0.66, 0.45, 0.69, 0.69, 0.66, 0.51, 0.63, 0.75, 0.69, 0.63, 0.69

0.5614285714285715
0.5, 0.57, 0.71, 0.5, 0.5, 0.5, 0.64, 0.57, 0.57, 0.57, 0.42, 0.71, 0.64, 0.57, 0.64, 0.42, 0.5, 0.57, 0.57, 0.57, 0.28, 0.78, 0.57, 0.57, 0.57, 0.42, 0.5, 0.5, 0.35, 0.42, 0.85, 0.64, 0.57, 0.57, 0.57, 0.57, 0.64, 0.64, 0.64, 0.57, 0.28, 0.57, 0.57, 0.5, 0.64, 0.5, 0.71, 0.5, 0.57, 0.64

0.59
0.5, 0.64, 0.64, 0.57, 0.5, 0.64, 0.5, 0.57, 0.5, 0.57, 0.57, 0.64, 0.57, 0.42, 0.42, 0.57, 0.5, 0.57, 0.78, 0.5, 0.71, 0.5, 0.64, 0.5, 0.64, 0.5, 0.78, 0.78, 0.64, 0.5, 0.57, 0.71, 0.71, 0.71, 0.64, 0.57, 0.64, 0.42, 0.64, 0.78, 0.42, 0.5, 0.57, 0.57, 0.64, 0.42, 0.64, 0.64, 0.5, 0.71

    accuracy, precision, recall, f_score
mv: 0.844762, 0.856614, 0.865431, 0.851536
wv: 0.838095, 0.850553, 0.855431, 0.843599
fs: 0.776190, 0.789243, 0.818568, 0.788061
rl: 0.884286, 0.881085, 0.914246, 0.898911

fs avg size: 8.70000, rl avg size: 4.02000
full test avg accu: 0.72901, test avg accu: 0.69248

training takes 47912.310 sec
