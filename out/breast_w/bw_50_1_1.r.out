{'dataset': 'breast_w', 'algorithm': 'ptdqn', 'num_clf': 50, 'num_training': 400000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 941, 'portion': 0.5, 'sequential': False}
(699, 10)
reading data takes 0.501 sec
number of labels: 2

Running iteration 1 of 10 fold...
[20, 0, 32, 3, 8, 4]
using cpu
using cpu
    accuracy, precision, recall, f_score
mdl1: 0.985714, 0.986000, 0.976190, 0.982754

    accuracy, precision, recall, f_score
max3: 0.942675, 0.943018, 0.938226, 0.936205

    accuracy, precision, recall, f_score
max1: 0.942857, 0.947170, 0.904762, 0.927761


min loss: 0.008, episode: 270000
max accu: 0.943, episode: 30000

1.00 classifiers used
    accuracy, precision, recall, f_score
mv: 0.971429, 0.972549, 0.952381, 0.965000
wv: 0.971429, 0.972549, 0.952381, 0.965000
fs: 0.914286, 0.923636, 0.857143, 0.887821
rl: 0.942857, 0.947170, 0.904762, 0.927761

0.9215238095238095
0.93, 0.90, 0.92, 0.93, 0.88, 0.94, 0.93, 0.93, 0.90, 0.92, 0.92, 0.93, 0.93, 0.91, 0.92, 0.93, 0.91, 0.88, 0.90, 0.92, 0.94, 0.91, 0.90, 0.92, 0.93, 0.92, 0.88, 0.93, 0.91, 0.91, 0.92, 0.91, 0.92, 0.93, 0.92, 0.92, 0.92, 0.93, 0.89, 0.92, 0.92, 0.93, 0.92, 0.91, 0.92, 0.92, 0.92, 0.92, 0.92, 0.93

0.9155414012738854
0.92, 0.90, 0.91, 0.92, 0.85, 0.95, 0.92, 0.94, 0.91, 0.91, 0.91, 0.92, 0.91, 0.91, 0.92, 0.92, 0.89, 0.86, 0.91, 0.92, 0.93, 0.90, 0.91, 0.94, 0.92, 0.90, 0.87, 0.93, 0.88, 0.89, 0.91, 0.89, 0.92, 0.92, 0.92, 0.91, 0.92, 0.92, 0.89, 0.93, 0.92, 0.92, 0.92, 0.90, 0.89, 0.91, 0.90, 0.90, 0.92, 0.92

0.9440000000000001
0.94, 0.92, 0.95, 0.9, 0.91, 0.95, 0.98, 0.94, 0.94, 0.95, 0.94, 0.95, 0.95, 0.88, 0.98, 0.9, 0.95, 0.91, 0.91, 0.91, 0.92, 0.92, 0.97, 0.91, 0.98, 0.95, 0.94, 0.95, 0.94, 0.91, 0.95, 0.97, 0.91, 0.9, 0.94, 0.98, 0.97, 0.97, 0.88, 0.97, 0.94, 0.98, 0.92, 0.92, 0.94, 0.95, 0.94, 0.94, 0.98, 0.97

0.9417142857142857
0.94, 0.95, 0.95, 0.94, 0.95, 0.94, 0.91, 0.95, 0.92, 0.91, 0.94, 0.92, 0.94, 0.91, 0.95, 0.97, 0.92, 0.97, 0.95, 0.94, 0.94, 0.92, 0.92, 0.9, 0.94, 0.97, 0.95, 0.95, 0.97, 0.91, 0.98, 0.87, 0.9, 0.95, 0.94, 0.98, 0.92, 0.92, 0.94, 0.94, 0.94, 0.92, 0.92, 0.95, 0.94, 0.94, 0.92, 0.95, 0.92, 0.95


Running iteration 2 of 10 fold...
[34, 0, 29, 11, 2, 22, 38, 47, 41, 18]
using cpu
using cpu
    accuracy, precision, recall, f_score
mdl1: 0.942857, 0.942857, 0.937778, 0.937778

    accuracy, precision, recall, f_score
max3: 0.961783, 0.961783, 0.956437, 0.956437

    accuracy, precision, recall, f_score
max1: 0.957143, 0.957917, 0.957778, 0.953734


min loss: 0.011, episode: 246000
max accu: 0.962, episode: 220000

8.67 classifiers used
    accuracy, precision, recall, f_score
mv: 0.957143, 0.957917, 0.957778, 0.953734
wv: 0.957143, 0.957917, 0.957778, 0.953734
fs: 0.942857, 0.942857, 0.937778, 0.937778
rl: 0.957143, 0.957917, 0.957778, 0.953734

0.9293968253968253
0.89, 0.93, 0.94, 0.91, 0.93, 0.93, 0.93, 0.93, 0.92, 0.92, 0.93, 0.90, 0.93, 0.91, 0.93, 0.93, 0.91, 0.90, 0.92, 0.93, 0.92, 0.92, 0.93, 0.92, 0.92, 0.91, 0.92, 0.93, 0.93, 0.95, 0.95, 0.93, 0.93, 0.92, 0.95, 0.91, 0.93, 0.92, 0.93, 0.93, 0.91, 0.93, 0.94, 0.91, 0.92, 0.93, 0.94, 0.94, 0.92, 0.92

0.9262420382165605
0.89, 0.92, 0.94, 0.91, 0.92, 0.93, 0.94, 0.92, 0.91, 0.93, 0.94, 0.89, 0.92, 0.91, 0.93, 0.94, 0.91, 0.92, 0.91, 0.92, 0.89, 0.92, 0.94, 0.91, 0.90, 0.91, 0.90, 0.94, 0.92, 0.95, 0.95, 0.92, 0.94, 0.92, 0.95, 0.89, 0.92, 0.91, 0.94, 0.92, 0.90, 0.94, 0.92, 0.89, 0.91, 0.93, 0.93, 0.94, 0.92, 0.91

0.9034285714285715
0.9, 0.92, 0.92, 0.9, 0.92, 0.92, 0.92, 0.91, 0.9, 0.87, 0.9, 0.9, 0.94, 0.91, 0.85, 0.91, 0.9, 0.85, 0.9, 0.9, 0.92, 0.88, 0.92, 0.85, 0.91, 0.9, 0.87, 0.91, 0.9, 0.88, 0.95, 0.94, 0.92, 0.92, 0.91, 0.84, 0.87, 0.88, 0.92, 0.87, 0.85, 0.91, 0.92, 0.91, 0.9, 0.9, 0.9, 0.94, 0.85, 0.88

0.9211428571428573
0.9, 0.94, 0.88, 0.97, 0.9, 0.95, 0.9, 0.87, 0.9, 0.92, 0.88, 0.91, 0.95, 0.9, 0.91, 0.92, 0.94, 0.91, 0.94, 0.88, 0.94, 0.92, 0.91, 0.92, 0.94, 0.9, 0.92, 0.94, 0.94, 0.92, 0.91, 0.92, 0.88, 0.94, 0.92, 0.95, 0.92, 0.91, 0.88, 0.91, 0.94, 0.88, 0.95, 0.91, 0.91, 0.92, 0.9, 0.92, 0.95, 0.88


Running iteration 3 of 10 fold...
[0, 1, 24, 3, 26]
using cpu
using cpu
    accuracy, precision, recall, f_score
mdl1: 0.971429, 0.971429, 0.968889, 0.968889

    accuracy, precision, recall, f_score
max3: 0.942675, 0.943059, 0.936636, 0.934319

    accuracy, precision, recall, f_score
max1: 0.971429, 0.971429, 0.968889, 0.968889


min loss: 0.009, episode: 270000
max accu: 0.943, episode: 400000

26.31 classifiers used
    accuracy, precision, recall, f_score
mv: 0.957143, 0.957169, 0.948889, 0.952904
wv: 0.957143, 0.957169, 0.948889, 0.952904
fs: 0.957143, 0.957917, 0.957778, 0.953734
rl: 0.971429, 0.971429, 0.968889, 0.968889

0.9339682539682539
0.95, 0.94, 0.93, 0.93, 0.93, 0.93, 0.93, 0.91, 0.92, 0.92, 0.93, 0.93, 0.92, 0.95, 0.93, 0.92, 0.93, 0.93, 0.94, 0.93, 0.92, 0.94, 0.94, 0.93, 0.93, 0.93, 0.93, 0.95, 0.93, 0.94, 0.89, 0.93, 0.93, 0.94, 0.93, 0.95, 0.92, 0.94, 0.92, 0.93, 0.91, 0.94, 0.94, 0.93, 0.93, 0.93, 0.93, 0.89, 0.92, 0.92

0.9253503184713376
0.94, 0.91, 0.92, 0.91, 0.92, 0.92, 0.92, 0.91, 0.92, 0.92, 0.91, 0.93, 0.89, 0.94, 0.92, 0.91, 0.94, 0.93, 0.94, 0.91, 0.91, 0.93, 0.93, 0.92, 0.92, 0.92, 0.92, 0.94, 0.92, 0.94, 0.88, 0.94, 0.93, 0.96, 0.91, 0.94, 0.92, 0.93, 0.89, 0.92, 0.90, 0.92, 0.94, 0.92, 0.93, 0.91, 0.90, 0.85, 0.91, 0.91

0.9228571428571428
0.94, 0.92, 0.92, 0.91, 0.91, 0.92, 0.97, 0.92, 0.9, 0.88, 0.9, 0.94, 0.92, 0.91, 0.84, 0.91, 0.95, 0.94, 0.92, 0.91, 0.92, 0.95, 0.9, 0.94, 0.92, 0.88, 0.91, 0.92, 0.94, 0.92, 0.92, 0.95, 0.92, 0.91, 0.98, 0.94, 0.94, 0.94, 0.9, 0.92, 0.9, 0.91, 0.94, 0.9, 0.88, 0.9, 0.92, 0.87, 0.92, 0.91

0.9242857142857143
0.94, 0.94, 0.87, 0.85, 0.9, 0.91, 0.94, 0.88, 0.92, 0.9, 0.92, 0.95, 0.9, 0.95, 0.94, 0.94, 0.87, 0.92, 0.92, 0.94, 0.91, 0.88, 0.91, 0.88, 0.91, 0.94, 0.94, 0.92, 0.95, 0.94, 0.9, 0.94, 0.94, 0.92, 0.91, 0.9, 0.92, 0.92, 0.88, 0.91, 0.91, 0.94, 0.97, 0.9, 0.92, 0.95, 0.92, 0.95, 0.95, 0.95


Running iteration 4 of 10 fold...
[27, 0, 3, 20, 38, 21]
using cpu
using cpu
    accuracy, precision, recall, f_score
mdl1: 0.971429, 0.971429, 0.970833, 0.970833

    accuracy, precision, recall, f_score
max3: 0.949045, 0.949828, 0.947660, 0.943545

    accuracy, precision, recall, f_score
max1: 0.971429, 0.971429, 0.970833, 0.970833


min loss: 0.008, episode: 262000
max accu: 0.949, episode: 400000

22.53 classifiers used
    accuracy, precision, recall, f_score
mv: 0.971429, 0.971429, 0.970833, 0.970833
wv: 0.971429, 0.971429, 0.970833, 0.970833
fs: 0.971429, 0.971429, 0.970833, 0.970833
rl: 0.971429, 0.971429, 0.970833, 0.970833

0.930920634920635
0.92, 0.94, 0.91, 0.94, 0.93, 0.92, 0.94, 0.93, 0.93, 0.93, 0.93, 0.92, 0.93, 0.94, 0.94, 0.92, 0.93, 0.92, 0.90, 0.93, 0.93, 0.90, 0.93, 0.93, 0.94, 0.93, 0.93, 0.95, 0.92, 0.92, 0.93, 0.93, 0.93, 0.93, 0.92, 0.92, 0.92, 0.92, 0.93, 0.93, 0.93, 0.91, 0.88, 0.93, 0.92, 0.95, 0.94, 0.93, 0.95, 0.92

0.920127388535032
0.89, 0.93, 0.90, 0.92, 0.92, 0.89, 0.92, 0.92, 0.91, 0.92, 0.92, 0.91, 0.93, 0.93, 0.93, 0.89, 0.91, 0.91, 0.88, 0.91, 0.92, 0.88, 0.94, 0.91, 0.92, 0.92, 0.92, 0.94, 0.90, 0.89, 0.91, 0.92, 0.92, 0.92, 0.92, 0.92, 0.91, 0.91, 0.94, 0.92, 0.91, 0.90, 0.86, 0.92, 0.90, 0.94, 0.92, 0.93, 0.94, 0.92

0.9305714285714285
0.9, 0.94, 0.85, 0.98, 0.85, 0.94, 0.94, 0.92, 0.91, 0.92, 0.91, 0.9, 0.91, 0.95, 0.95, 0.94, 0.91, 0.95, 0.91, 0.91, 0.92, 0.88, 0.95, 0.94, 0.95, 0.94, 0.91, 0.95, 0.94, 0.95, 0.92, 0.91, 0.95, 0.91, 0.92, 0.97, 0.97, 0.95, 0.95, 0.94, 0.92, 0.9, 0.9, 0.9, 0.92, 0.92, 0.95, 0.9, 0.95, 0.91

0.9222857142857143
0.92, 0.92, 0.9, 0.95, 0.91, 0.91, 0.9, 0.94, 0.98, 0.91, 0.95, 0.85, 0.92, 0.92, 0.94, 0.88, 0.9, 0.94, 0.92, 0.91, 0.88, 0.95, 0.92, 0.92, 0.92, 0.9, 0.9, 0.91, 0.95, 0.9, 0.94, 0.92, 0.97, 0.94, 0.94, 0.94, 0.88, 0.97, 0.92, 0.95, 0.85, 0.91, 0.88, 0.9, 0.94, 0.94, 0.85, 0.91, 0.92, 0.88


Running iteration 5 of 10 fold...
[11, 0, 1, 12, 5, 3, 39, 4]
using cpu
using cpu
    accuracy, precision, recall, f_score
mdl1: 0.957143, 0.963265, 0.971154, 0.946687

    accuracy, precision, recall, f_score
max3: 0.961783, 0.962441, 0.962064, 0.958021

    accuracy, precision, recall, f_score
max1: 0.957143, 0.963265, 0.971154, 0.946687


min loss: 0.008, episode: 250000
max accu: 0.962, episode: 370000

33.91 classifiers used
    accuracy, precision, recall, f_score
mv: 0.957143, 0.963265, 0.971154, 0.946687
wv: 0.957143, 0.963265, 0.971154, 0.946687
fs: 0.957143, 0.963265, 0.971154, 0.946687
rl: 0.957143, 0.963265, 0.971154, 0.946687

0.9293968253968252
0.91, 0.93, 0.90, 0.91, 0.94, 0.93, 0.95, 0.94, 0.92, 0.93, 0.93, 0.95, 0.92, 0.93, 0.94, 0.92, 0.90, 0.93, 0.90, 0.91, 0.93, 0.94, 0.93, 0.92, 0.91, 0.93, 0.93, 0.92, 0.91, 0.94, 0.90, 0.93, 0.92, 0.92, 0.90, 0.94, 0.94, 0.93, 0.93, 0.92, 0.95, 0.90, 0.94, 0.90, 0.94, 0.92, 0.90, 0.93, 0.93, 0.93

0.9249681528662421
0.91, 0.92, 0.89, 0.90, 0.92, 0.91, 0.94, 0.94, 0.91, 0.91, 0.94, 0.94, 0.93, 0.93, 0.93, 0.92, 0.90, 0.94, 0.89, 0.92, 0.94, 0.93, 0.92, 0.92, 0.91, 0.91, 0.92, 0.93, 0.89, 0.95, 0.89, 0.92, 0.91, 0.92, 0.89, 0.96, 0.93, 0.92, 0.92, 0.90, 0.94, 0.91, 0.93, 0.91, 0.92, 0.91, 0.89, 0.94, 0.91, 0.93

0.9317142857142858
0.88, 0.92, 0.92, 0.85, 0.88, 0.94, 0.94, 0.95, 0.94, 0.95, 0.91, 0.94, 0.94, 0.92, 0.94, 0.91, 0.92, 0.94, 0.94, 0.91, 0.94, 0.92, 0.91, 0.91, 0.91, 0.94, 0.94, 0.95, 0.91, 0.95, 0.94, 0.95, 0.92, 0.94, 0.95, 0.94, 0.95, 0.94, 0.91, 0.95, 0.91, 0.91, 0.95, 0.92, 0.92, 0.94, 0.92, 0.91, 0.92, 0.91

0.9420000000000002
0.92, 0.98, 0.91, 0.92, 0.95, 0.91, 0.91, 0.97, 0.94, 0.94, 0.95, 0.94, 0.92, 0.94, 0.97, 0.97, 0.9, 0.95, 0.91, 0.94, 0.92, 0.91, 0.92, 0.94, 0.98, 0.94, 0.95, 0.92, 0.92, 0.95, 0.94, 0.92, 0.92, 0.91, 0.94, 0.97, 0.92, 0.95, 0.94, 0.87, 0.95, 0.94, 0.95, 0.95, 0.97, 0.98, 0.95, 0.94, 0.92, 0.92


Running iteration 6 of 10 fold...
[33, 0, 14, 5, 22, 1, 34, 35]
using cpu
using cpu
    accuracy, precision, recall, f_score
mdl1: 0.957143, 0.962286, 0.968750, 0.951956

    accuracy, precision, recall, f_score
max3: 0.955414, 0.955308, 0.948930, 0.950817

    accuracy, precision, recall, f_score
max1: 0.942857, 0.945807, 0.946023, 0.935245


min loss: 0.010, episode: 252000
max accu: 0.955, episode: 210000

3.03 classifiers used
    accuracy, precision, recall, f_score
mv: 0.957143, 0.962286, 0.968750, 0.951956
wv: 0.957143, 0.962286, 0.968750, 0.951956
fs: 0.957143, 0.962286, 0.968750, 0.951956
rl: 0.942857, 0.945807, 0.946023, 0.935245

0.9358095238095239
0.94, 0.92, 0.92, 0.95, 0.92, 0.93, 0.94, 0.94, 0.93, 0.91, 0.91, 0.95, 0.93, 0.95, 0.95, 0.93, 0.94, 0.93, 0.93, 0.91, 0.93, 0.93, 0.95, 0.93, 0.92, 0.90, 0.93, 0.93, 0.91, 0.95, 0.92, 0.95, 0.94, 0.95, 0.92, 0.93, 0.94, 0.93, 0.89, 0.93, 0.92, 0.93, 0.92, 0.95, 0.95, 0.94, 0.94, 0.94, 0.93, 0.93

0.9264968152866241
0.94, 0.90, 0.91, 0.93, 0.90, 0.92, 0.93, 0.92, 0.92, 0.90, 0.91, 0.95, 0.91, 0.94, 0.94, 0.91, 0.94, 0.91, 0.94, 0.89, 0.91, 0.92, 0.95, 0.89, 0.91, 0.89, 0.93, 0.91, 0.89, 0.94, 0.91, 0.94, 0.93, 0.94, 0.92, 0.92, 0.93, 0.94, 0.90, 0.94, 0.89, 0.91, 0.92, 0.93, 0.94, 0.94, 0.92, 0.94, 0.92, 0.94

0.9471428571428572
0.98, 0.94, 0.95, 0.94, 0.95, 0.94, 0.95, 0.95, 0.91, 0.95, 0.94, 0.95, 0.94, 0.92, 0.95, 0.94, 0.92, 0.95, 0.95, 0.97, 0.94, 0.95, 0.94, 0.94, 0.94, 0.92, 0.91, 0.98, 0.92, 0.97, 0.91, 0.95, 0.94, 0.95, 0.97, 0.98, 0.94, 0.92, 0.94, 0.95, 0.92, 0.91, 0.94, 0.95, 0.94, 0.95, 0.95, 0.94, 0.92, 0.92

0.9502857142857143
0.97, 0.95, 0.92, 0.94, 0.95, 0.95, 0.94, 0.94, 0.92, 0.97, 0.91, 0.94, 0.95, 0.98, 0.94, 0.94, 0.97, 0.95, 0.95, 0.92, 0.94, 0.94, 0.95, 0.97, 0.97, 0.94, 0.94, 0.94, 0.98, 0.97, 0.94, 0.97, 0.97, 0.94, 0.98, 0.92, 0.92, 0.97, 0.92, 0.94, 0.95, 0.92, 0.92, 0.94, 0.94, 0.94, 0.95, 0.94, 0.91, 0.97


Running iteration 7 of 10 fold...
[0, 1, 29, 4, 11, 2, 3, 6, 5, 7, 8, 14, 44, 9, 31, 12, 10, 15, 13, 20, 23, 21, 26, 16, 18, 25, 41, 39]
using cpu
using cpu
    accuracy, precision, recall, f_score
mdl1: 0.971429, 0.972789, 0.966667, 0.970563

    accuracy, precision, recall, f_score
max3: 0.968153, 0.968399, 0.966241, 0.963880

    accuracy, precision, recall, f_score
max1: 0.971429, 0.972789, 0.966667, 0.970563


min loss: 0.009, episode: 252000
max accu: 0.968, episode: 400000

24.49 classifiers used
    accuracy, precision, recall, f_score
mv: 0.971429, 0.972789, 0.966667, 0.970563
wv: 0.971429, 0.972789, 0.966667, 0.970563
fs: 0.957143, 0.960133, 0.950000, 0.955612
rl: 0.971429, 0.972789, 0.966667, 0.970563

0.9338412698412699
0.96, 0.94, 0.90, 0.94, 0.94, 0.94, 0.92, 0.93, 0.95, 0.92, 0.95, 0.94, 0.95, 0.93, 0.90, 0.94, 0.88, 0.93, 0.87, 0.93, 0.93, 0.94, 0.95, 0.93, 0.94, 0.89, 0.94, 0.94, 0.92, 0.94, 0.93, 0.95, 0.94, 0.94, 0.95, 0.92, 0.93, 0.91, 0.93, 0.93, 0.92, 0.93, 0.92, 0.92, 0.91, 0.93, 0.91, 0.93, 0.91, 0.95

0.9313375796178345
0.96, 0.94, 0.91, 0.94, 0.93, 0.95, 0.92, 0.94, 0.94, 0.91, 0.96, 0.94, 0.96, 0.93, 0.89, 0.94, 0.88, 0.92, 0.90, 0.92, 0.92, 0.92, 0.94, 0.91, 0.95, 0.87, 0.92, 0.92, 0.92, 0.94, 0.92, 0.94, 0.96, 0.94, 0.94, 0.92, 0.92, 0.92, 0.92, 0.94, 0.92, 0.93, 0.89, 0.91, 0.92, 0.93, 0.91, 0.92, 0.91, 0.94

0.9219999999999999
0.97, 0.9, 0.94, 0.94, 0.91, 0.9, 0.95, 0.94, 0.92, 0.9, 0.91, 0.95, 0.92, 0.92, 0.9, 0.91, 0.91, 0.91, 0.9, 0.9, 0.92, 0.95, 0.94, 0.98, 0.91, 0.87, 0.91, 0.9, 0.92, 0.95, 0.9, 0.88, 0.97, 0.92, 0.97, 0.91, 0.94, 0.94, 0.77, 0.91, 0.95, 0.97, 0.88, 0.9, 0.9, 0.88, 0.94, 0.9, 0.92, 0.91

0.9228571428571429
0.95, 0.94, 0.94, 0.95, 0.88, 0.91, 0.88, 0.95, 0.94, 0.94, 0.94, 0.94, 0.91, 0.95, 0.92, 0.91, 0.9, 0.9, 0.85, 0.91, 0.85, 0.91, 0.84, 0.91, 0.92, 0.94, 0.91, 0.92, 0.92, 0.94, 0.87, 0.94, 0.9, 0.92, 0.94, 0.91, 0.91, 0.91, 0.95, 0.94, 0.91, 0.95, 0.97, 0.88, 0.91, 0.92, 0.94, 0.92, 0.95, 0.9


Running iteration 8 of 10 fold...
[15, 0, 6, 17]
using cpu
using cpu
    accuracy, precision, recall, f_score
mdl1: 0.985714, 0.986286, 0.989130, 0.984301

    accuracy, precision, recall, f_score
max3: 0.974522, 0.974522, 0.971517, 0.971517

    accuracy, precision, recall, f_score
max1: 0.985714, 0.986286, 0.989130, 0.984301


min loss: 0.010, episode: 256000
max accu: 0.975, episode: 230000

7.30 classifiers used
    accuracy, precision, recall, f_score
mv: 1.000000, 1.000000, 1.000000, 1.000000
wv: 1.000000, 1.000000, 1.000000, 1.000000
fs: 0.971429, 0.973626, 0.978261, 0.968889
rl: 0.985714, 0.986286, 0.989130, 0.984301

0.9313650793650793
0.94, 0.93, 0.93, 0.93, 0.92, 0.91, 0.92, 0.93, 0.93, 0.91, 0.92, 0.92, 0.94, 0.94, 0.90, 0.95, 0.92, 0.93, 0.92, 0.93, 0.93, 0.91, 0.91, 0.91, 0.91, 0.94, 0.91, 0.93, 0.95, 0.92, 0.92, 0.93, 0.93, 0.93, 0.92, 0.92, 0.94, 0.93, 0.91, 0.93, 0.93, 0.94, 0.94, 0.92, 0.92, 0.93, 0.92, 0.95, 0.93, 0.93

0.9336305732484077
0.95, 0.94, 0.94, 0.93, 0.92, 0.91, 0.92, 0.94, 0.91, 0.91, 0.94, 0.91, 0.96, 0.94, 0.89, 0.96, 0.91, 0.94, 0.90, 0.92, 0.92, 0.92, 0.92, 0.93, 0.90, 0.94, 0.91, 0.94, 0.94, 0.92, 0.91, 0.94, 0.93, 0.94, 0.92, 0.91, 0.95, 0.93, 0.94, 0.93, 0.94, 0.94, 0.96, 0.91, 0.94, 0.92, 0.91, 0.96, 0.93, 0.92

0.9491428571428571
0.95, 0.95, 0.98, 0.97, 0.94, 0.92, 0.98, 0.94, 0.94, 0.88, 0.94, 0.97, 0.94, 0.98, 0.94, 0.95, 0.97, 0.97, 0.91, 0.92, 0.94, 0.92, 0.94, 0.94, 0.94, 0.92, 0.94, 0.94, 0.91, 0.91, 0.97, 0.92, 0.94, 0.95, 0.94, 0.95, 0.94, 0.97, 0.92, 0.94, 0.87, 0.94, 0.98, 0.98, 0.97, 0.95, 0.95, 0.95, 0.98, 0.98

0.9568571428571429
0.94, 0.91, 0.98, 0.92, 0.9, 0.9, 0.97, 0.97, 0.95, 0.95, 0.97, 0.97, 0.94, 0.95, 0.97, 0.97, 0.98, 0.98, 0.95, 0.95, 0.91, 0.94, 0.97, 1.0, 0.91, 0.94, 0.98, 0.95, 0.94, 0.94, 0.91, 0.97, 0.98, 0.97, 0.98, 0.91, 0.94, 0.95, 0.95, 0.97, 0.98, 0.95, 0.94, 0.97, 0.94, 0.95, 0.98, 1.0, 0.94, 0.97


Running iteration 9 of 10 fold...
[31, 0, 26, 19, 5, 8, 18, 16, 2, 27, 3, 14, 4, 29, 1, 33, 6, 35, 7, 45, 12, 36, 13, 39, 23, 43, 24]
using cpu
using cpu
    accuracy, precision, recall, f_score
mdl1: 0.957143, 0.957169, 0.948889, 0.952904

    accuracy, precision, recall, f_score
max3: 0.974522, 0.975079, 0.976178, 0.972014

    accuracy, precision, recall, f_score
max1: 0.957143, 0.957169, 0.948889, 0.952904


min loss: 0.007, episode: 269000
max accu: 0.975, episode: 250000

19.33 classifiers used
    accuracy, precision, recall, f_score
mv: 0.971429, 0.971429, 0.968889, 0.968889
wv: 0.971429, 0.971429, 0.968889, 0.968889
fs: 0.957143, 0.957169, 0.948889, 0.952904
rl: 0.957143, 0.957169, 0.948889, 0.952904

0.9378412698412697
0.93, 0.91, 0.95, 0.95, 0.94, 0.95, 0.93, 0.93, 0.94, 0.93, 0.94, 0.91, 0.95, 0.96, 0.93, 0.94, 0.92, 0.92, 0.92, 0.92, 0.94, 0.92, 0.95, 0.95, 0.92, 0.93, 0.95, 0.91, 0.92, 0.93, 0.88, 0.96, 0.93, 0.91, 0.94, 0.95, 0.93, 0.94, 0.93, 0.94, 0.94, 0.96, 0.94, 0.93, 0.93, 0.91, 0.94, 0.94, 0.93, 0.91

0.9380891719745224
0.92, 0.91, 0.96, 0.96, 0.92, 0.94, 0.94, 0.92, 0.94, 0.94, 0.95, 0.90, 0.94, 0.96, 0.93, 0.94, 0.92, 0.92, 0.94, 0.94, 0.92, 0.92, 0.94, 0.94, 0.91, 0.94, 0.94, 0.92, 0.91, 0.94, 0.87, 0.97, 0.94, 0.90, 0.94, 0.94, 0.93, 0.95, 0.94, 0.94, 0.94, 0.96, 0.94, 0.95, 0.92, 0.90, 0.93, 0.94, 0.94, 0.91

0.9257142857142858
0.92, 0.9, 0.91, 0.91, 0.9, 0.97, 0.92, 0.9, 0.92, 0.94, 0.97, 0.9, 0.95, 0.91, 0.92, 0.9, 0.92, 0.94, 0.9, 0.91, 0.9, 0.94, 0.95, 0.91, 0.87, 0.94, 0.95, 0.9, 0.94, 0.94, 0.95, 0.92, 0.9, 0.94, 0.91, 0.9, 0.9, 0.88, 0.94, 0.91, 0.94, 0.95, 0.94, 0.95, 0.9, 0.91, 0.94, 0.91, 0.94, 0.92

0.9328571428571429
0.87, 0.94, 0.94, 0.97, 0.95, 0.91, 0.97, 0.97, 0.91, 0.95, 0.91, 0.94, 0.95, 0.87, 0.92, 0.9, 0.94, 0.97, 0.97, 0.95, 0.91, 0.91, 0.9, 0.92, 0.91, 0.95, 0.94, 0.95, 0.88, 0.98, 0.88, 0.95, 0.94, 0.92, 0.94, 0.92, 0.95, 0.97, 0.91, 0.91, 0.91, 0.91, 0.94, 0.88, 0.88, 0.94, 0.94, 0.94, 0.9, 0.95


Running iteration 10 of 10 fold...
[13, 0, 23, 5, 2, 3, 11, 9, 8, 12, 1, 17, 4, 20, 6, 14, 10, 18, 21, 7, 19, 24, 15, 32, 26, 45, 29]
using cpu
using cpu
    accuracy, precision, recall, f_score
mdl1: 0.956522, 0.957531, 0.955357, 0.949327

    accuracy, precision, recall, f_score
max3: 0.961783, 0.961846, 0.955898, 0.958986

    accuracy, precision, recall, f_score
max1: 0.956522, 0.957531, 0.955357, 0.949327


min loss: 0.009, episode: 239000
max accu: 0.962, episode: 210000

9.41 classifiers used
    accuracy, precision, recall, f_score
mv: 0.971014, 0.973535, 0.979167, 0.966634
wv: 0.971014, 0.973535, 0.979167, 0.966634
fs: 0.956522, 0.957531, 0.955357, 0.949327
rl: 0.956522, 0.957531, 0.955357, 0.949327

0.9358095238095239
0.92, 0.92, 0.91, 0.93, 0.93, 0.93, 0.94, 0.93, 0.95, 0.91, 0.93, 0.95, 0.94, 0.95, 0.93, 0.91, 0.94, 0.93, 0.91, 0.94, 0.93, 0.94, 0.91, 0.94, 0.93, 0.93, 0.93, 0.93, 0.95, 0.93, 0.93, 0.94, 0.95, 0.93, 0.94, 0.92, 0.93, 0.95, 0.91, 0.95, 0.93, 0.93, 0.94, 0.92, 0.93, 0.91, 0.93, 0.95, 0.93, 0.94

0.9244585987261147
0.91, 0.92, 0.89, 0.91, 0.91, 0.93, 0.93, 0.91, 0.94, 0.89, 0.92, 0.94, 0.92, 0.94, 0.93, 0.91, 0.94, 0.92, 0.91, 0.93, 0.91, 0.92, 0.89, 0.92, 0.90, 0.91, 0.91, 0.91, 0.94, 0.93, 0.91, 0.92, 0.94, 0.91, 0.94, 0.89, 0.92, 0.93, 0.89, 0.96, 0.92, 0.91, 0.93, 0.92, 0.90, 0.92, 0.92, 0.92, 0.94, 0.92

0.9368115942028986
0.91, 0.97, 0.91, 0.94, 0.94, 0.92, 0.95, 0.88, 0.94, 0.95, 0.92, 0.95, 0.94, 0.92, 0.91, 0.92, 0.95, 0.97, 0.91, 0.95, 0.92, 0.94, 0.95, 0.94, 0.94, 0.91, 0.92, 0.95, 0.95, 0.95, 0.94, 0.97, 0.92, 0.95, 0.92, 0.86, 0.98, 0.95, 0.92, 0.95, 0.89, 0.91, 0.97, 0.91, 0.89, 0.91, 0.92, 0.97, 0.89, 0.95

0.9489855072463769
0.91, 0.97, 0.95, 0.94, 0.95, 0.95, 0.94, 0.92, 0.94, 0.97, 0.95, 0.91, 0.94, 0.98, 0.91, 0.94, 0.97, 0.95, 0.95, 0.97, 0.94, 0.97, 0.92, 0.97, 0.94, 0.92, 0.95, 0.95, 0.95, 0.95, 0.94, 0.92, 0.95, 0.95, 0.95, 0.95, 0.97, 0.92, 0.94, 0.92, 0.94, 0.97, 0.92, 0.95, 0.95, 0.94, 0.95, 0.95, 0.94, 0.94

    accuracy, precision, recall, f_score
mv: 0.968530, 0.970236, 0.968451, 0.964720
wv: 0.968530, 0.970236, 0.968451, 0.964720
fs: 0.954224, 0.956985, 0.949594, 0.947554
rl: 0.965652, 0.966962, 0.965091, 0.961524

fs avg size: 12.90000, rl avg size: 15.60000
full test avg accu: 0.93633, test avg accu: 0.93134

training takes 36378.223 sec
