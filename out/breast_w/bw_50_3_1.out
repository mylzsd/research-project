{'dataset': 'breast_w', 'algorithm': 'ptdqn', 'num_clf': 50, 'num_training': 350000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 2027, 'portion': 0.5, 'sequential': False}
(699, 10)
reading data takes 0.484 sec
number of labels: 2

Running iteration 1 of 10 fold...
[2, 0, 21, 8, 18, 5, 17, 4, 3, 20, 7, 19, 10, 26, 22, 29, 11, 31, 13, 23, 14, 24, 15, 32, 16, 25, 34, 1, 35, 6, 36, 9, 47, 12]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.933333, 0.933492, 0.927716, 0.926816

    accuracy, precision, recall, f_score
max3: 0.929936, 0.929740, 0.916756, 0.922028

    accuracy, precision, recall, f_score
max1: 0.928571, 0.930971, 0.920833, 0.926020


min loss: 0.009, episode: 259000
max accu: 0.929, episode: 30000

1.00 classifiers used
    accuracy, precision, recall, f_score
mv: 0.900000, 0.906667, 0.887500, 0.895187
wv: 0.928571, 0.930971, 0.920833, 0.926020
fs: 0.914286, 0.918581, 0.904167, 0.910714
rl: 0.928571, 0.930971, 0.920833, 0.926020

0.9178412698412699
0.94, 0.93, 0.95, 0.92, 0.95, 0.94, 0.94, 0.92, 0.94, 0.93, 0.94, 0.93, 0.93, 0.94, 0.94, 0.94, 0.92, 0.91, 0.93, 0.91, 0.93, 0.93, 0.90, 0.88, 0.89, 0.91, 0.93, 0.91, 0.91, 0.92, 0.91, 0.91, 0.90, 0.89, 0.90, 0.89, 0.92, 0.89, 0.87, 0.89, 0.89, 0.91, 0.91, 0.86, 0.88, 0.90, 0.89, 0.93, 0.90, 0.89

0.9196178343949044
0.94, 0.92, 0.96, 0.91, 0.94, 0.94, 0.92, 0.91, 0.93, 0.92, 0.93, 0.94, 0.92, 0.94, 0.95, 0.94, 0.92, 0.91, 0.91, 0.91, 0.92, 0.91, 0.92, 0.87, 0.88, 0.89, 0.91, 0.89, 0.90, 0.92, 0.89, 0.89, 0.88, 0.88, 0.92, 0.89, 0.94, 0.91, 0.86, 0.91, 0.91, 0.92, 0.91, 0.89, 0.89, 0.92, 0.92, 0.94, 0.90, 0.92

0.9057142857142858
0.87, 0.9, 0.91, 0.88, 0.88, 0.92, 0.91, 0.92, 0.9, 0.92, 0.9, 0.91, 0.92, 0.9, 0.91, 0.92, 0.9, 0.87, 0.92, 0.91, 0.92, 0.87, 0.91, 0.87, 0.9, 0.92, 0.91, 0.88, 0.87, 0.91, 0.94, 0.92, 0.88, 0.9, 0.92, 0.87, 0.92, 0.88, 0.88, 0.91, 0.92, 0.9, 0.92, 0.88, 0.85, 0.91, 0.92, 0.91, 0.9, 0.9

0.9079999999999999
0.88, 0.87, 0.91, 0.92, 0.92, 0.94, 0.87, 0.9, 0.88, 0.91, 0.9, 0.88, 0.92, 0.92, 0.94, 0.91, 0.94, 0.91, 0.91, 0.88, 0.85, 0.88, 0.88, 0.9, 0.88, 0.91, 0.91, 0.88, 0.91, 0.9, 0.87, 0.91, 0.87, 0.9, 0.92, 0.88, 0.91, 0.94, 0.92, 0.91, 0.95, 0.9, 0.91, 0.91, 0.91, 0.92, 0.92, 0.92, 0.85, 0.94


Running iteration 2 of 10 fold...
[10, 0, 22, 36, 6, 17]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.936508, 0.936487, 0.925978, 0.930727

    accuracy, precision, recall, f_score
max3: 0.955414, 0.955566, 0.943995, 0.949920

    accuracy, precision, recall, f_score
max1: 0.971429, 0.973810, 0.979167, 0.967623


min loss: 0.010, episode: 246000
max accu: 0.971, episode: 210000

4.34 classifiers used
    accuracy, precision, recall, f_score
mv: 0.971429, 0.973810, 0.979167, 0.967623
wv: 0.971429, 0.973810, 0.979167, 0.967623
fs: 0.971429, 0.971429, 0.966856, 0.966856
rl: 0.971429, 0.973810, 0.979167, 0.967623

0.9156825396825397
0.93, 0.93, 0.93, 0.92, 0.93, 0.92, 0.92, 0.92, 0.93, 0.93, 0.94, 0.92, 0.92, 0.94, 0.92, 0.93, 0.92, 0.90, 0.93, 0.93, 0.91, 0.91, 0.92, 0.92, 0.87, 0.91, 0.90, 0.91, 0.92, 0.89, 0.92, 0.92, 0.91, 0.87, 0.90, 0.90, 0.89, 0.91, 0.90, 0.90, 0.91, 0.89, 0.90, 0.88, 0.89, 0.93, 0.89, 0.90, 0.89, 0.90

0.9240764331210191
0.93, 0.94, 0.93, 0.93, 0.93, 0.93, 0.93, 0.91, 0.93, 0.92, 0.94, 0.92, 0.92, 0.94, 0.92, 0.94, 0.91, 0.92, 0.93, 0.93, 0.92, 0.92, 0.91, 0.92, 0.87, 0.92, 0.89, 0.91, 0.92, 0.92, 0.94, 0.92, 0.92, 0.87, 0.92, 0.91, 0.91, 0.93, 0.92, 0.92, 0.91, 0.90, 0.92, 0.91, 0.91, 0.92, 0.90, 0.94, 0.91, 0.92

0.932857142857143
0.94, 0.97, 0.94, 0.95, 0.95, 0.97, 0.95, 0.91, 0.98, 0.95, 0.97, 0.97, 0.98, 0.94, 0.97, 0.91, 0.9, 0.94, 0.92, 0.94, 0.91, 0.91, 0.91, 0.92, 0.84, 0.94, 0.94, 0.91, 0.91, 0.9, 0.92, 0.94, 0.91, 0.9, 0.94, 0.91, 0.88, 0.92, 0.9, 0.97, 0.91, 0.88, 0.95, 0.92, 0.94, 0.91, 0.95, 0.9, 0.92, 0.92

0.9337142857142858
0.97, 0.94, 0.92, 0.92, 0.95, 0.95, 0.94, 0.92, 0.95, 0.91, 0.92, 0.97, 0.9, 0.92, 0.95, 0.95, 0.91, 0.94, 0.95, 0.94, 0.94, 0.94, 0.91, 0.94, 0.95, 0.92, 0.92, 0.95, 0.94, 0.92, 0.94, 0.95, 0.92, 0.94, 0.94, 0.91, 0.95, 0.91, 0.94, 0.92, 0.92, 0.92, 0.91, 0.88, 0.85, 0.92, 0.91, 0.91, 0.88, 0.94


Running iteration 3 of 10 fold...
[1, 0, 18, 37, 21, 34, 8, 9, 14, 20]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.930159, 0.931533, 0.930458, 0.925962

    accuracy, precision, recall, f_score
max3: 0.942675, 0.942967, 0.939912, 0.938256

    accuracy, precision, recall, f_score
max1: 0.985714, 0.986429, 0.990196, 0.982229


min loss: 0.007, episode: 263000
max accu: 0.986, episode: 240000

15.56 classifiers used
    accuracy, precision, recall, f_score
mv: 0.971429, 0.974150, 0.980392, 0.965000
wv: 0.971429, 0.974150, 0.980392, 0.965000
fs: 0.971429, 0.974150, 0.980392, 0.965000
rl: 0.985714, 0.986429, 0.990196, 0.982229

0.9136507936507935
0.91, 0.94, 0.92, 0.93, 0.93, 0.93, 0.93, 0.93, 0.94, 0.92, 0.94, 0.93, 0.92, 0.92, 0.92, 0.92, 0.92, 0.91, 0.93, 0.89, 0.92, 0.89, 0.91, 0.89, 0.92, 0.92, 0.92, 0.91, 0.92, 0.92, 0.90, 0.90, 0.90, 0.90, 0.90, 0.90, 0.91, 0.87, 0.89, 0.89, 0.89, 0.89, 0.90, 0.90, 0.90, 0.88, 0.89, 0.89, 0.90, 0.86

0.9249681528662421
0.92, 0.95, 0.93, 0.93, 0.94, 0.94, 0.93, 0.94, 0.95, 0.92, 0.94, 0.92, 0.92, 0.92, 0.94, 0.94, 0.91, 0.92, 0.94, 0.91, 0.94, 0.89, 0.92, 0.90, 0.94, 0.94, 0.92, 0.92, 0.92, 0.92, 0.92, 0.91, 0.89, 0.91, 0.90, 0.89, 0.92, 0.88, 0.89, 0.91, 0.91, 0.91, 0.92, 0.93, 0.91, 0.91, 0.91, 0.91, 0.92, 0.89

0.9394285714285715
0.91, 0.95, 0.95, 0.92, 0.95, 0.92, 0.97, 0.94, 0.94, 0.91, 0.92, 0.92, 0.91, 0.94, 0.92, 0.95, 0.95, 0.91, 0.9, 0.88, 0.91, 0.9, 0.9, 0.92, 0.9, 0.91, 0.92, 0.92, 0.91, 0.9, 0.91, 0.94, 0.92, 0.91, 0.94, 0.98, 0.97, 1.0, 0.97, 0.95, 0.95, 0.95, 0.95, 0.98, 0.94, 0.98, 0.95, 0.97, 1.0, 0.92

0.9388571428571427
0.95, 0.94, 0.95, 0.95, 0.94, 0.95, 0.95, 0.97, 0.92, 0.92, 0.95, 0.91, 0.95, 0.95, 0.95, 0.95, 0.92, 0.9, 0.88, 0.91, 0.9, 0.92, 0.9, 0.91, 0.88, 0.91, 0.91, 0.92, 0.92, 0.91, 0.9, 0.9, 0.9, 0.91, 0.95, 0.98, 0.94, 0.95, 0.94, 0.95, 0.98, 0.95, 0.97, 0.98, 0.97, 0.97, 0.94, 0.92, 0.94, 0.97

    accuracy, precision, recall, f_score
mv: 0.947619, 0.951542, 0.949020, 0.942603
wv: 0.957143, 0.959643, 0.960131, 0.952881
fs: 0.952381, 0.954720, 0.950472, 0.947523
rl: 0.961905, 0.963736, 0.963399, 0.958624

fs avg size: 16.66667, rl avg size: 6.96667
full test avg accu: 0.92686, test avg accu: 0.92600

training takes 10247.681 sec
