{'dataset': 'breast_w', 'algorithm': 'ptdqn', 'num_clf': 100, 'num_training': 400000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 7503, 'portion': 0.5, 'sequential': False}
(699, 10)
reading data takes 0.689 sec
number of labels: 2

Running iteration 1 of 10 fold...
[41, 0, 39, 1, 27, 22, 23, 45, 61, 72]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.9683, 0.9695, 0.9714, 0.9638

    accuracy, precision, recall, f_score
max3: 0.9618, 0.9641, 0.9666, 0.9544

    accuracy, precision, recall, f_score
max1: 0.9857, 0.9864, 0.9898, 0.9832


min loss: 0.007, episode: 283000
max accu: 0.986, episode: 400000

79.70 classifiers used
    accuracy, precision, recall, f_score
mv: 0.9857, 0.9864, 0.9898, 0.9832
wv: 0.9857, 0.9864, 0.9898, 0.9832
fs: 0.9714, 0.9714, 0.9660, 0.9660
rl: 0.9857, 0.9864, 0.9898, 0.9832

0.9464285714285714
0.97, 0.95, 0.94, 0.95, 0.92, 0.94, 0.9, 0.92, 0.97, 0.91, 0.92, 0.91, 0.94, 0.94, 0.97, 0.95, 0.92, 0.95, 0.98, 0.94, 0.97, 0.94, 0.92, 0.94, 0.95, 0.92, 0.95, 0.98, 0.97, 0.95, 0.95, 0.94, 0.95, 0.92, 0.91, 0.94, 0.95, 0.95, 0.94, 0.94, 0.9, 0.97, 0.94, 0.91, 0.97, 0.95, 0.9, 0.94, 0.95, 0.92, 0.94, 0.92, 0.95, 0.94, 0.95, 0.88, 0.97, 0.98, 0.94, 0.95, 0.95, 0.95, 0.97, 0.91, 0.92, 0.94, 0.94, 0.95, 0.9, 0.98, 0.94, 0.91, 0.91, 0.94, 0.95, 0.94, 0.95, 0.97, 0.97, 0.97, 0.85, 0.95, 0.92, 0.9, 0.97, 0.92, 0.98, 0.95, 0.95, 0.97, 0.91, 0.94, 0.97, 0.95, 0.97, 0.97, 0.98, 0.94, 0.92, 0.97

0.9432857142857144
0.92, 0.95, 0.95, 0.91, 0.94, 0.95, 0.94, 0.94, 0.94, 0.95, 0.94, 0.97, 0.94, 0.91, 0.95, 0.94, 0.94, 0.97, 0.88, 0.98, 0.97, 0.95, 0.95, 0.97, 0.97, 0.95, 0.92, 0.95, 0.95, 0.92, 0.88, 0.95, 0.88, 0.97, 0.95, 0.97, 0.98, 0.91, 0.91, 0.94, 0.92, 0.91, 0.98, 0.91, 0.97, 0.92, 0.92, 0.92, 0.94, 0.94, 0.92, 0.92, 0.88, 0.91, 0.94, 0.91, 0.91, 0.95, 0.95, 0.94, 0.95, 0.95, 0.95, 0.94, 0.95, 0.97, 0.95, 0.98, 0.95, 0.95, 0.91, 0.97, 0.9, 0.95, 0.98, 0.94, 0.91, 0.94, 0.92, 0.97, 0.84, 0.92, 0.92, 0.94, 0.92, 0.95, 0.94, 0.97, 0.94, 0.9, 0.98, 0.94, 0.94, 0.97, 0.87, 0.98, 0.92, 0.95, 0.95, 0.95


Running iteration 2 of 10 fold...
[42, 0, 3, 4, 16, 5, 12, 1, 13, 14, 2, 17, 11, 18, 30, 7, 28, 8, 20, 22, 34, 27, 46, 35, 55, 15, 32, 36, 75, 9]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.9302, 0.9341, 0.9321, 0.9194

    accuracy, precision, recall, f_score
max3: 0.8981, 0.9129, 0.9069, 0.8754

    accuracy, precision, recall, f_score
max1: 0.9429, 0.9454, 0.9467, 0.9388


min loss: 0.007, episode: 261000
max accu: 0.943, episode: 10000

2.60 classifiers used
    accuracy, precision, recall, f_score
mv: 0.9286, 0.9296, 0.9267, 0.9229
wv: 0.9286, 0.9296, 0.9267, 0.9229
fs: 0.9143, 0.9143, 0.9067, 0.9067
rl: 0.9429, 0.9454, 0.9467, 0.9388

0.9208571428571429
0.9, 0.94, 0.9, 0.92, 0.87, 0.91, 0.9, 0.91, 0.92, 0.87, 0.91, 0.9, 0.91, 0.94, 0.9, 0.92, 0.94, 0.91, 0.92, 0.92, 0.92, 0.9, 0.94, 0.91, 0.92, 0.9, 0.92, 0.94, 0.87, 0.94, 0.92, 0.94, 0.91, 0.92, 0.92, 0.94, 0.92, 0.91, 0.91, 0.92, 0.91, 0.9, 0.91, 0.92, 0.95, 0.91, 0.92, 0.91, 0.94, 0.88, 0.9, 0.9, 0.91, 0.92, 0.92, 0.92, 0.9, 0.92, 0.88, 0.9, 0.92, 0.91, 0.91, 0.9, 0.94, 0.91, 0.94, 0.91, 0.94, 0.94, 0.91, 0.91, 0.92, 0.91, 0.92, 0.95, 0.92, 0.92, 0.91, 0.94, 0.9, 0.92, 0.91, 0.92, 0.92, 0.91, 0.92, 0.92, 0.92, 0.94, 0.94, 0.9, 0.92, 0.92, 0.92, 0.91, 0.94, 0.92, 0.91, 0.91

0.9251428571428572
0.91, 0.9, 0.91, 0.91, 0.94, 0.91, 0.91, 0.92, 0.94, 0.92, 0.91, 0.95, 0.92, 0.92, 0.92, 0.94, 0.91, 0.92, 0.92, 0.91, 0.91, 0.92, 0.88, 0.94, 0.94, 0.91, 0.92, 0.92, 0.91, 0.92, 0.91, 0.91, 0.95, 0.92, 0.94, 0.92, 0.9, 0.91, 0.94, 0.91, 0.94, 0.92, 0.94, 0.88, 0.92, 0.88, 0.91, 0.94, 0.91, 0.91, 0.92, 0.9, 0.91, 0.91, 0.92, 0.92, 0.91, 0.9, 0.9, 0.95, 0.92, 0.92, 0.95, 0.9, 0.91, 0.94, 0.9, 0.92, 0.92, 0.92, 0.9, 0.94, 0.92, 0.91, 0.92, 0.91, 0.92, 0.92, 0.92, 0.91, 0.94, 0.94, 0.94, 0.9, 0.94, 0.92, 0.94, 0.92, 0.91, 0.92, 0.92, 0.92, 0.94, 0.95, 0.94, 0.92, 0.92, 0.92, 0.91, 0.94


Running iteration 3 of 10 fold...
[76, 0, 79, 4, 9, 2, 3, 1, 38, 8, 5, 6, 7, 12, 11, 16, 10, 17, 13, 18, 14, 22, 15, 23, 25, 19, 28, 24, 20, 29, 30, 21, 33, 26, 39, 27, 40, 31, 41, 32, 49, 35, 50, 36, 56, 37, 62, 34, 85, 46, 69, 42, 87, 47, 73, 43, 96, 44, 99, 45]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.9683, 0.9689, 0.9686, 0.9636

    accuracy, precision, recall, f_score
max3: 0.9618, 0.9643, 0.9664, 0.9533

    accuracy, precision, recall, f_score
max1: 0.9429, 0.9457, 0.9463, 0.9366


min loss: 0.008, episode: 282000
max accu: 0.943, episode: 260000

29.60 classifiers used
    accuracy, precision, recall, f_score
mv: 0.9429, 0.9457, 0.9463, 0.9366
wv: 0.9429, 0.9457, 0.9463, 0.9366
fs: 0.9571, 0.9580, 0.9570, 0.9520
rl: 0.9429, 0.9457, 0.9463, 0.9366

0.9105714285714286
0.97, 0.88, 0.9, 0.94, 0.87, 0.9, 0.9, 0.91, 0.92, 0.91, 0.9, 0.97, 0.88, 0.92, 0.91, 0.91, 0.92, 0.92, 0.9, 0.9, 0.85, 0.88, 0.87, 0.92, 0.95, 0.91, 0.95, 0.87, 0.97, 0.92, 0.92, 0.92, 0.87, 0.91, 0.87, 0.92, 0.87, 0.94, 0.9, 0.95, 0.91, 0.87, 0.88, 0.88, 0.9, 0.9, 0.9, 0.94, 0.9, 0.91, 0.94, 0.92, 0.92, 0.85, 0.9, 0.94, 0.9, 0.88, 0.88, 0.91, 0.88, 0.92, 0.9, 0.9, 0.91, 0.88, 0.91, 0.87, 0.9, 0.9, 0.92, 0.9, 0.94, 0.94, 0.91, 0.91, 0.94, 0.91, 0.88, 0.91, 0.92, 0.95, 0.9, 0.87, 0.88, 0.88, 0.94, 0.91, 0.87, 0.94, 0.94, 0.92, 0.9, 0.92, 0.9, 0.88, 0.95, 0.91, 0.85, 0.88

0.9072857142857146
0.94, 0.82, 0.88, 0.9, 0.88, 0.92, 0.87, 0.88, 0.91, 0.88, 0.9, 0.91, 0.9, 0.91, 0.97, 0.92, 0.91, 0.92, 0.88, 0.87, 0.88, 0.95, 0.9, 0.9, 0.9, 0.87, 0.94, 0.94, 0.95, 0.87, 0.9, 0.91, 0.92, 0.92, 0.88, 0.9, 0.9, 0.9, 0.92, 0.87, 0.92, 0.9, 0.91, 0.88, 0.9, 0.87, 0.94, 0.91, 0.92, 0.88, 0.91, 0.92, 0.91, 0.9, 0.91, 0.91, 0.87, 0.88, 0.9, 0.91, 0.94, 0.91, 0.85, 0.92, 0.9, 0.92, 0.81, 0.91, 0.92, 0.9, 0.95, 0.91, 0.9, 0.87, 0.91, 0.85, 0.91, 0.95, 0.87, 0.85, 0.92, 0.9, 0.9, 0.91, 0.92, 0.87, 0.95, 0.92, 0.9, 0.95, 0.87, 0.95, 0.88, 0.92, 0.94, 0.94, 0.9, 0.88, 0.88, 0.92


Running iteration 4 of 10 fold...
[73, 0, 2, 1, 79, 3, 11, 4, 5, 6, 15, 44, 7, 8, 18, 12, 9, 17, 13, 26, 14, 19, 16, 28, 21, 20, 24, 22, 29, 35, 10, 46, 23, 57, 36, 59, 34, 40, 25, 60, 27, 42, 30, 62, 31, 47, 32, 63, 33, 64, 37, 66, 38, 83, 39, 48, 41, 85, 43, 95, 45]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.9746, 0.9753, 0.9758, 0.9702

    accuracy, precision, recall, f_score
max3: 0.9618, 0.9627, 0.9592, 0.9526

    accuracy, precision, recall, f_score
max1: 0.9857, 0.9860, 0.9800, 0.9843


min loss: 0.008, episode: 270000
max accu: 0.986, episode: 240000

11.21 classifiers used
    accuracy, precision, recall, f_score
mv: 0.9857, 0.9860, 0.9800, 0.9843
wv: 0.9857, 0.9860, 0.9800, 0.9843
fs: 0.9857, 0.9860, 0.9800, 0.9843
rl: 0.9857, 0.9860, 0.9800, 0.9843

0.946857142857143
0.87, 0.95, 0.94, 0.94, 0.95, 0.97, 0.94, 0.97, 0.94, 0.92, 0.97, 0.97, 0.92, 0.95, 0.92, 0.98, 0.92, 0.9, 0.94, 0.97, 0.91, 0.95, 0.97, 0.95, 0.94, 0.94, 0.95, 0.94, 0.95, 0.97, 0.98, 0.97, 0.97, 0.97, 0.98, 0.94, 0.95, 0.9, 0.94, 0.95, 0.91, 0.97, 0.94, 0.95, 0.9, 0.97, 0.94, 0.95, 0.92, 0.95, 0.9, 0.97, 0.95, 0.94, 0.92, 0.97, 0.95, 0.97, 0.94, 0.92, 0.92, 0.97, 0.95, 0.97, 0.92, 0.88, 0.92, 0.92, 0.92, 0.92, 0.95, 0.97, 0.9, 0.98, 0.94, 0.97, 0.92, 0.95, 0.94, 0.92, 0.91, 0.92, 0.97, 0.92, 0.92, 0.91, 0.95, 0.97, 0.94, 0.95, 0.94, 0.97, 0.94, 0.98, 0.95, 0.95, 0.9, 0.97, 0.94, 0.92

0.9422857142857143
0.92, 0.95, 0.94, 0.91, 0.92, 0.95, 0.97, 0.98, 0.94, 0.95, 0.95, 0.95, 0.94, 0.94, 0.88, 0.92, 0.9, 0.98, 0.95, 0.97, 0.95, 0.98, 0.95, 0.98, 0.91, 0.92, 0.91, 0.95, 0.94, 0.9, 0.97, 0.94, 0.94, 0.95, 0.92, 0.95, 0.91, 0.97, 0.92, 0.92, 0.94, 0.91, 0.94, 0.91, 0.92, 0.92, 0.95, 0.94, 0.9, 0.92, 0.92, 0.97, 0.95, 0.97, 0.92, 0.92, 0.98, 0.92, 0.95, 0.95, 0.92, 0.94, 0.92, 0.92, 0.95, 0.95, 0.94, 0.91, 0.95, 0.92, 0.92, 0.97, 0.91, 0.94, 0.97, 0.95, 0.97, 0.92, 0.91, 0.94, 0.95, 0.94, 0.94, 0.91, 0.97, 0.92, 0.94, 0.95, 0.9, 0.92, 0.92, 0.92, 0.95, 0.92, 0.88, 0.94, 0.97, 0.95, 0.95, 0.94

    accuracy, precision, recall, f_score
mv: 0.9607, 0.9619, 0.9607, 0.9568
wv: 0.9607, 0.9619, 0.9607, 0.9568
fs: 0.9571, 0.9574, 0.9524, 0.9522
rl: 0.9643, 0.9659, 0.9657, 0.9607

fs avg size: 40.25000, rl avg size: 30.77857
full test avg accu: 0.92950, test avg accu: 0.93118

training takes 36809.676 sec
