{'dataset': 'credit_card', 'algorithm': 'ptdqn', 'num_clf': 50, 'num_training': 400000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 637, 'portion': 0.5, 'sequential': False}
(30000, 31)
reading data takes 0.149 sec
number of labels: 2

Running iteration 1 of 10 fold...
[8, 0, 21, 18, 29, 28, 39]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.797407, 0.769494, 0.579486, 0.587252

    accuracy, precision, recall, f_score
max3: 0.798667, 0.765209, 0.572011, 0.578015

    accuracy, precision, recall, f_score
max1: 0.803000, 0.779385, 0.581615, 0.590539


min loss: 0.009, episode: 226000
max accu: 0.803, episode: 210000

17.02 classifiers used
    accuracy, precision, recall, f_score
mv: 0.789667, 0.784181, 0.520358, 0.482685
wv: 0.807667, 0.797496, 0.577378, 0.583454
fs: 0.800667, 0.772462, 0.590119, 0.602576
rl: 0.803000, 0.779385, 0.581615, 0.590539

0.7324933333333332
0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.72, 0.72, 0.72, 0.72, 0.69, 0.69, 0.68, 0.70, 0.69, 0.69, 0.69, 0.70, 0.69, 0.69, 0.68, 0.70, 0.69, 0.69, 0.68, 0.69

0.7376385185185186
0.77, 0.77, 0.77, 0.78, 0.77, 0.77, 0.78, 0.77, 0.78, 0.77, 0.77, 0.78, 0.77, 0.78, 0.78, 0.77, 0.77, 0.73, 0.73, 0.72, 0.73, 0.72, 0.73, 0.73, 0.72, 0.73, 0.72, 0.73, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.70, 0.69, 0.69, 0.70, 0.69, 0.70, 0.69, 0.70, 0.69, 0.69, 0.69, 0.70, 0.70, 0.70, 0.68, 0.70

0.7340066666666665
0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.73, 0.72, 0.72, 0.74, 0.74, 0.74, 0.73, 0.74, 0.72, 0.72, 0.73, 0.73, 0.74, 0.73, 0.73, 0.72, 0.73, 0.69, 0.68, 0.68, 0.70, 0.68, 0.69, 0.68, 0.70, 0.67, 0.67, 0.69, 0.70, 0.69, 0.68, 0.70, 0.67

0.7403
0.77, 0.77, 0.78, 0.78, 0.77, 0.78, 0.78, 0.77, 0.78, 0.78, 0.77, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.74, 0.74, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.73, 0.73, 0.74, 0.69, 0.70, 0.69, 0.69, 0.69, 0.69, 0.69, 0.68, 0.70, 0.71, 0.69, 0.69, 0.71, 0.71, 0.70, 0.69


Running iteration 2 of 10 fold...
[5, 0, 17, 48, 29]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.786074, 0.747714, 0.541657, 0.527131

    accuracy, precision, recall, f_score
max3: 0.795852, 0.757257, 0.540506, 0.527237

    accuracy, precision, recall, f_score
max1: 0.784000, 0.750680, 0.546935, 0.534659


min loss: 0.011, episode: 221000
max accu: 0.784, episode: 180000

1.65 classifiers used
    accuracy, precision, recall, f_score
mv: 0.778333, 0.750366, 0.514955, 0.470770
wv: 0.792667, 0.769269, 0.569313, 0.570347
fs: 0.778333, 0.733510, 0.535410, 0.515814
rl: 0.784000, 0.750680, 0.546935, 0.534659

0.734794074074074
0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.73, 0.72, 0.72, 0.73, 0.72, 0.73, 0.73, 0.72, 0.73, 0.73, 0.72, 0.73, 0.72, 0.73, 0.73, 0.72, 0.72, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.68, 0.69, 0.69, 0.69, 0.70, 0.70, 0.69, 0.70, 0.69

0.7425125925925926
0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.73, 0.73, 0.73, 0.74, 0.73, 0.73, 0.74, 0.73, 0.74, 0.74, 0.73, 0.73, 0.73, 0.74, 0.73, 0.73, 0.73, 0.70, 0.70, 0.69, 0.70, 0.70, 0.70, 0.69, 0.69, 0.70, 0.69, 0.70, 0.71, 0.71, 0.69, 0.71, 0.69

0.7292866666666667
0.76, 0.77, 0.76, 0.76, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.77, 0.76, 0.77, 0.76, 0.76, 0.76, 0.76, 0.73, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.72, 0.72, 0.67, 0.69, 0.69, 0.69, 0.7, 0.69, 0.68, 0.68, 0.69, 0.68, 0.68, 0.69, 0.68, 0.69, 0.69, 0.68

0.7322666666666667
0.77, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.73, 0.72, 0.72, 0.72, 0.72, 0.74, 0.73, 0.73, 0.71, 0.73, 0.71, 0.71, 0.72, 0.73, 0.72, 0.73, 0.73, 0.69, 0.70, 0.69, 0.69, 0.68, 0.69, 0.68, 0.70, 0.69, 0.69, 0.70, 0.68, 0.68, 0.69, 0.70, 0.69


Running iteration 3 of 10 fold...
[3, 0, 23, 13, 28, 38, 32]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.789111, 0.760791, 0.548036, 0.536425

    accuracy, precision, recall, f_score
max3: 0.797481, 0.766688, 0.546114, 0.535566

    accuracy, precision, recall, f_score
max1: 0.793333, 0.788283, 0.565353, 0.561204


min loss: 0.008, episode: 202000
max accu: 0.793, episode: 390000

4.16 classifiers used
    accuracy, precision, recall, f_score
mv: 0.779667, 0.785039, 0.524903, 0.487567
wv: 0.790333, 0.768279, 0.573592, 0.575985
fs: 0.777000, 0.744747, 0.530303, 0.502178
rl: 0.793333, 0.788283, 0.565353, 0.561204

0.7332148148148145
0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.71, 0.72, 0.73, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.72, 0.70, 0.70, 0.70, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.68, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69

0.739751111111111
0.78, 0.78, 0.78, 0.78, 0.78, 0.77, 0.78, 0.78, 0.77, 0.78, 0.78, 0.77, 0.78, 0.78, 0.78, 0.78, 0.78, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.74, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.72, 0.70, 0.70, 0.70, 0.69, 0.69, 0.69, 0.70, 0.70, 0.69, 0.69, 0.70, 0.69, 0.70, 0.69, 0.69, 0.70

0.7282733333333333
0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.76, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.73, 0.72, 0.72, 0.71, 0.72, 0.71, 0.73, 0.70, 0.73, 0.73, 0.72, 0.72, 0.73, 0.72, 0.73, 0.73, 0.74, 0.68, 0.69, 0.69, 0.69, 0.69, 0.68, 0.69, 0.69, 0.69, 0.67, 0.69, 0.70, 0.68, 0.68, 0.68, 0.69

0.7278133333333333
0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.72, 0.73, 0.71, 0.71, 0.72, 0.71, 0.72, 0.71, 0.71, 0.71, 0.71, 0.74, 0.72, 0.71, 0.72, 0.72, 0.72, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.68, 0.69, 0.68, 0.68, 0.69, 0.69, 0.68, 0.69, 0.68

    accuracy, precision, recall, f_score
mv: 0.782556, 0.773195, 0.520072, 0.480341
wv: 0.796889, 0.778348, 0.573428, 0.576595
fs: 0.785333, 0.750240, 0.551944, 0.540189
rl: 0.793444, 0.772783, 0.564634, 0.562134

fs avg size: 6.33333, rl avg size: 7.60956
full test avg accu: 0.73346, test avg accu: 0.73052

training takes 25070.691 sec
