{'dataset': 'glass', 'algorithm': 'ptdqn', 'num_clf': 50, 'num_training': 500000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 3792, 'portion': 0.5, 'sequential': False}
(214, 10)
reading data takes 0.018 sec
number of labels: 6

Running iteration 1 of 10 fold...
[14, 0, 16, 3, 12, 33, 4]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.677083, 0.735046, 0.686023, 0.628481

    accuracy, precision, recall, f_score
max3: 0.708333, 0.643849, 0.690972, 0.672673

    accuracy, precision, recall, f_score
max1: 0.590909, 1.000000, 0.098485, 0.123810


min loss: 0.007, episode: 248000
max accu: 0.591, episode: 190000

3.95 classifiers used
    accuracy, precision, recall, f_score
mv: 0.454545, 1.000000, 0.075758, 0.104167
wv: 0.454545, 1.000000, 0.075758, 0.104167
fs: 0.409091, 1.000000, 0.068182, 0.096774
rl: 0.590909, 1.000000, 0.098485, 0.123810

0.5758333333333333
0.58, 0.66, 0.53, 0.64, 0.55, 0.47, 0.65, 0.61, 0.52, 0.62, 0.59, 0.55, 0.53, 0.63, 0.67, 0.55, 0.58, 0.58, 0.52, 0.55, 0.61, 0.57, 0.54, 0.59, 0.60, 0.60, 0.53, 0.54, 0.56, 0.53, 0.65, 0.66, 0.48, 0.51, 0.55, 0.56, 0.52, 0.57, 0.56, 0.48, 0.58, 0.40, 0.62, 0.62, 0.60, 0.54, 0.62, 0.63, 0.61, 0.59

0.5891666666666666
0.60, 0.68, 0.54, 0.66, 0.58, 0.39, 0.70, 0.60, 0.5, 0.68, 0.62, 0.5, 0.60, 0.62, 0.70, 0.56, 0.66, 0.54, 0.54, 0.60, 0.54, 0.62, 0.54, 0.58, 0.68, 0.62, 0.52, 0.60, 0.52, 0.58, 0.68, 0.70, 0.47, 0.5, 0.58, 0.58, 0.58, 0.5, 0.58, 0.47, 0.66, 0.39, 0.66, 0.60, 0.62, 0.52, 0.60, 0.68, 0.62, 0.58

0.28454545454545455
0.13, 0.36, 0.18, 0.36, 0.18, 0.22, 0.63, 0.31, 0.18, 0.13, 0.13, 0.63, 0.31, 0.31, 0.54, 0.18, 0.45, 0.13, 0.09, 0.36, 0.04, 0.45, 0.31, 0.27, 0.22, 0.27, 0.22, 0.18, 0.18, 0.31, 0.36, 0.45, 0.22, 0.22, 0.40, 0.22, 0.27, 0.04, 0.36, 0.18, 0.45, 0.13, 0.27, 0.04, 0.27, 0.54, 0.13, 0.31, 0.22, 0.63

0.43545454545454537
0.31, 0.63, 0.27, 0.5, 0.63, 0.40, 0.45, 0.36, 0.27, 0.27, 0.40, 0.68, 0.59, 0.27, 0.59, 0.27, 0.45, 0.31, 0.45, 0.18, 0.5, 0.40, 0.63, 0.59, 0.13, 0.59, 0.59, 0.72, 0.5, 0.18, 0.5, 0.68, 0.31, 0.54, 0.72, 0.40, 0.40, 0.54, 0.27, 0.09, 0.45, 0.22, 0.18, 0.5, 0.59, 0.59, 0.36, 0.72, 0.31, 0.09


Running iteration 2 of 10 fold...
[21, 0, 6, 25, 13, 47]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.718750, 0.754699, 0.736901, 0.729421

    accuracy, precision, recall, f_score
max3: 0.708333, 0.745581, 0.710417, 0.725868

    accuracy, precision, recall, f_score
max1: 0.909091, 1.000000, 0.151515, 0.158730


min loss: 0.005, episode: 249000
max accu: 0.909, episode: 370000

15.00 classifiers used
    accuracy, precision, recall, f_score
mv: 0.818182, 1.000000, 0.136364, 0.150000
wv: 0.818182, 1.000000, 0.136364, 0.150000
fs: 0.772727, 1.000000, 0.128788, 0.145299
rl: 0.909091, 1.000000, 0.151515, 0.158730

0.5583333333333332
0.56, 0.58, 0.45, 0.59, 0.53, 0.57, 0.64, 0.57, 0.54, 0.5, 0.5, 0.53, 0.51, 0.55, 0.57, 0.52, 0.54, 0.62, 0.46, 0.52, 0.5, 0.66, 0.44, 0.57, 0.57, 0.60, 0.48, 0.53, 0.60, 0.52, 0.59, 0.63, 0.57, 0.59, 0.57, 0.61, 0.65, 0.53, 0.57, 0.59, 0.65, 0.52, 0.54, 0.54, 0.66, 0.58, 0.59, 0.45, 0.44, 0.55

0.58125
0.62, 0.54, 0.39, 0.64, 0.64, 0.64, 0.64, 0.56, 0.56, 0.52, 0.60, 0.47, 0.54, 0.56, 0.60, 0.54, 0.5, 0.60, 0.5, 0.62, 0.60, 0.72, 0.52, 0.60, 0.58, 0.64, 0.52, 0.5, 0.66, 0.58, 0.58, 0.62, 0.56, 0.60, 0.56, 0.64, 0.64, 0.5, 0.54, 0.62, 0.72, 0.58, 0.56, 0.60, 0.72, 0.58, 0.60, 0.45, 0.43, 0.56

0.58
0.86, 0.77, 0.81, 0.31, 0.86, 0.31, 0.54, 0.27, 0.27, 0.68, 0.59, 0.68, 0.45, 0.54, 0.77, 0.5, 0.68, 0.86, 0.63, 0.36, 0.54, 0.5, 0.63, 0.40, 0.18, 0.72, 0.68, 0.36, 0.72, 0.72, 0.5, 0.81, 0.54, 0.72, 0.45, 0.72, 0.72, 0.68, 0.68, 0.63, 0.22, 0.68, 0.81, 0.40, 0.86, 0.5, 0.59, 0.31, 0.36, 0.40

0.6245454545454545
0.5, 0.72, 0.54, 0.40, 0.90, 0.72, 0.72, 0.68, 0.59, 0.59, 0.40, 0.72, 0.59, 0.45, 0.72, 0.54, 0.54, 0.81, 0.68, 0.54, 0.5, 0.72, 0.59, 0.86, 0.81, 0.45, 0.63, 0.59, 0.59, 0.72, 0.68, 0.68, 0.59, 0.54, 0.45, 0.40, 0.72, 0.63, 0.68, 0.54, 0.86, 0.31, 0.81, 0.72, 0.59, 0.72, 0.68, 0.54, 0.59, 0.45


Running iteration 3 of 10 fold...
[29, 0, 46, 12, 41]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.593750, 0.608224, 0.631547, 0.608625

    accuracy, precision, recall, f_score
max3: 0.645833, 0.635849, 0.667361, 0.675228

    accuracy, precision, recall, f_score
max1: 0.818182, 1.000000, 0.136364, 0.150000


min loss: 0.005, episode: 259000
max accu: 0.818, episode: 180000

2.00 classifiers used
    accuracy, precision, recall, f_score
mv: 0.636364, 1.000000, 0.106061, 0.129630
wv: 0.636364, 1.000000, 0.106061, 0.129630
fs: 0.681818, 1.000000, 0.113636, 0.135135
rl: 0.818182, 1.000000, 0.136364, 0.150000

0.5624999999999999
0.65, 0.53, 0.55, 0.44, 0.5, 0.5, 0.52, 0.46, 0.54, 0.66, 0.62, 0.59, 0.53, 0.5, 0.58, 0.63, 0.56, 0.59, 0.51, 0.46, 0.63, 0.61, 0.60, 0.43, 0.47, 0.54, 0.57, 0.53, 0.61, 0.69, 0.59, 0.52, 0.62, 0.53, 0.63, 0.53, 0.64, 0.55, 0.62, 0.57, 0.57, 0.56, 0.62, 0.46, 0.63, 0.54, 0.60, 0.57, 0.39, 0.59

0.57875
0.66, 0.54, 0.56, 0.45, 0.43, 0.45, 0.58, 0.47, 0.56, 0.72, 0.62, 0.64, 0.58, 0.5, 0.64, 0.68, 0.54, 0.58, 0.60, 0.41, 0.62, 0.58, 0.62, 0.39, 0.56, 0.5, 0.60, 0.60, 0.70, 0.75, 0.66, 0.56, 0.64, 0.52, 0.62, 0.47, 0.60, 0.58, 0.64, 0.66, 0.70, 0.43, 0.54, 0.5, 0.62, 0.58, 0.68, 0.58, 0.41, 0.58

0.46454545454545454
0.90, 0.27, 0.81, 0.31, 0.36, 0.36, 0.36, 0.31, 0.36, 0.54, 0.5, 0.81, 0.31, 0.22, 0.59, 0.22, 0.54, 0.36, 0.72, 0.5, 0.59, 0.27, 0.22, 0.5, 0.54, 0.72, 0.27, 0.22, 0.54, 0.68, 0.63, 0.40, 0.40, 0.45, 0.5, 0.22, 0.45, 0.63, 0.68, 0.31, 0.5, 0.22, 0.36, 0.36, 0.72, 0.5, 0.31, 0.36, 0.59, 0.5

0.4336363636363636
0.36, 0.59, 0.31, 0.36, 0.63, 0.27, 0.40, 0.45, 0.68, 0.27, 0.31, 0.40, 0.27, 0.31, 0.40, 0.5, 0.31, 0.77, 0.22, 0.59, 0.36, 0.27, 0.45, 0.40, 0.59, 0.36, 0.36, 0.5, 0.31, 0.40, 0.5, 0.31, 0.5, 0.40, 0.5, 0.45, 0.5, 0.59, 0.5, 0.36, 0.27, 0.54, 0.45, 0.5, 0.40, 0.45, 0.45, 0.5, 0.59, 0.31


Running iteration 4 of 10 fold...
[13, 0, 7, 5, 8, 20, 19, 41, 3, 30, 18]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.645833, 0.572821, 0.657456, 0.606914

    accuracy, precision, recall, f_score
max3: 0.666667, 0.604672, 0.655214, 0.645036

    accuracy, precision, recall, f_score
max1: 0.863636, 0.922078, 0.305556, 0.272727


min loss: 0.010, episode: 241000
max accu: 0.864, episode: 10000

1.00 classifiers used
    accuracy, precision, recall, f_score
mv: 0.909091, 0.963636, 0.314815, 0.305011
wv: 0.909091, 0.963636, 0.314815, 0.305011
fs: 0.727273, 0.788636, 0.212963, 0.211329
rl: 0.863636, 0.922078, 0.305556, 0.272727

0.564375
0.53, 0.48, 0.56, 0.57, 0.64, 0.66, 0.5, 0.64, 0.54, 0.51, 0.56, 0.63, 0.48, 0.68, 0.56, 0.54, 0.53, 0.59, 0.51, 0.62, 0.63, 0.51, 0.57, 0.48, 0.60, 0.64, 0.52, 0.64, 0.52, 0.45, 0.62, 0.60, 0.41, 0.62, 0.58, 0.53, 0.51, 0.55, 0.54, 0.51, 0.57, 0.61, 0.53, 0.63, 0.45, 0.60, 0.59, 0.51, 0.58, 0.60

0.6045833333333334
0.64, 0.52, 0.60, 0.62, 0.62, 0.75, 0.54, 0.68, 0.60, 0.58, 0.56, 0.68, 0.58, 0.68, 0.62, 0.58, 0.58, 0.54, 0.5, 0.66, 0.66, 0.56, 0.60, 0.54, 0.62, 0.62, 0.56, 0.66, 0.52, 0.54, 0.64, 0.66, 0.47, 0.66, 0.62, 0.58, 0.56, 0.66, 0.58, 0.56, 0.62, 0.68, 0.58, 0.68, 0.5, 0.66, 0.58, 0.56, 0.54, 0.62

0.6236363636363635
0.59, 0.72, 0.31, 0.59, 0.81, 0.86, 0.22, 0.63, 0.5, 0.72, 0.63, 0.5, 0.59, 0.5, 0.40, 0.59, 0.77, 0.86, 0.45, 0.40, 0.68, 0.81, 0.68, 0.40, 0.59, 0.81, 0.68, 0.86, 0.54, 0.40, 0.54, 0.40, 0.54, 0.27, 0.45, 0.86, 0.54, 0.72, 0.81, 0.72, 0.68, 0.90, 0.86, 0.59, 0.59, 0.68, 0.77, 0.45, 0.77, 0.72

0.6218181818181818
0.77, 0.86, 0.90, 0.63, 0.77, 0.31, 0.45, 0.68, 0.63, 0.77, 0.45, 0.5, 0.45, 0.45, 0.63, 0.81, 0.77, 0.81, 0.36, 0.81, 0.27, 0.77, 0.63, 0.77, 0.86, 0.95, 0.59, 0.68, 0.40, 0.72, 0.0, 0.45, 0.5, 0.54, 0.54, 0.54, 0.54, 0.72, 0.54, 0.45, 0.54, 0.63, 0.95, 0.36, 0.72, 0.81, 0.72, 0.72, 0.40, 0.72


Running iteration 5 of 10 fold...
[14, 0, 6, 5, 37, 28]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.587629, 0.596693, 0.500051, 0.462557

    accuracy, precision, recall, f_score
max3: 0.530612, 0.543197, 0.516035, 0.401070

    accuracy, precision, recall, f_score
max1: 0.380952, 1.000000, 0.063492, 0.091954


min loss: 0.005, episode: 280000
max accu: 0.381, episode: 180000

1.24 classifiers used
    accuracy, precision, recall, f_score
mv: 0.190476, 1.000000, 0.031746, 0.053333
wv: 0.190476, 1.000000, 0.031746, 0.053333
fs: 0.142857, 1.000000, 0.023810, 0.041667
rl: 0.380952, 1.000000, 0.063492, 0.091954

0.6061855670103092
0.57, 0.54, 0.67, 0.58, 0.63, 0.58, 0.65, 0.49, 0.56, 0.62, 0.62, 0.62, 0.57, 0.54, 0.74, 0.67, 0.53, 0.68, 0.58, 0.62, 0.60, 0.61, 0.62, 0.59, 0.62, 0.64, 0.64, 0.67, 0.63, 0.62, 0.46, 0.70, 0.64, 0.57, 0.52, 0.60, 0.64, 0.59, 0.53, 0.59, 0.60, 0.59, 0.64, 0.51, 0.67, 0.56, 0.63, 0.49, 0.47, 0.68

0.6302040816326531
0.69, 0.61, 0.67, 0.57, 0.61, 0.61, 0.71, 0.55, 0.61, 0.59, 0.65, 0.65, 0.57, 0.57, 0.75, 0.73, 0.57, 0.67, 0.61, 0.65, 0.61, 0.63, 0.63, 0.71, 0.65, 0.69, 0.67, 0.67, 0.79, 0.71, 0.48, 0.69, 0.69, 0.59, 0.53, 0.65, 0.63, 0.63, 0.57, 0.65, 0.55, 0.57, 0.67, 0.46, 0.75, 0.51, 0.71, 0.55, 0.38, 0.69

0.2476190476190476
0.04, 0.42, 0.47, 0.23, 0.38, 0.04, 0.14, 0.09, 0.23, 0.33, 0.57, 0.19, 0.28, 0.33, 0.14, 0.04, 0.09, 0.09, 0.42, 0.23, 0.14, 0.47, 0.38, 0.09, 0.09, 0.14, 0.23, 0.33, 0.23, 0.14, 0.09, 0.28, 0.28, 0.09, 0.23, 0.23, 0.28, 0.38, 0.23, 0.42, 0.33, 0.33, 0.42, 0.23, 0.19, 0.33, 0.09, 0.42, 0.23, 0.04

0.29904761904761906
0.33, 0.57, 0.33, 0.23, 0.19, 0.47, 0.33, 0.14, 0.23, 0.23, 0.14, 0.14, 0.23, 0.52, 0.19, 0.28, 0.38, 0.19, 0.19, 0.38, 0.38, 0.19, 0.33, 0.14, 0.23, 0.47, 0.14, 0.28, 0.28, 0.14, 0.14, 0.19, 0.19, 0.38, 0.52, 0.19, 0.14, 0.33, 0.38, 0.19, 0.33, 0.52, 0.33, 0.33, 0.47, 0.42, 0.52, 0.33, 0.28, 0.33


Running iteration 6 of 10 fold...
[29, 0, 28, 6, 4, 5, 18, 12, 32, 9, 48]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.742268, 0.801876, 0.732172, 0.711315

    accuracy, precision, recall, f_score
max3: 0.816327, 0.723469, 0.783333, 0.741931

    accuracy, precision, recall, f_score
max1: 0.714286, 1.000000, 0.119048, 0.138889


min loss: 0.011, episode: 241000
max accu: 0.714, episode: 260000

49.24 classifiers used
    accuracy, precision, recall, f_score
mv: 0.523810, 1.000000, 0.087302, 0.114583
wv: 0.523810, 1.000000, 0.087302, 0.114583
fs: 0.523810, 1.000000, 0.087302, 0.114583
rl: 0.714286, 1.000000, 0.119048, 0.138889

0.5944329896907218
0.63, 0.58, 0.65, 0.50, 0.67, 0.57, 0.63, 0.65, 0.52, 0.63, 0.55, 0.51, 0.58, 0.57, 0.56, 0.54, 0.67, 0.63, 0.59, 0.58, 0.53, 0.59, 0.55, 0.61, 0.55, 0.49, 0.68, 0.59, 0.60, 0.69, 0.47, 0.67, 0.63, 0.64, 0.56, 0.53, 0.67, 0.59, 0.60, 0.60, 0.58, 0.56, 0.49, 0.59, 0.59, 0.55, 0.68, 0.49, 0.60, 0.62

0.6473469387755101
0.67, 0.61, 0.73, 0.48, 0.75, 0.63, 0.75, 0.75, 0.61, 0.67, 0.63, 0.42, 0.65, 0.61, 0.63, 0.67, 0.73, 0.73, 0.65, 0.63, 0.61, 0.69, 0.59, 0.69, 0.55, 0.57, 0.73, 0.65, 0.65, 0.75, 0.53, 0.73, 0.65, 0.73, 0.57, 0.57, 0.73, 0.69, 0.61, 0.75, 0.61, 0.63, 0.46, 0.63, 0.67, 0.57, 0.67, 0.59, 0.63, 0.69

0.5161904761904762
0.47, 0.57, 0.52, 0.57, 0.38, 0.42, 0.42, 0.61, 0.33, 0.61, 0.71, 0.57, 0.61, 0.66, 0.38, 0.52, 0.66, 0.42, 0.42, 0.52, 0.19, 0.57, 0.61, 0.57, 0.57, 0.47, 0.38, 0.66, 0.61, 0.52, 0.47, 0.42, 0.47, 0.52, 0.52, 0.71, 0.52, 0.57, 0.57, 0.42, 0.42, 0.71, 0.42, 0.57, 0.38, 0.52, 0.57, 0.33, 0.61, 0.33

0.4761904761904761
0.47, 0.38, 0.42, 0.66, 0.47, 0.42, 0.42, 0.38, 0.61, 0.42, 0.66, 0.42, 0.61, 0.42, 0.57, 0.71, 0.52, 0.52, 0.42, 0.52, 0.61, 0.38, 0.47, 0.47, 0.61, 0.42, 0.52, 0.42, 0.80, 0.33, 0.28, 0.57, 0.42, 0.47, 0.47, 0.47, 0.57, 0.42, 0.52, 0.42, 0.33, 0.42, 0.61, 0.23, 0.23, 0.28, 0.38, 0.47, 0.42, 0.47


Running iteration 7 of 10 fold...
[32, 0, 8, 28, 37, 23]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.659794, 0.708397, 0.622475, 0.591332

    accuracy, precision, recall, f_score
max3: 0.734694, 0.750814, 0.741667, 0.722160

    accuracy, precision, recall, f_score
max1: 0.666667, 0.592593, 0.145833, 0.137255


min loss: 0.008, episode: 258000
max accu: 0.667, episode: 210000

8.29 classifiers used
    accuracy, precision, recall, f_score
mv: 0.476190, 0.544218, 0.104167, 0.111111
wv: 0.476190, 0.544218, 0.104167, 0.111111
fs: 0.523810, 0.644689, 0.114583, 0.126437
rl: 0.666667, 0.592593, 0.145833, 0.137255

0.6107216494845361
0.55, 0.60, 0.59, 0.67, 0.58, 0.67, 0.65, 0.60, 0.60, 0.50, 0.62, 0.50, 0.55, 0.59, 0.55, 0.60, 0.56, 0.69, 0.64, 0.58, 0.62, 0.47, 0.58, 0.56, 0.60, 0.70, 0.59, 0.62, 0.53, 0.63, 0.53, 0.61, 0.72, 0.58, 0.68, 0.59, 0.60, 0.62, 0.51, 0.59, 0.62, 0.55, 0.58, 0.71, 0.69, 0.55, 0.61, 0.71, 0.67, 0.72

0.6546938775510205
0.61, 0.63, 0.67, 0.75, 0.61, 0.67, 0.73, 0.69, 0.67, 0.53, 0.63, 0.57, 0.65, 0.61, 0.57, 0.57, 0.65, 0.79, 0.65, 0.69, 0.71, 0.48, 0.63, 0.59, 0.71, 0.69, 0.59, 0.67, 0.57, 0.73, 0.65, 0.65, 0.79, 0.59, 0.75, 0.59, 0.67, 0.67, 0.55, 0.67, 0.67, 0.57, 0.63, 0.79, 0.71, 0.53, 0.65, 0.69, 0.73, 0.71

0.4676190476190476
0.52, 0.66, 0.42, 0.52, 0.47, 0.38, 0.61, 0.28, 0.61, 0.42, 0.42, 0.47, 0.42, 0.52, 0.52, 0.42, 0.47, 0.23, 0.52, 0.47, 0.28, 0.61, 0.57, 0.23, 0.47, 0.52, 0.52, 0.33, 0.42, 0.47, 0.38, 0.38, 0.57, 0.71, 0.38, 0.47, 0.57, 0.52, 0.57, 0.28, 0.38, 0.57, 0.42, 0.38, 0.47, 0.66, 0.47, 0.42, 0.38, 0.38

0.519047619047619
0.66, 0.38, 0.47, 0.52, 0.47, 0.52, 0.61, 0.23, 0.52, 0.57, 0.47, 0.33, 0.61, 0.42, 0.33, 0.57, 0.47, 0.47, 0.47, 0.47, 0.42, 0.61, 0.61, 0.57, 0.47, 0.52, 0.57, 0.47, 0.52, 0.61, 0.47, 0.57, 0.57, 0.57, 0.38, 0.66, 0.61, 0.47, 0.57, 0.57, 0.42, 0.47, 0.57, 0.66, 0.66, 0.42, 0.61, 0.57, 0.47, 0.47


Running iteration 8 of 10 fold...
[4, 0, 7]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.701031, 0.714780, 0.501515, 0.515336

    accuracy, precision, recall, f_score
max3: 0.755102, 0.732839, 0.566667, 0.563030

    accuracy, precision, recall, f_score
max1: 0.380952, 0.428571, 0.148148, 0.156863


min loss: 0.004, episode: 273000
max accu: 0.381, episode: 20000

2.19 classifiers used
    accuracy, precision, recall, f_score
mv: 0.142857, 1.000000, 0.050926, 0.086247
wv: 0.095238, 0.428571, 0.037037, 0.060606
fs: 0.380952, 1.000000, 0.143519, 0.171474
rl: 0.380952, 0.428571, 0.148148, 0.156863

0.6331958762886598
0.58, 0.61, 0.57, 0.65, 0.73, 0.59, 0.53, 0.59, 0.67, 0.70, 0.68, 0.62, 0.69, 0.70, 0.63, 0.65, 0.70, 0.64, 0.68, 0.58, 0.62, 0.58, 0.64, 0.64, 0.62, 0.65, 0.57, 0.71, 0.64, 0.59, 0.61, 0.63, 0.67, 0.45, 0.61, 0.58, 0.63, 0.56, 0.62, 0.65, 0.57, 0.59, 0.60, 0.58, 0.65, 0.65, 0.67, 0.64, 0.62, 0.70

0.6644897959183673
0.57, 0.63, 0.63, 0.63, 0.77, 0.65, 0.61, 0.61, 0.73, 0.71, 0.71, 0.69, 0.71, 0.77, 0.65, 0.71, 0.73, 0.63, 0.73, 0.65, 0.63, 0.63, 0.71, 0.61, 0.67, 0.69, 0.59, 0.77, 0.61, 0.61, 0.69, 0.65, 0.67, 0.57, 0.63, 0.59, 0.57, 0.63, 0.65, 0.67, 0.59, 0.67, 0.65, 0.59, 0.71, 0.69, 0.71, 0.69, 0.71, 0.69

0.21999999999999997
0.09, 0.09, 0.33, 0.33, 0.42, 0.38, 0.14, 0.0, 0.38, 0.23, 0.14, 0.38, 0.38, 0.28, 0.28, 0.38, 0.04, 0.28, 0.23, 0.19, 0.19, 0.47, 0.14, 0.23, 0.04, 0.09, 0.19, 0.38, 0.19, 0.28, 0.09, 0.09, 0.04, 0.19, 0.38, 0.28, 0.23, 0.09, 0.23, 0.23, 0.38, 0.19, 0.04, 0.14, 0.0, 0.38, 0.0, 0.09, 0.19, 0.38

0.2009523809523809
0.23, 0.38, 0.14, 0.14, 0.33, 0.23, 0.04, 0.47, 0.28, 0.28, 0.09, 0.04, 0.04, 0.19, 0.19, 0.23, 0.28, 0.38, 0.42, 0.23, 0.23, 0.19, 0.23, 0.19, 0.09, 0.09, 0.14, 0.19, 0.14, 0.19, 0.09, 0.14, 0.04, 0.19, 0.04, 0.19, 0.09, 0.42, 0.33, 0.09, 0.14, 0.19, 0.19, 0.04, 0.28, 0.23, 0.19, 0.23, 0.19, 0.23


Running iteration 9 of 10 fold...
[23, 0, 12, 21, 6, 16, 15, 27, 10]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.762887, 0.766283, 0.578493, 0.582152

    accuracy, precision, recall, f_score
max3: 0.755102, 0.750047, 0.422619, 0.412913

    accuracy, precision, recall, f_score
max1: 0.333333, 0.368254, 0.208333, 0.206349


min loss: 0.006, episode: 254000
max accu: 0.333, episode: 10000

14.48 classifiers used
    accuracy, precision, recall, f_score
mv: 0.238095, 0.476190, 0.145833, 0.194444
wv: 0.238095, 0.476190, 0.145833, 0.194444
fs: 0.238095, 0.317460, 0.145833, 0.166667
rl: 0.333333, 0.368254, 0.208333, 0.206349

0.6222680412371134
0.62, 0.58, 0.46, 0.63, 0.55, 0.65, 0.59, 0.63, 0.58, 0.65, 0.59, 0.52, 0.72, 0.50, 0.65, 0.57, 0.65, 0.69, 0.60, 0.71, 0.55, 0.67, 0.53, 0.74, 0.68, 0.62, 0.64, 0.73, 0.64, 0.63, 0.65, 0.62, 0.62, 0.67, 0.56, 0.67, 0.61, 0.56, 0.55, 0.59, 0.62, 0.59, 0.57, 0.67, 0.54, 0.63, 0.56, 0.61, 0.67, 0.67

0.6191836734693877
0.67, 0.51, 0.42, 0.65, 0.57, 0.67, 0.57, 0.57, 0.55, 0.65, 0.63, 0.48, 0.71, 0.48, 0.69, 0.59, 0.73, 0.71, 0.69, 0.67, 0.61, 0.69, 0.42, 0.73, 0.63, 0.69, 0.69, 0.75, 0.65, 0.61, 0.65, 0.57, 0.57, 0.63, 0.53, 0.61, 0.61, 0.53, 0.57, 0.69, 0.61, 0.65, 0.65, 0.61, 0.55, 0.67, 0.57, 0.55, 0.69, 0.61

0.2209523809523809
0.19, 0.19, 0.19, 0.14, 0.23, 0.19, 0.33, 0.23, 0.19, 0.28, 0.23, 0.09, 0.28, 0.14, 0.14, 0.19, 0.19, 0.23, 0.19, 0.28, 0.19, 0.23, 0.28, 0.19, 0.23, 0.23, 0.19, 0.33, 0.28, 0.23, 0.14, 0.19, 0.28, 0.28, 0.23, 0.23, 0.23, 0.09, 0.28, 0.23, 0.28, 0.19, 0.19, 0.28, 0.28, 0.23, 0.19, 0.19, 0.19, 0.14

0.2542857142857142
0.33, 0.23, 0.28, 0.19, 0.33, 0.19, 0.28, 0.23, 0.23, 0.42, 0.23, 0.23, 0.19, 0.23, 0.33, 0.23, 0.19, 0.28, 0.28, 0.28, 0.42, 0.33, 0.42, 0.23, 0.33, 0.28, 0.23, 0.33, 0.19, 0.19, 0.19, 0.23, 0.19, 0.19, 0.14, 0.28, 0.19, 0.19, 0.23, 0.23, 0.19, 0.28, 0.33, 0.28, 0.14, 0.19, 0.33, 0.19, 0.23, 0.14


Running iteration 10 of 10 fold...
[11, 0, 3, 27, 45, 36, 46, 12]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.701031, 0.725161, 0.548846, 0.587687

    accuracy, precision, recall, f_score
max3: 0.653061, 0.659568, 0.460714, 0.466146

    accuracy, precision, recall, f_score
max1: 0.761905, 1.000000, 0.126984, 0.144144


min loss: 0.005, episode: 228000
max accu: 0.762, episode: 190000

30.71 classifiers used
    accuracy, precision, recall, f_score
mv: 0.952381, 1.000000, 0.158730, 0.162602
wv: 0.952381, 1.000000, 0.158730, 0.162602
fs: 0.666667, 1.000000, 0.111111, 0.133333
rl: 0.761905, 1.000000, 0.126984, 0.144144

0.543917525773196
0.49, 0.55, 0.53, 0.61, 0.54, 0.52, 0.60, 0.57, 0.52, 0.55, 0.51, 0.67, 0.56, 0.50, 0.51, 0.46, 0.52, 0.60, 0.47, 0.49, 0.57, 0.49, 0.56, 0.49, 0.51, 0.52, 0.59, 0.64, 0.49, 0.49, 0.52, 0.44, 0.56, 0.57, 0.63, 0.52, 0.62, 0.52, 0.45, 0.52, 0.63, 0.49, 0.44, 0.54, 0.49, 0.67, 0.62, 0.45, 0.56, 0.54

0.49551020408163265
0.36, 0.55, 0.53, 0.63, 0.42, 0.44, 0.55, 0.55, 0.48, 0.57, 0.48, 0.61, 0.51, 0.46, 0.48, 0.38, 0.44, 0.48, 0.44, 0.48, 0.57, 0.42, 0.57, 0.40, 0.42, 0.40, 0.55, 0.59, 0.44, 0.42, 0.44, 0.46, 0.46, 0.51, 0.63, 0.53, 0.59, 0.48, 0.40, 0.46, 0.57, 0.42, 0.40, 0.53, 0.40, 0.67, 0.55, 0.44, 0.53, 0.40

0.3219047619047619
0.85, 0.47, 0.71, 0.38, 0.0, 0.0, 0.52, 0.38, 0.33, 0.38, 0.95, 0.0, 0.28, 0.80, 0.0, 0.76, 0.0, 0.0, 0.52, 0.14, 0.14, 0.28, 0.0, 0.47, 0.04, 0.0, 0.90, 0.0, 0.04, 0.90, 0.85, 0.38, 0.14, 0.0, 0.0, 0.0, 0.0, 0.04, 0.23, 0.04, 0.90, 0.0, 0.04, 0.80, 0.38, 0.90, 0.66, 0.33, 0.0, 0.0

0.6780952380952381
0.95, 0.76, 0.85, 0.90, 0.95, 0.90, 0.71, 0.47, 0.0, 0.76, 0.85, 0.19, 0.61, 0.95, 0.90, 0.47, 0.52, 0.47, 0.52, 0.47, 0.90, 0.19, 0.95, 0.28, 0.28, 0.95, 0.47, 0.42, 0.66, 0.90, 0.90, 0.90, 0.95, 0.90, 0.61, 0.95, 0.90, 0.85, 0.71, 0.90, 0.95, 0.57, 0.90, 0.90, 0.0, 0.14, 0.66, 0.38, 0.80, 0.61

    accuracy, precision, recall, f_score
mv: 0.534199, 0.898404, 0.121170, 0.141113
wv: 0.529437, 0.841262, 0.119781, 0.138549
fs: 0.506710, 0.875079, 0.114973, 0.134270
rl: 0.641991, 0.831150, 0.150376, 0.158072

fs avg size: 7.20000, rl avg size: 12.80974
full test avg accu: 0.45431, test avg accu: 0.39470

training takes 41272.864 sec
