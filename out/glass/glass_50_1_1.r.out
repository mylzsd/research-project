{'dataset': 'glass', 'algorithm': 'ptdqn', 'num_clf': 50, 'num_training': 500000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 9720, 'portion': 0.5, 'sequential': False}
(214, 10)
reading data takes 0.009 sec
number of labels: 6

Running iteration 1 of 10 fold...
[31, 0, 4, 10, 25, 2, 41, 8, 1, 43, 29, 48, 22, 7]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.718750, 0.753632, 0.705281, 0.701458

    accuracy, precision, recall, f_score
max3: 0.729167, 0.753064, 0.803247, 0.809143

    accuracy, precision, recall, f_score
max1: 0.590909, 1.000000, 0.590909, 0.742857


min loss: 0.006, episode: 271000
max accu: 0.719, episode: 220000

13.45 classifiers used
    accuracy, precision, recall, f_score
mv: 0.500000, 1.000000, 0.500000, 0.666667
wv: 0.500000, 1.000000, 0.500000, 0.666667
fs: 0.590909, 1.000000, 0.590909, 0.742857
rl: 0.590909, 1.000000, 0.590909, 0.742857

0.5820833333333333
0.60, 0.58, 0.58, 0.57, 0.62, 0.47, 0.63, 0.55, 0.61, 0.51, 0.54, 0.46, 0.58, 0.60, 0.52, 0.64, 0.52, 0.61, 0.58, 0.56, 0.52, 0.51, 0.45, 0.56, 0.57, 0.62, 0.61, 0.61, 0.58, 0.59, 0.64, 0.65, 0.61, 0.55, 0.62, 0.55, 0.61, 0.62, 0.52, 0.60, 0.56, 0.61, 0.58, 0.61, 0.59, 0.59, 0.55, 0.65, 0.61, 0.64

0.5733333333333335
0.56, 0.68, 0.60, 0.56, 0.58, 0.45, 0.62, 0.60, 0.60, 0.45, 0.60, 0.5, 0.56, 0.64, 0.45, 0.68, 0.52, 0.54, 0.54, 0.5, 0.43, 0.5, 0.43, 0.56, 0.54, 0.64, 0.60, 0.58, 0.54, 0.58, 0.70, 0.64, 0.62, 0.47, 0.60, 0.56, 0.64, 0.64, 0.52, 0.60, 0.58, 0.56, 0.58, 0.54, 0.58, 0.58, 0.58, 0.64, 0.54, 0.66

0.48909090909090913
0.54, 0.31, 0.68, 0.40, 0.59, 0.45, 0.45, 0.31, 0.68, 0.04, 0.72, 0.31, 0.40, 0.5, 0.27, 0.68, 0.86, 0.36, 0.54, 0.45, 0.40, 0.36, 0.54, 0.40, 0.63, 0.36, 0.72, 0.77, 0.27, 0.59, 0.54, 0.31, 0.31, 0.63, 0.5, 0.45, 0.59, 0.59, 0.22, 0.59, 0.63, 0.45, 0.54, 0.54, 0.36, 0.45, 0.22, 0.59, 0.72, 0.40

0.42272727272727273
0.27, 0.59, 0.27, 0.27, 0.54, 0.45, 0.18, 0.31, 0.40, 0.31, 0.36, 0.36, 0.63, 0.31, 0.63, 0.45, 0.63, 0.59, 0.31, 0.13, 0.72, 0.18, 0.54, 0.45, 0.59, 0.36, 0.31, 0.22, 0.31, 0.59, 0.13, 0.36, 0.59, 0.54, 0.63, 0.59, 0.54, 0.59, 0.31, 0.40, 0.22, 0.18, 0.40, 0.36, 0.45, 0.40, 0.5, 0.81, 0.18, 0.45


Running iteration 2 of 10 fold...
[20, 0, 13, 4]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.687500, 0.776551, 0.703287, 0.684933

    accuracy, precision, recall, f_score
max3: 0.687500, 0.697669, 0.783247, 0.774206

    accuracy, precision, recall, f_score
max1: 0.818182, 1.000000, 0.818182, 0.900000


min loss: 0.005, episode: 268000
max accu: 0.688, episode: 430000

9.23 classifiers used
    accuracy, precision, recall, f_score
mv: 0.909091, 1.000000, 0.909091, 0.952381
wv: 0.909091, 1.000000, 0.909091, 0.952381
fs: 0.681818, 1.000000, 0.681818, 0.810811
rl: 0.818182, 1.000000, 0.818182, 0.900000

0.5566666666666666
0.48, 0.55, 0.54, 0.53, 0.58, 0.48, 0.51, 0.59, 0.55, 0.52, 0.62, 0.59, 0.62, 0.54, 0.55, 0.5, 0.62, 0.58, 0.58, 0.56, 0.64, 0.57, 0.46, 0.57, 0.56, 0.60, 0.51, 0.52, 0.45, 0.61, 0.63, 0.55, 0.48, 0.55, 0.54, 0.55, 0.51, 0.51, 0.59, 0.58, 0.57, 0.5, 0.55, 0.63, 0.57, 0.45, 0.58, 0.63, 0.55, 0.56

0.53875
0.47, 0.43, 0.47, 0.47, 0.56, 0.5, 0.54, 0.5, 0.58, 0.5, 0.60, 0.47, 0.66, 0.54, 0.5, 0.54, 0.58, 0.54, 0.5, 0.58, 0.62, 0.56, 0.54, 0.58, 0.58, 0.56, 0.54, 0.52, 0.41, 0.60, 0.56, 0.47, 0.47, 0.5, 0.56, 0.58, 0.52, 0.56, 0.60, 0.5, 0.52, 0.43, 0.58, 0.62, 0.54, 0.47, 0.54, 0.62, 0.54, 0.54

0.7
1.0, 0.77, 0.90, 0.77, 0.63, 0.59, 0.68, 0.77, 0.59, 0.27, 0.63, 0.5, 0.81, 0.86, 0.90, 0.54, 0.86, 0.90, 0.63, 0.40, 0.27, 0.81, 0.86, 0.72, 0.77, 0.81, 0.90, 0.68, 0.81, 0.59, 0.36, 0.77, 0.5, 0.68, 0.68, 1.0, 0.45, 0.5, 0.95, 0.72, 0.36, 0.86, 0.77, 0.63, 0.77, 0.68, 0.90, 0.54, 0.63, 0.81

0.6463636363636363
0.5, 0.22, 0.81, 0.72, 0.59, 0.68, 0.81, 0.40, 0.77, 0.54, 0.68, 0.5, 0.63, 0.59, 0.45, 0.77, 0.59, 0.77, 0.72, 0.72, 0.86, 0.63, 0.81, 0.77, 0.54, 0.63, 0.68, 0.72, 0.54, 0.68, 0.5, 0.86, 0.68, 0.81, 0.72, 0.54, 0.54, 0.63, 0.72, 0.68, 0.63, 0.68, 0.45, 0.68, 0.22, 0.72, 0.54, 0.59, 0.81, 0.77


Running iteration 3 of 10 fold...
[19, 0, 46, 44, 5, 35, 22, 36]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.729167, 0.803879, 0.677625, 0.662890

    accuracy, precision, recall, f_score
max3: 0.687500, 0.678972, 0.661429, 0.625464

    accuracy, precision, recall, f_score
max1: 0.681818, 1.000000, 0.681818, 0.810811


min loss: 0.008, episode: 235000
max accu: 0.729, episode: 210000

42.73 classifiers used
    accuracy, precision, recall, f_score
mv: 0.636364, 1.000000, 0.636364, 0.777778
wv: 0.636364, 1.000000, 0.636364, 0.777778
fs: 0.636364, 1.000000, 0.636364, 0.777778
rl: 0.681818, 1.000000, 0.681818, 0.810811

0.5604166666666666
0.59, 0.55, 0.48, 0.52, 0.51, 0.5, 0.40, 0.56, 0.61, 0.54, 0.47, 0.54, 0.65, 0.52, 0.48, 0.65, 0.5, 0.56, 0.52, 0.68, 0.62, 0.55, 0.57, 0.55, 0.62, 0.57, 0.61, 0.63, 0.61, 0.46, 0.68, 0.53, 0.47, 0.51, 0.55, 0.57, 0.54, 0.55, 0.65, 0.45, 0.58, 0.62, 0.54, 0.47, 0.60, 0.53, 0.59, 0.64, 0.52, 0.61

0.56125
0.64, 0.47, 0.5, 0.58, 0.5, 0.47, 0.41, 0.56, 0.52, 0.60, 0.54, 0.54, 0.62, 0.52, 0.5, 0.62, 0.54, 0.62, 0.54, 0.70, 0.56, 0.5, 0.56, 0.60, 0.62, 0.56, 0.60, 0.58, 0.60, 0.5, 0.75, 0.56, 0.5, 0.52, 0.52, 0.62, 0.58, 0.52, 0.60, 0.45, 0.62, 0.60, 0.52, 0.45, 0.62, 0.43, 0.62, 0.62, 0.52, 0.60

0.4281818181818181
0.40, 0.54, 0.5, 0.22, 0.5, 0.22, 0.18, 0.40, 0.54, 0.36, 0.13, 0.45, 0.5, 0.22, 0.59, 0.63, 0.59, 0.40, 0.45, 0.5, 0.36, 0.31, 0.27, 0.27, 0.27, 0.31, 0.31, 0.36, 0.81, 0.31, 0.54, 0.59, 0.40, 0.31, 0.54, 0.54, 0.5, 0.59, 0.40, 0.59, 0.22, 0.54, 0.18, 0.68, 0.40, 0.45, 0.63, 0.27, 0.59, 0.31

0.4572727272727273
0.45, 0.13, 0.40, 0.36, 0.5, 0.40, 0.27, 0.22, 0.40, 0.27, 0.36, 0.36, 0.40, 0.59, 0.68, 0.5, 0.68, 0.68, 0.59, 0.40, 0.68, 0.5, 0.22, 0.40, 0.59, 0.59, 0.36, 0.5, 0.59, 0.59, 0.63, 0.36, 0.40, 0.40, 0.5, 0.40, 0.45, 0.45, 0.22, 0.5, 0.63, 0.27, 0.5, 0.54, 0.27, 0.63, 0.59, 0.54, 0.31, 0.40


Running iteration 4 of 10 fold...
[49, 0, 1, 17, 29, 3, 35, 33]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.760417, 0.819876, 0.713860, 0.720908

    accuracy, precision, recall, f_score
max3: 0.812500, 0.775568, 0.796429, 0.826539

    accuracy, precision, recall, f_score
max1: 0.727273, 0.788636, 0.638889, 0.633987


min loss: 0.006, episode: 253000
max accu: 0.760, episode: 330000

34.73 classifiers used
    accuracy, precision, recall, f_score
mv: 0.863636, 0.963636, 0.916667, 0.898990
wv: 0.863636, 0.963636, 0.916667, 0.898990
fs: 0.590909, 0.690909, 0.458333, 0.474747
rl: 0.727273, 0.788636, 0.638889, 0.633987

0.595
0.54, 0.66, 0.56, 0.67, 0.54, 0.56, 0.59, 0.5, 0.64, 0.53, 0.54, 0.61, 0.60, 0.53, 0.54, 0.68, 0.62, 0.65, 0.61, 0.5, 0.64, 0.55, 0.63, 0.57, 0.55, 0.61, 0.57, 0.63, 0.55, 0.66, 0.65, 0.68, 0.62, 0.66, 0.63, 0.60, 0.61, 0.56, 0.5, 0.59, 0.57, 0.57, 0.54, 0.46, 0.58, 0.56, 0.66, 0.56, 0.59, 0.73

0.6124999999999999
0.54, 0.75, 0.56, 0.64, 0.45, 0.60, 0.58, 0.54, 0.58, 0.58, 0.60, 0.58, 0.58, 0.52, 0.54, 0.77, 0.64, 0.64, 0.58, 0.56, 0.75, 0.60, 0.66, 0.58, 0.60, 0.66, 0.60, 0.64, 0.5, 0.72, 0.68, 0.64, 0.68, 0.62, 0.70, 0.58, 0.66, 0.60, 0.56, 0.60, 0.60, 0.60, 0.5, 0.47, 0.64, 0.47, 0.68, 0.66, 0.62, 0.70

0.47818181818181815
0.45, 0.36, 0.59, 0.27, 0.13, 0.90, 0.45, 0.22, 0.18, 0.68, 0.63, 0.13, 0.54, 0.31, 0.45, 0.63, 0.72, 0.68, 0.5, 0.31, 0.27, 0.45, 0.45, 0.72, 0.45, 0.36, 0.5, 0.5, 0.45, 0.45, 0.90, 0.54, 0.18, 0.45, 0.59, 0.54, 0.31, 0.95, 0.27, 0.59, 0.63, 0.18, 0.31, 0.31, 0.45, 0.27, 0.81, 0.81, 0.40, 0.45

0.5918181818181819
0.40, 0.68, 0.63, 0.68, 0.72, 0.81, 0.63, 0.86, 0.45, 0.81, 0.68, 0.68, 0.77, 0.77, 0.40, 0.54, 0.31, 0.63, 0.72, 0.77, 0.59, 0.77, 0.63, 0.63, 0.40, 0.31, 0.36, 0.45, 0.5, 0.31, 0.63, 0.45, 0.5, 0.63, 0.81, 0.90, 0.59, 0.40, 0.81, 0.90, 0.45, 0.22, 0.31, 0.40, 0.90, 0.40, 0.63, 0.18, 0.40, 0.90


Running iteration 5 of 10 fold...
[11, 0, 16, 17, 6, 13, 8]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.762887, 0.692338, 0.896481, 0.868156

    accuracy, precision, recall, f_score
max3: 0.775510, 0.753721, 0.867843, 0.860542

    accuracy, precision, recall, f_score
max1: 0.285714, 1.000000, 0.285714, 0.444444


min loss: 0.005, episode: 253000
max accu: 0.763, episode: 490000

6.95 classifiers used
    accuracy, precision, recall, f_score
mv: 0.285714, 1.000000, 0.285714, 0.444444
wv: 0.285714, 1.000000, 0.285714, 0.444444
fs: 0.285714, 1.000000, 0.285714, 0.444444
rl: 0.285714, 1.000000, 0.285714, 0.444444

0.583298969072165
0.52, 0.56, 0.51, 0.59, 0.63, 0.53, 0.62, 0.61, 0.55, 0.42, 0.59, 0.68, 0.51, 0.57, 0.59, 0.57, 0.61, 0.67, 0.63, 0.53, 0.53, 0.57, 0.56, 0.59, 0.55, 0.63, 0.57, 0.58, 0.63, 0.56, 0.55, 0.64, 0.55, 0.54, 0.50, 0.62, 0.65, 0.57, 0.60, 0.52, 0.59, 0.61, 0.65, 0.58, 0.65, 0.61, 0.53, 0.49, 0.53, 0.57

0.5914285714285714
0.53, 0.51, 0.44, 0.55, 0.69, 0.55, 0.63, 0.61, 0.61, 0.42, 0.65, 0.67, 0.51, 0.59, 0.59, 0.61, 0.57, 0.73, 0.69, 0.46, 0.48, 0.53, 0.61, 0.61, 0.63, 0.69, 0.61, 0.53, 0.67, 0.59, 0.53, 0.69, 0.55, 0.61, 0.51, 0.61, 0.69, 0.61, 0.65, 0.53, 0.61, 0.63, 0.67, 0.59, 0.71, 0.65, 0.51, 0.44, 0.48, 0.59

0.2780952380952381
0.14, 0.19, 0.23, 0.09, 0.38, 0.09, 0.47, 0.23, 0.52, 0.38, 0.47, 0.23, 0.23, 0.42, 0.19, 0.28, 0.38, 0.38, 0.28, 0.23, 0.04, 0.19, 0.14, 0.28, 0.47, 0.52, 0.23, 0.28, 0.19, 0.42, 0.38, 0.23, 0.19, 0.28, 0.09, 0.04, 0.42, 0.19, 0.38, 0.19, 0.19, 0.14, 0.52, 0.23, 0.38, 0.38, 0.19, 0.09, 0.33, 0.28

0.30761904761904757
0.38, 0.28, 0.47, 0.38, 0.28, 0.38, 0.19, 0.14, 0.47, 0.28, 0.28, 0.23, 0.33, 0.23, 0.28, 0.38, 0.04, 0.33, 0.57, 0.33, 0.04, 0.23, 0.33, 0.28, 0.28, 0.38, 0.09, 0.23, 0.38, 0.28, 0.52, 0.42, 0.38, 0.33, 0.23, 0.04, 0.14, 0.38, 0.33, 0.33, 0.28, 0.19, 0.28, 0.14, 0.42, 0.38, 0.33, 0.47, 0.33, 0.47


Running iteration 6 of 10 fold...
[37, 0, 43, 1, 2, 8, 17, 29, 5]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.752577, 0.676117, 0.860556, 0.847907

    accuracy, precision, recall, f_score
max3: 0.775510, 0.731625, 0.810637, 0.809781

    accuracy, precision, recall, f_score
max1: 0.380952, 1.000000, 0.380952, 0.551724


min loss: 0.005, episode: 284000
max accu: 0.753, episode: 410000

7.71 classifiers used
    accuracy, precision, recall, f_score
mv: 0.619048, 1.000000, 0.619048, 0.764706
wv: 0.619048, 1.000000, 0.619048, 0.764706
fs: 0.476190, 1.000000, 0.476190, 0.645161
rl: 0.380952, 1.000000, 0.380952, 0.551724

0.5643298969072166
0.56, 0.63, 0.57, 0.52, 0.58, 0.56, 0.48, 0.50, 0.67, 0.47, 0.46, 0.52, 0.53, 0.58, 0.52, 0.49, 0.53, 0.62, 0.64, 0.49, 0.50, 0.50, 0.57, 0.57, 0.62, 0.47, 0.53, 0.60, 0.58, 0.64, 0.59, 0.62, 0.49, 0.54, 0.57, 0.56, 0.55, 0.71, 0.62, 0.48, 0.55, 0.48, 0.47, 0.64, 0.60, 0.56, 0.65, 0.53, 0.60, 0.58

0.5840816326530613
0.63, 0.65, 0.63, 0.55, 0.61, 0.63, 0.40, 0.57, 0.75, 0.44, 0.48, 0.51, 0.55, 0.55, 0.61, 0.48, 0.53, 0.63, 0.69, 0.46, 0.55, 0.53, 0.55, 0.57, 0.65, 0.46, 0.57, 0.65, 0.63, 0.65, 0.65, 0.65, 0.53, 0.53, 0.51, 0.59, 0.57, 0.71, 0.67, 0.53, 0.55, 0.57, 0.46, 0.75, 0.67, 0.61, 0.69, 0.53, 0.57, 0.55

0.38095238095238093
0.28, 0.52, 0.28, 0.28, 0.28, 0.33, 0.28, 0.47, 0.42, 0.33, 0.28, 0.38, 0.33, 0.42, 0.42, 0.42, 0.61, 0.61, 0.38, 0.47, 0.33, 0.19, 0.61, 0.61, 0.42, 0.23, 0.38, 0.52, 0.47, 0.33, 0.23, 0.33, 0.38, 0.33, 0.23, 0.33, 0.19, 0.42, 0.38, 0.47, 0.42, 0.23, 0.38, 0.47, 0.19, 0.38, 0.42, 0.33, 0.57, 0.23

0.4733333333333334
0.57, 0.61, 0.33, 0.57, 0.52, 0.47, 0.38, 0.38, 0.47, 0.28, 0.23, 0.66, 0.57, 0.38, 0.57, 0.38, 0.52, 0.47, 0.33, 0.42, 0.38, 0.28, 0.33, 0.52, 0.33, 0.47, 0.42, 0.52, 0.28, 0.38, 0.33, 0.42, 0.57, 0.66, 0.47, 0.28, 0.42, 0.76, 0.52, 0.61, 0.61, 0.57, 0.71, 0.47, 0.47, 0.47, 0.57, 0.57, 0.38, 0.57


Running iteration 7 of 10 fold...
[40, 0, 15, 17, 18, 3]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.773196, 0.708708, 0.870000, 0.836680

    accuracy, precision, recall, f_score
max3: 0.816327, 0.765538, 0.891373, 0.882562

    accuracy, precision, recall, f_score
max1: 0.380952, 0.677249, 0.500000, 0.640000


min loss: 0.008, episode: 254000
max accu: 0.773, episode: 370000

9.76 classifiers used
    accuracy, precision, recall, f_score
mv: 0.666667, 0.857143, 0.506250, 0.572917
wv: 0.666667, 0.857143, 0.506250, 0.572917
fs: 0.428571, 0.623377, 0.562500, 0.666667
rl: 0.380952, 0.677249, 0.500000, 0.640000

0.5979381443298969
0.50, 0.54, 0.56, 0.59, 0.60, 0.57, 0.55, 0.56, 0.57, 0.61, 0.56, 0.60, 0.46, 0.56, 0.56, 0.68, 0.60, 0.59, 0.61, 0.63, 0.68, 0.64, 0.62, 0.62, 0.61, 0.44, 0.55, 0.59, 0.58, 0.56, 0.61, 0.59, 0.62, 0.59, 0.63, 0.53, 0.69, 0.57, 0.62, 0.56, 0.73, 0.55, 0.56, 0.64, 0.61, 0.56, 0.62, 0.65, 0.61, 0.61

0.6073469387755103
0.48, 0.57, 0.51, 0.57, 0.63, 0.55, 0.57, 0.53, 0.63, 0.65, 0.55, 0.57, 0.46, 0.61, 0.59, 0.73, 0.63, 0.65, 0.61, 0.67, 0.71, 0.73, 0.65, 0.65, 0.63, 0.42, 0.55, 0.61, 0.51, 0.55, 0.63, 0.67, 0.59, 0.61, 0.61, 0.57, 0.65, 0.57, 0.63, 0.57, 0.79, 0.61, 0.53, 0.69, 0.61, 0.55, 0.57, 0.67, 0.67, 0.67

0.3828571428571428
0.42, 0.28, 0.38, 0.33, 0.38, 0.28, 0.52, 0.19, 0.47, 0.28, 0.23, 0.52, 0.19, 0.33, 0.23, 0.33, 0.42, 0.33, 0.23, 0.42, 0.28, 0.52, 0.52, 0.52, 0.47, 0.47, 0.33, 0.47, 0.33, 0.47, 0.38, 0.52, 0.28, 0.23, 0.42, 0.38, 0.42, 0.42, 0.33, 0.38, 0.42, 0.23, 0.47, 0.47, 0.47, 0.42, 0.33, 0.38, 0.33, 0.47

0.5485714285714286
0.52, 0.28, 0.57, 0.61, 0.42, 0.47, 0.66, 0.42, 0.52, 0.76, 0.76, 0.42, 0.52, 0.61, 0.52, 0.47, 0.47, 0.57, 0.33, 0.52, 0.66, 0.57, 0.80, 0.57, 0.52, 0.61, 0.38, 0.66, 0.47, 0.57, 0.57, 0.66, 0.80, 0.52, 0.47, 0.61, 0.57, 0.52, 0.52, 0.33, 0.66, 0.47, 0.52, 0.28, 0.71, 0.42, 0.61, 0.57, 0.52, 0.61


Running iteration 8 of 10 fold...
[5, 0, 23, 18, 24]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.793814, 0.772841, 0.823547, 0.807265

    accuracy, precision, recall, f_score
max3: 0.795918, 0.764378, 0.862319, 0.860526

    accuracy, precision, recall, f_score
max1: 0.095238, 0.428571, 0.222222, 0.363636


min loss: 0.007, episode: 272000
max accu: 0.794, episode: 480000

5.90 classifiers used
    accuracy, precision, recall, f_score
mv: 0.047619, 0.428571, 0.111111, 0.200000
wv: 0.047619, 0.428571, 0.111111, 0.200000
fs: 0.190476, 1.000000, 0.208333, 0.326923
rl: 0.095238, 0.428571, 0.222222, 0.363636

0.6391752577319588
0.55, 0.58, 0.70, 0.56, 0.71, 0.78, 0.64, 0.67, 0.67, 0.68, 0.71, 0.71, 0.67, 0.55, 0.62, 0.70, 0.52, 0.63, 0.64, 0.57, 0.60, 0.64, 0.68, 0.77, 0.64, 0.60, 0.56, 0.59, 0.70, 0.64, 0.55, 0.62, 0.61, 0.62, 0.71, 0.56, 0.67, 0.61, 0.58, 0.63, 0.62, 0.69, 0.68, 0.57, 0.68, 0.58, 0.58, 0.61, 0.67, 0.57

0.6408163265306122
0.57, 0.61, 0.73, 0.55, 0.71, 0.73, 0.67, 0.65, 0.65, 0.63, 0.71, 0.77, 0.65, 0.48, 0.63, 0.71, 0.48, 0.65, 0.65, 0.55, 0.65, 0.67, 0.71, 0.77, 0.67, 0.63, 0.59, 0.55, 0.73, 0.59, 0.51, 0.61, 0.57, 0.61, 0.75, 0.55, 0.67, 0.65, 0.61, 0.65, 0.63, 0.65, 0.73, 0.63, 0.67, 0.61, 0.59, 0.61, 0.69, 0.55

0.14476190476190479
0.38, 0.09, 0.04, 0.19, 0.14, 0.14, 0.09, 0.19, 0.04, 0.14, 0.28, 0.38, 0.09, 0.04, 0.23, 0.0, 0.28, 0.04, 0.23, 0.38, 0.09, 0.19, 0.09, 0.14, 0.04, 0.09, 0.04, 0.04, 0.09, 0.14, 0.04, 0.09, 0.04, 0.42, 0.0, 0.04, 0.09, 0.09, 0.09, 0.04, 0.38, 0.09, 0.04, 0.04, 0.14, 0.38, 0.19, 0.04, 0.14, 0.28

0.17333333333333328
0.09, 0.28, 0.09, 0.23, 0.33, 0.33, 0.23, 0.23, 0.09, 0.09, 0.14, 0.04, 0.09, 0.04, 0.09, 0.38, 0.09, 0.0, 0.28, 0.14, 0.42, 0.09, 0.19, 0.04, 0.04, 0.0, 0.14, 0.19, 0.14, 0.33, 0.14, 0.14, 0.19, 0.14, 0.09, 0.14, 0.38, 0.14, 0.09, 0.23, 0.33, 0.14, 0.23, 0.23, 0.19, 0.09, 0.14, 0.23, 0.09, 0.23


Running iteration 9 of 10 fold...
[45, 0, 44, 21, 6, 5, 27, 38, 7]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.793814, 0.802866, 0.677735, 0.715761

    accuracy, precision, recall, f_score
max3: 0.816327, 0.791801, 0.714266, 0.732607

    accuracy, precision, recall, f_score
max1: 0.238095, 0.571429, 0.375000, 0.533333


min loss: 0.006, episode: 263000
max accu: 0.794, episode: 330000

48.90 classifiers used
    accuracy, precision, recall, f_score
mv: 0.285714, 0.571429, 0.437500, 0.584615
wv: 0.285714, 0.571429, 0.437500, 0.584615
fs: 0.238095, 0.571429, 0.375000, 0.533333
rl: 0.238095, 0.571429, 0.375000, 0.533333

0.6125773195876288
0.67, 0.65, 0.62, 0.58, 0.51, 0.67, 0.68, 0.64, 0.62, 0.60, 0.71, 0.64, 0.52, 0.54, 0.65, 0.61, 0.57, 0.53, 0.68, 0.62, 0.65, 0.63, 0.69, 0.63, 0.56, 0.58, 0.43, 0.71, 0.60, 0.56, 0.67, 0.64, 0.59, 0.54, 0.67, 0.53, 0.55, 0.58, 0.63, 0.64, 0.55, 0.47, 0.53, 0.48, 0.69, 0.74, 0.62, 0.62, 0.59, 0.64

0.6195918367346939
0.71, 0.65, 0.65, 0.61, 0.55, 0.69, 0.63, 0.61, 0.61, 0.59, 0.73, 0.67, 0.51, 0.53, 0.69, 0.63, 0.51, 0.59, 0.67, 0.63, 0.65, 0.63, 0.67, 0.63, 0.57, 0.63, 0.40, 0.73, 0.63, 0.57, 0.73, 0.71, 0.65, 0.55, 0.71, 0.57, 0.55, 0.57, 0.65, 0.59, 0.57, 0.46, 0.57, 0.42, 0.71, 0.75, 0.59, 0.63, 0.61, 0.67

0.22857142857142856
0.23, 0.19, 0.14, 0.28, 0.19, 0.23, 0.38, 0.19, 0.19, 0.14, 0.23, 0.19, 0.38, 0.19, 0.19, 0.28, 0.19, 0.14, 0.19, 0.19, 0.28, 0.23, 0.33, 0.23, 0.23, 0.23, 0.23, 0.28, 0.23, 0.19, 0.19, 0.19, 0.28, 0.19, 0.28, 0.19, 0.28, 0.23, 0.09, 0.19, 0.09, 0.38, 0.19, 0.23, 0.28, 0.19, 0.33, 0.14, 0.33, 0.19

0.25904761904761897
0.23, 0.28, 0.23, 0.09, 0.38, 0.23, 0.33, 0.09, 0.28, 0.38, 0.19, 0.19, 0.28, 0.38, 0.14, 0.28, 0.23, 0.28, 0.28, 0.28, 0.19, 0.14, 0.33, 0.28, 0.28, 0.38, 0.23, 0.09, 0.14, 0.28, 0.23, 0.33, 0.33, 0.09, 0.19, 0.28, 0.38, 0.28, 0.23, 0.23, 0.38, 0.28, 0.28, 0.33, 0.19, 0.23, 0.28, 0.42, 0.19, 0.19


Running iteration 10 of 10 fold...
[14, 0, 24, 13, 27, 35, 2, 5, 9, 3, 18, 17, 25, 32, 39]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.721649, 0.723999, 0.601809, 0.640001

    accuracy, precision, recall, f_score
max3: 0.775510, 0.787911, 0.692935, 0.738889

    accuracy, precision, recall, f_score
max1: 0.333333, 1.000000, 0.333333, 0.500000


min loss: 0.005, episode: 228000
max accu: 0.722, episode: 500000

5.24 classifiers used
    accuracy, precision, recall, f_score
mv: 0.952381, 1.000000, 0.952381, 0.975610
wv: 0.904762, 1.000000, 0.904762, 0.950000
fs: 0.904762, 1.000000, 0.904762, 0.950000
rl: 0.333333, 1.000000, 0.333333, 0.500000

0.5498969072164949
0.44, 0.61, 0.47, 0.40, 0.57, 0.47, 0.47, 0.61, 0.58, 0.57, 0.52, 0.51, 0.58, 0.64, 0.65, 0.45, 0.64, 0.59, 0.53, 0.58, 0.54, 0.48, 0.47, 0.57, 0.57, 0.55, 0.44, 0.65, 0.57, 0.56, 0.39, 0.56, 0.63, 0.51, 0.43, 0.54, 0.50, 0.64, 0.48, 0.61, 0.52, 0.51, 0.56, 0.53, 0.64, 0.52, 0.56, 0.51, 0.65, 0.60

0.5775510204081632
0.53, 0.61, 0.53, 0.44, 0.67, 0.46, 0.51, 0.71, 0.63, 0.61, 0.55, 0.51, 0.46, 0.67, 0.67, 0.48, 0.77, 0.59, 0.55, 0.63, 0.53, 0.44, 0.48, 0.57, 0.59, 0.61, 0.42, 0.65, 0.57, 0.61, 0.46, 0.61, 0.59, 0.55, 0.42, 0.57, 0.57, 0.69, 0.55, 0.63, 0.59, 0.51, 0.65, 0.53, 0.65, 0.59, 0.61, 0.59, 0.69, 0.61

0.5323809523809525
0.0, 0.66, 1.0, 0.85, 0.90, 0.95, 0.04, 0.90, 0.52, 0.0, 0.52, 0.04, 0.52, 0.71, 0.66, 0.0, 0.90, 0.0, 0.0, 0.04, 0.57, 0.61, 0.71, 0.90, 0.95, 0.95, 0.38, 0.33, 0.33, 0.23, 0.28, 0.66, 0.38, 0.85, 0.76, 0.66, 0.85, 0.61, 0.71, 0.71, 0.61, 0.85, 0.0, 0.42, 0.47, 0.0, 0.85, 0.90, 0.0, 0.66

0.5914285714285714
0.71, 0.95, 0.71, 0.04, 0.90, 0.95, 0.76, 0.95, 0.42, 0.76, 0.42, 0.95, 0.23, 0.76, 0.95, 0.23, 0.71, 0.57, 0.90, 0.76, 0.90, 0.14, 0.71, 0.61, 0.66, 0.66, 0.04, 0.95, 0.0, 0.80, 0.09, 0.71, 0.04, 0.23, 0.0, 0.76, 0.57, 0.90, 0.80, 0.76, 0.04, 0.90, 0.76, 0.47, 0.23, 0.95, 0.52, 0.47, 0.33, 0.71

    accuracy, precision, recall, f_score
mv: 0.576623, 0.882078, 0.587413, 0.683811
wv: 0.571861, 0.882078, 0.582651, 0.681250
fs: 0.502381, 0.888571, 0.517992, 0.637272
rl: 0.453247, 0.846589, 0.482702, 0.612079

fs avg size: 8.50000, rl avg size: 18.46126
full test avg accu: 0.44715, test avg accu: 0.40431

training takes 49191.712 sec
