{'dataset': 'abalone', 'algorithm': 'ptdqn', 'num_clf': 50, 'num_training': 400000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 8083, 'portion': 0.5, 'sequential': False}
(4177, 11)
reading data takes 2.817 sec
number of labels: 28

Running iteration 1 of 10 fold...
[18, 0, 30, 10, 11, 34, 20, 23]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.234167, 0.214245, 0.119826, 0.117656

    accuracy, precision, recall, f_score
max3: 0.252396, 0.236212, 0.138836, 0.134388

    accuracy, precision, recall, f_score
max1: 0.267943, 0.258504, 0.158029, 0.152716


min loss: 0.001, episode: 186000
max accu: 0.234, episode: 210000

49.59 classifiers used
    accuracy, precision, recall, f_score
mv: 0.265550, 0.260652, 0.167127, 0.152107
wv: 0.260766, 0.263728, 0.164045, 0.149737
fs: 0.232057, 0.231621, 0.162390, 0.158784
rl: 0.267943, 0.258504, 0.158029, 0.152716

0.1884406599254923
0.17, 0.19, 0.19, 0.19, 0.17, 0.19, 0.17, 0.17, 0.19, 0.17, 0.20, 0.20, 0.18, 0.17, 0.18, 0.18, 0.16, 0.18, 0.21, 0.18, 0.17, 0.17, 0.17, 0.19, 0.18, 0.19, 0.18, 0.19, 0.18, 0.18, 0.20, 0.21, 0.17, 0.18, 0.18, 0.19, 0.18, 0.18, 0.19, 0.19, 0.17, 0.18, 0.20, 0.20, 0.18, 0.19, 0.20, 0.19, 0.19, 0.18

0.19312034078807244
0.18, 0.20, 0.19, 0.19, 0.17, 0.20, 0.16, 0.19, 0.19, 0.18, 0.20, 0.21, 0.18, 0.17, 0.17, 0.17, 0.18, 0.19, 0.21, 0.18, 0.17, 0.16, 0.17, 0.18, 0.18, 0.20, 0.19, 0.19, 0.20, 0.16, 0.20, 0.21, 0.18, 0.19, 0.18, 0.20, 0.17, 0.20, 0.18, 0.20, 0.19, 0.18, 0.19, 0.21, 0.19, 0.20, 0.22, 0.20, 0.19, 0.18

0.19870813397129186
0.18, 0.17, 0.18, 0.21, 0.18, 0.22, 0.16, 0.20, 0.19, 0.21, 0.20, 0.21, 0.20, 0.19, 0.21, 0.21, 0.22, 0.19, 0.20, 0.20, 0.18, 0.18, 0.22, 0.22, 0.19, 0.14, 0.19, 0.19, 0.21, 0.21, 0.18, 0.18, 0.20, 0.19, 0.17, 0.20, 0.21, 0.18, 0.16, 0.18, 0.20, 0.20, 0.20, 0.17, 0.21, 0.20, 0.22, 0.21, 0.18, 0.17

0.1989473684210526
0.18, 0.18, 0.21, 0.20, 0.21, 0.18, 0.18, 0.18, 0.19, 0.21, 0.19, 0.24, 0.17, 0.20, 0.18, 0.20, 0.18, 0.20, 0.16, 0.21, 0.20, 0.20, 0.22, 0.19, 0.21, 0.18, 0.20, 0.19, 0.19, 0.20, 0.19, 0.20, 0.17, 0.19, 0.21, 0.18, 0.20, 0.19, 0.22, 0.17, 0.18, 0.21, 0.17, 0.19, 0.21, 0.22, 0.18, 0.18, 0.17, 0.23


Running iteration 2 of 10 fold...
[46, 0, 19, 42, 47, 40, 8, 41]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.241618, 0.228754, 0.127350, 0.132367

    accuracy, precision, recall, f_score
max3: 0.244941, 0.234428, 0.127602, 0.130564

    accuracy, precision, recall, f_score
max1: 0.208134, 0.200642, 0.105807, 0.098819


min loss: 0.001, episode: 199000
max accu: 0.242, episode: 230000

49.89 classifiers used
    accuracy, precision, recall, f_score
mv: 0.208134, 0.206724, 0.109187, 0.110887
wv: 0.210526, 0.206917, 0.109027, 0.110635
fs: 0.210526, 0.205097, 0.109631, 0.103280
rl: 0.208134, 0.200642, 0.105807, 0.098819

0.1914529004789782
0.19, 0.19, 0.18, 0.18, 0.19, 0.17, 0.20, 0.18, 0.18, 0.20, 0.19, 0.20, 0.19, 0.20, 0.18, 0.19, 0.18, 0.18, 0.17, 0.20, 0.17, 0.18, 0.19, 0.19, 0.18, 0.19, 0.19, 0.18, 0.18, 0.20, 0.18, 0.19, 0.19, 0.18, 0.18, 0.19, 0.19, 0.19, 0.18, 0.19, 0.19, 0.19, 0.20, 0.19, 0.18, 0.18, 0.21, 0.19, 0.18, 0.19

0.1931416400425985
0.19, 0.20, 0.17, 0.18, 0.21, 0.17, 0.20, 0.19, 0.17, 0.21, 0.21, 0.18, 0.17, 0.21, 0.18, 0.20, 0.18, 0.19, 0.18, 0.19, 0.17, 0.18, 0.19, 0.20, 0.19, 0.18, 0.20, 0.17, 0.17, 0.20, 0.19, 0.20, 0.20, 0.18, 0.19, 0.21, 0.18, 0.20, 0.15, 0.18, 0.18, 0.18, 0.21, 0.19, 0.19, 0.18, 0.21, 0.18, 0.17, 0.19

0.18497607655502393
0.20, 0.15, 0.17, 0.18, 0.18, 0.16, 0.16, 0.18, 0.15, 0.18, 0.14, 0.21, 0.17, 0.18, 0.19, 0.19, 0.17, 0.17, 0.19, 0.18, 0.21, 0.19, 0.19, 0.18, 0.19, 0.19, 0.21, 0.17, 0.23, 0.19, 0.20, 0.18, 0.16, 0.18, 0.17, 0.19, 0.16, 0.18, 0.19, 0.17, 0.16, 0.16, 0.19, 0.17, 0.17, 0.17, 0.18, 0.21, 0.18, 0.17

0.1805263157894737
0.18, 0.14, 0.18, 0.18, 0.20, 0.16, 0.17, 0.17, 0.18, 0.19, 0.17, 0.15, 0.19, 0.16, 0.20, 0.16, 0.16, 0.16, 0.19, 0.16, 0.13, 0.19, 0.17, 0.16, 0.17, 0.19, 0.17, 0.18, 0.20, 0.17, 0.16, 0.21, 0.20, 0.18, 0.17, 0.19, 0.16, 0.19, 0.18, 0.17, 0.21, 0.18, 0.17, 0.20, 0.17, 0.16, 0.18, 0.18, 0.18, 0.18


Running iteration 3 of 10 fold...
[41, 0, 3, 29, 26, 2, 10, 20, 34]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.242150, 0.229003, 0.121240, 0.123601

    accuracy, precision, recall, f_score
max3: 0.240682, 0.227766, 0.111668, 0.113804

    accuracy, precision, recall, f_score
max1: 0.241627, 0.228644, 0.135300, 0.137806


min loss: 0.002, episode: 112000
max accu: 0.242, episode: 100000

49.47 classifiers used
    accuracy, precision, recall, f_score
mv: 0.248804, 0.236449, 0.147468, 0.144630
wv: 0.253589, 0.236700, 0.154496, 0.145635
fs: 0.220096, 0.207232, 0.115407, 0.112303
rl: 0.241627, 0.228644, 0.135300, 0.137806

0.1897072911122938
0.20, 0.18, 0.19, 0.18, 0.19, 0.19, 0.17, 0.18, 0.18, 0.20, 0.19, 0.18, 0.18, 0.19, 0.18, 0.18, 0.18, 0.19, 0.18, 0.18, 0.20, 0.17, 0.19, 0.19, 0.19, 0.19, 0.18, 0.20, 0.18, 0.19, 0.18, 0.16, 0.18, 0.18, 0.19, 0.18, 0.19, 0.17, 0.20, 0.18, 0.19, 0.20, 0.19, 0.19, 0.17, 0.19, 0.17, 0.18, 0.19, 0.17

0.18856230031948884
0.19, 0.18, 0.18, 0.20, 0.18, 0.20, 0.17, 0.20, 0.19, 0.19, 0.18, 0.18, 0.16, 0.19, 0.17, 0.19, 0.19, 0.18, 0.19, 0.18, 0.19, 0.18, 0.20, 0.18, 0.19, 0.18, 0.18, 0.18, 0.18, 0.20, 0.18, 0.15, 0.17, 0.18, 0.21, 0.17, 0.19, 0.16, 0.20, 0.17, 0.19, 0.20, 0.17, 0.20, 0.17, 0.18, 0.18, 0.18, 0.19, 0.18

0.19023923444976076
0.18, 0.21, 0.18, 0.14, 0.18, 0.21, 0.17, 0.16, 0.18, 0.19, 0.14, 0.20, 0.18, 0.23, 0.21, 0.19, 0.16, 0.16, 0.19, 0.20, 0.19, 0.16, 0.19, 0.16, 0.18, 0.15, 0.20, 0.18, 0.21, 0.16, 0.22, 0.19, 0.21, 0.18, 0.17, 0.20, 0.19, 0.19, 0.17, 0.17, 0.21, 0.20, 0.18, 0.20, 0.19, 0.20, 0.19, 0.17, 0.18, 0.20

0.19617224880382778
0.19, 0.22, 0.20, 0.18, 0.18, 0.19, 0.21, 0.19, 0.18, 0.17, 0.19, 0.20, 0.21, 0.20, 0.19, 0.21, 0.19, 0.18, 0.20, 0.19, 0.19, 0.17, 0.18, 0.22, 0.20, 0.17, 0.20, 0.22, 0.18, 0.18, 0.21, 0.17, 0.20, 0.22, 0.21, 0.19, 0.19, 0.15, 0.19, 0.15, 0.21, 0.21, 0.17, 0.21, 0.20, 0.18, 0.15, 0.20, 0.19, 0.17


Running iteration 4 of 10 fold...
[39, 0, 17, 44, 3, 31, 8, 32, 6, 41]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.232038, 0.216272, 0.120784, 0.124792

    accuracy, precision, recall, f_score
max3: 0.236422, 0.219911, 0.125862, 0.124751

    accuracy, precision, recall, f_score
max1: 0.255981, 0.244410, 0.183729, 0.193160


min loss: 0.002, episode: 216000
max accu: 0.232, episode: 220000

39.70 classifiers used
    accuracy, precision, recall, f_score
mv: 0.234450, 0.213856, 0.141049, 0.137915
wv: 0.246411, 0.222370, 0.144981, 0.140858
fs: 0.234450, 0.220232, 0.188144, 0.177082
rl: 0.255981, 0.244410, 0.183729, 0.193160

0.18908994145822242
0.19, 0.18, 0.19, 0.18, 0.18, 0.18, 0.19, 0.19, 0.18, 0.19, 0.17, 0.18, 0.19, 0.19, 0.18, 0.18, 0.17, 0.19, 0.20, 0.18, 0.19, 0.18, 0.19, 0.17, 0.18, 0.18, 0.19, 0.18, 0.18, 0.17, 0.19, 0.19, 0.18, 0.18, 0.19, 0.19, 0.19, 0.18, 0.18, 0.20, 0.17, 0.18, 0.19, 0.18, 0.19, 0.18, 0.18, 0.18, 0.19, 0.17

0.1886900958466454
0.21, 0.17, 0.20, 0.16, 0.17, 0.17, 0.19, 0.18, 0.19, 0.19, 0.19, 0.17, 0.18, 0.19, 0.19, 0.16, 0.17, 0.19, 0.20, 0.19, 0.20, 0.16, 0.18, 0.17, 0.17, 0.18, 0.19, 0.17, 0.18, 0.18, 0.20, 0.20, 0.19, 0.17, 0.20, 0.19, 0.18, 0.19, 0.18, 0.20, 0.18, 0.19, 0.19, 0.17, 0.20, 0.17, 0.17, 0.19, 0.18, 0.18

0.19784688995215313
0.22, 0.20, 0.17, 0.19, 0.17, 0.16, 0.16, 0.17, 0.19, 0.20, 0.20, 0.16, 0.17, 0.20, 0.21, 0.19, 0.24, 0.18, 0.18, 0.19, 0.20, 0.20, 0.20, 0.20, 0.15, 0.19, 0.23, 0.19, 0.21, 0.21, 0.22, 0.22, 0.21, 0.20, 0.21, 0.20, 0.21, 0.19, 0.22, 0.19, 0.19, 0.20, 0.18, 0.19, 0.16, 0.19, 0.16, 0.22, 0.20, 0.21

0.19272727272727275
0.18, 0.17, 0.19, 0.18, 0.20, 0.16, 0.17, 0.18, 0.19, 0.19, 0.20, 0.18, 0.17, 0.20, 0.18, 0.20, 0.19, 0.19, 0.19, 0.19, 0.18, 0.16, 0.16, 0.22, 0.19, 0.20, 0.19, 0.21, 0.20, 0.20, 0.17, 0.20, 0.16, 0.16, 0.20, 0.18, 0.17, 0.21, 0.23, 0.13, 0.19, 0.21, 0.19, 0.20, 0.17, 0.21, 0.21, 0.17, 0.18, 0.21


Running iteration 5 of 10 fold...
[17, 0, 1, 30, 20, 9, 34]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.225652, 0.203594, 0.120572, 0.110501

    accuracy, precision, recall, f_score
max3: 0.210863, 0.191363, 0.112733, 0.099681

    accuracy, precision, recall, f_score
max1: 0.239234, 0.227425, 0.111927, 0.114995


min loss: 0.004, episode: 283000
max accu: 0.226, episode: 280000

22.13 classifiers used
    accuracy, precision, recall, f_score
mv: 0.236842, 0.225284, 0.141928, 0.136195
wv: 0.239234, 0.227412, 0.142881, 0.136683
fs: 0.270335, 0.261626, 0.130407, 0.136751
rl: 0.239234, 0.227425, 0.111927, 0.114995

0.1892070250133049
0.18, 0.18, 0.18, 0.19, 0.18, 0.18, 0.18, 0.17, 0.18, 0.19, 0.18, 0.17, 0.19, 0.19, 0.18, 0.19, 0.17, 0.20, 0.18, 0.18, 0.19, 0.20, 0.19, 0.18, 0.19, 0.18, 0.18, 0.19, 0.18, 0.19, 0.19, 0.18, 0.18, 0.19, 0.19, 0.18, 0.19, 0.18, 0.18, 0.18, 0.19, 0.17, 0.19, 0.19, 0.18, 0.19, 0.17, 0.18, 0.19, 0.18

0.18777422790202347
0.19, 0.18, 0.18, 0.19, 0.16, 0.17, 0.16, 0.15, 0.18, 0.19, 0.19, 0.17, 0.18, 0.20, 0.19, 0.18, 0.18, 0.21, 0.16, 0.20, 0.19, 0.21, 0.20, 0.19, 0.21, 0.19, 0.17, 0.17, 0.19, 0.19, 0.19, 0.18, 0.18, 0.18, 0.18, 0.17, 0.19, 0.18, 0.18, 0.17, 0.19, 0.17, 0.19, 0.19, 0.18, 0.18, 0.18, 0.18, 0.18, 0.18

0.20794258373205746
0.21, 0.23, 0.23, 0.23, 0.18, 0.20, 0.23, 0.20, 0.20, 0.20, 0.22, 0.17, 0.19, 0.22, 0.21, 0.21, 0.18, 0.25, 0.16, 0.20, 0.22, 0.20, 0.19, 0.22, 0.21, 0.17, 0.20, 0.20, 0.20, 0.21, 0.22, 0.18, 0.21, 0.22, 0.21, 0.18, 0.21, 0.19, 0.22, 0.22, 0.18, 0.18, 0.21, 0.20, 0.18, 0.19, 0.22, 0.21, 0.21, 0.19

0.19794258373205742
0.21, 0.22, 0.16, 0.18, 0.18, 0.19, 0.22, 0.19, 0.20, 0.23, 0.18, 0.19, 0.20, 0.18, 0.20, 0.20, 0.20, 0.20, 0.17, 0.20, 0.19, 0.20, 0.19, 0.20, 0.18, 0.21, 0.20, 0.18, 0.18, 0.17, 0.19, 0.19, 0.17, 0.19, 0.18, 0.20, 0.18, 0.20, 0.21, 0.20, 0.16, 0.22, 0.20, 0.21, 0.17, 0.20, 0.21, 0.17, 0.21, 0.18


Running iteration 6 of 10 fold...
[9, 0, 4, 34, 16, 12, 43, 33, 49]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.236828, 0.228464, 0.134097, 0.140764

    accuracy, precision, recall, f_score
max3: 0.227902, 0.214518, 0.127379, 0.131419

    accuracy, precision, recall, f_score
max1: 0.222488, 0.207131, 0.113379, 0.105077


min loss: 0.002, episode: 165000
max accu: 0.237, episode: 10000

26.62 classifiers used
    accuracy, precision, recall, f_score
mv: 0.217703, 0.212376, 0.105726, 0.102976
wv: 0.220096, 0.211530, 0.111811, 0.112178
fs: 0.251196, 0.232161, 0.126468, 0.122088
rl: 0.222488, 0.207131, 0.113379, 0.105077

0.19427354976051092
0.17, 0.18, 0.19, 0.20, 0.20, 0.19, 0.19, 0.19, 0.19, 0.20, 0.19, 0.19, 0.19, 0.19, 0.20, 0.20, 0.20, 0.20, 0.19, 0.19, 0.18, 0.17, 0.19, 0.18, 0.18, 0.18, 0.19, 0.18, 0.17, 0.20, 0.19, 0.19, 0.19, 0.19, 0.20, 0.19, 0.19, 0.20, 0.19, 0.19, 0.18, 0.19, 0.19, 0.20, 0.18, 0.19, 0.19, 0.19, 0.18, 0.20

0.1916932907348243
0.16, 0.19, 0.18, 0.18, 0.20, 0.20, 0.19, 0.17, 0.19, 0.20, 0.20, 0.19, 0.19, 0.18, 0.19, 0.19, 0.21, 0.20, 0.18, 0.19, 0.18, 0.18, 0.19, 0.17, 0.19, 0.18, 0.18, 0.19, 0.18, 0.19, 0.18, 0.20, 0.19, 0.18, 0.19, 0.19, 0.18, 0.21, 0.17, 0.19, 0.18, 0.18, 0.19, 0.19, 0.17, 0.19, 0.17, 0.19, 0.18, 0.20

0.19014354066985648
0.17, 0.16, 0.20, 0.20, 0.18, 0.16, 0.18, 0.21, 0.17, 0.22, 0.19, 0.18, 0.20, 0.22, 0.17, 0.18, 0.18, 0.18, 0.19, 0.21, 0.17, 0.17, 0.20, 0.17, 0.18, 0.19, 0.16, 0.16, 0.17, 0.20, 0.19, 0.21, 0.18, 0.19, 0.17, 0.22, 0.21, 0.22, 0.19, 0.18, 0.17, 0.18, 0.18, 0.17, 0.18, 0.16, 0.16, 0.19, 0.20, 0.20

0.18440191387559807
0.17, 0.18, 0.20, 0.18, 0.20, 0.18, 0.16, 0.17, 0.18, 0.19, 0.18, 0.16, 0.18, 0.18, 0.16, 0.18, 0.17, 0.19, 0.17, 0.20, 0.19, 0.19, 0.18, 0.16, 0.18, 0.21, 0.19, 0.21, 0.19, 0.17, 0.15, 0.17, 0.18, 0.19, 0.18, 0.17, 0.17, 0.17, 0.17, 0.19, 0.20, 0.17, 0.19, 0.18, 0.18, 0.19, 0.16, 0.17, 0.16, 0.17


Running iteration 7 of 10 fold...
[48, 0, 5, 36, 11, 14, 45, 28]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.242682, 0.226571, 0.126997, 0.126906

    accuracy, precision, recall, f_score
max3: 0.249201, 0.234809, 0.148603, 0.147818

    accuracy, precision, recall, f_score
max1: 0.234450, 0.222363, 0.187644, 0.158102


min loss: 0.001, episode: 175000
max accu: 0.243, episode: 130000

31.50 classifiers used
    accuracy, precision, recall, f_score
mv: 0.253589, 0.233466, 0.142208, 0.138481
wv: 0.241627, 0.224738, 0.137412, 0.134544
fs: 0.224880, 0.209503, 0.163124, 0.129434
rl: 0.234450, 0.222363, 0.187644, 0.158102

0.19197445449707284
0.19, 0.20, 0.20, 0.18, 0.19, 0.20, 0.17, 0.18, 0.19, 0.18, 0.19, 0.20, 0.19, 0.19, 0.18, 0.17, 0.18, 0.18, 0.19, 0.17, 0.19, 0.20, 0.18, 0.18, 0.19, 0.18, 0.19, 0.20, 0.20, 0.18, 0.20, 0.19, 0.17, 0.19, 0.19, 0.18, 0.19, 0.19, 0.18, 0.19, 0.18, 0.18, 0.18, 0.19, 0.19, 0.20, 0.17, 0.19, 0.20, 0.18

0.19510117145899894
0.19, 0.20, 0.20, 0.16, 0.19, 0.20, 0.17, 0.17, 0.20, 0.18, 0.20, 0.21, 0.19, 0.19, 0.17, 0.16, 0.19, 0.18, 0.19, 0.19, 0.19, 0.20, 0.18, 0.17, 0.21, 0.17, 0.20, 0.21, 0.22, 0.18, 0.22, 0.19, 0.17, 0.20, 0.20, 0.19, 0.20, 0.19, 0.17, 0.20, 0.18, 0.19, 0.18, 0.19, 0.19, 0.21, 0.18, 0.18, 0.21, 0.20

0.18923444976076556
0.18, 0.19, 0.18, 0.17, 0.19, 0.18, 0.22, 0.19, 0.16, 0.19, 0.19, 0.21, 0.19, 0.18, 0.20, 0.19, 0.19, 0.16, 0.20, 0.18, 0.18, 0.19, 0.17, 0.18, 0.18, 0.17, 0.16, 0.19, 0.17, 0.16, 0.17, 0.22, 0.16, 0.17, 0.21, 0.19, 0.16, 0.16, 0.18, 0.19, 0.18, 0.16, 0.21, 0.15, 0.19, 0.22, 0.19, 0.19, 0.22, 0.19

0.19205741626794257
0.17, 0.18, 0.20, 0.20, 0.23, 0.17, 0.21, 0.20, 0.23, 0.17, 0.16, 0.17, 0.18, 0.18, 0.18, 0.19, 0.22, 0.18, 0.18, 0.17, 0.17, 0.22, 0.20, 0.15, 0.19, 0.19, 0.21, 0.17, 0.18, 0.21, 0.17, 0.17, 0.18, 0.18, 0.19, 0.16, 0.19, 0.20, 0.18, 0.18, 0.18, 0.18, 0.18, 0.18, 0.19, 0.22, 0.17, 0.21, 0.20, 0.18


Running iteration 8 of 10 fold...
[37, 0, 6, 35, 43, 48, 9, 46, 36, 24, 29]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.238830, 0.219542, 0.119375, 0.112226

    accuracy, precision, recall, f_score
max3: 0.242553, 0.230455, 0.147064, 0.144688

    accuracy, precision, recall, f_score
max1: 0.230216, 0.255155, 0.135520, 0.141253


min loss: 0.002, episode: 219000
max accu: 0.239, episode: 200000

36.65 classifiers used
    accuracy, precision, recall, f_score
mv: 0.251799, 0.242151, 0.140719, 0.143618
wv: 0.244604, 0.231043, 0.134623, 0.136598
fs: 0.203837, 0.197412, 0.122806, 0.121805
rl: 0.230216, 0.255155, 0.135520, 0.141253

0.19272340425531911
0.17, 0.18, 0.17, 0.17, 0.19, 0.19, 0.19, 0.20, 0.18, 0.20, 0.18, 0.19, 0.20, 0.18, 0.18, 0.18, 0.19, 0.18, 0.19, 0.18, 0.17, 0.20, 0.19, 0.19, 0.20, 0.18, 0.19, 0.17, 0.18, 0.19, 0.18, 0.18, 0.20, 0.18, 0.18, 0.20, 0.20, 0.21, 0.18, 0.19, 0.21, 0.19, 0.20, 0.19, 0.19, 0.18, 0.19, 0.20, 0.20, 0.19

0.19185106382978723
0.18, 0.19, 0.18, 0.16, 0.17, 0.19, 0.19, 0.19, 0.18, 0.2, 0.18, 0.19, 0.20, 0.19, 0.17, 0.18, 0.18, 0.18, 0.19, 0.2, 0.17, 0.19, 0.19, 0.18, 0.20, 0.17, 0.19, 0.17, 0.16, 0.19, 0.18, 0.18, 0.18, 0.18, 0.19, 0.21, 0.21, 0.23, 0.19, 0.17, 0.20, 0.20, 0.19, 0.2, 0.18, 0.19, 0.19, 0.19, 0.20, 0.19

0.19395683453237414
0.16, 0.17, 0.16, 0.20, 0.18, 0.20, 0.15, 0.15, 0.18, 0.20, 0.21, 0.16, 0.19, 0.20, 0.22, 0.19, 0.19, 0.19, 0.18, 0.18, 0.15, 0.19, 0.18, 0.18, 0.19, 0.17, 0.19, 0.23, 0.19, 0.15, 0.24, 0.20, 0.18, 0.20, 0.20, 0.18, 0.23, 0.19, 0.24, 0.21, 0.17, 0.18, 0.18, 0.19, 0.20, 0.19, 0.18, 0.22, 0.17, 0.22

0.19741007194244606
0.18, 0.18, 0.21, 0.18, 0.18, 0.17, 0.19, 0.17, 0.15, 0.20, 0.20, 0.20, 0.19, 0.23, 0.20, 0.19, 0.20, 0.20, 0.20, 0.18, 0.17, 0.19, 0.20, 0.19, 0.19, 0.20, 0.20, 0.23, 0.21, 0.19, 0.17, 0.20, 0.15, 0.19, 0.18, 0.22, 0.23, 0.16, 0.17, 0.20, 0.21, 0.21, 0.17, 0.19, 0.22, 0.19, 0.20, 0.20, 0.20, 0.18


Running iteration 9 of 10 fold...
[29, 0, 11, 4, 7, 14, 37]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.229787, 0.215872, 0.109120, 0.108498

    accuracy, precision, recall, f_score
max3: 0.225532, 0.213590, 0.119757, 0.117883

    accuracy, precision, recall, f_score
max1: 0.266187, 0.260138, 0.188559, 0.185779


min loss: 0.002, episode: 216000
max accu: 0.230, episode: 210000

41.46 classifiers used
    accuracy, precision, recall, f_score
mv: 0.263789, 0.267298, 0.190629, 0.200496
wv: 0.268585, 0.281552, 0.193189, 0.203596
fs: 0.247002, 0.243056, 0.146953, 0.135551
rl: 0.266187, 0.260138, 0.188559, 0.185779

0.18901063829787235
0.18, 0.18, 0.18, 0.17, 0.19, 0.19, 0.18, 0.19, 0.18, 0.19, 0.17, 0.19, 0.18, 0.18, 0.20, 0.19, 0.19, 0.17, 0.18, 0.17, 0.18, 0.20, 0.17, 0.19, 0.18, 0.19, 0.18, 0.19, 0.18, 0.20, 0.18, 0.17, 0.19, 0.19, 0.18, 0.18, 0.18, 0.18, 0.19, 0.18, 0.19, 0.19, 0.19, 0.17, 0.19, 0.18, 0.19, 0.17, 0.18, 0.19

0.19202127659574464
0.18, 0.19, 0.19, 0.18, 0.20, 0.18, 0.18, 0.18, 0.19, 0.19, 0.18, 0.19, 0.17, 0.19, 0.20, 0.19, 0.2, 0.17, 0.19, 0.16, 0.17, 0.20, 0.17, 0.21, 0.18, 0.19, 0.18, 0.19, 0.18, 0.22, 0.2, 0.17, 0.20, 0.21, 0.18, 0.20, 0.19, 0.19, 0.18, 0.17, 0.19, 0.19, 0.19, 0.16, 0.18, 0.20, 0.18, 0.17, 0.18, 0.2

0.2058033573141487
0.18, 0.20, 0.19, 0.20, 0.19, 0.19, 0.22, 0.21, 0.20, 0.20, 0.21, 0.20, 0.21, 0.23, 0.18, 0.19, 0.19, 0.17, 0.21, 0.20, 0.17, 0.23, 0.17, 0.19, 0.20, 0.21, 0.21, 0.19, 0.21, 0.24, 0.23, 0.17, 0.20, 0.18, 0.21, 0.21, 0.23, 0.20, 0.21, 0.18, 0.21, 0.20, 0.23, 0.21, 0.19, 0.22, 0.16, 0.21, 0.20, 0.20

0.20800959232613914
0.20, 0.18, 0.22, 0.23, 0.19, 0.19, 0.21, 0.19, 0.25, 0.23, 0.20, 0.17, 0.20, 0.17, 0.17, 0.22, 0.19, 0.23, 0.19, 0.25, 0.18, 0.21, 0.24, 0.20, 0.19, 0.20, 0.21, 0.21, 0.21, 0.21, 0.23, 0.20, 0.24, 0.21, 0.22, 0.21, 0.18, 0.20, 0.20, 0.15, 0.19, 0.21, 0.22, 0.18, 0.20, 0.19, 0.18, 0.19, 0.20, 0.22


Running iteration 10 of 10 fold...
[16, 0, 31, 12, 28, 24, 42, 29, 1, 26, 40, 39]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.230851, 0.217732, 0.123606, 0.117403

    accuracy, precision, recall, f_score
max3: 0.243617, 0.235181, 0.153663, 0.163382

    accuracy, precision, recall, f_score
max1: 0.266187, 0.250628, 0.174775, 0.172323


min loss: 0.002, episode: 172000
max accu: 0.231, episode: 200000

41.81 classifiers used
    accuracy, precision, recall, f_score
mv: 0.249400, 0.235086, 0.199108, 0.194810
wv: 0.261391, 0.242752, 0.201942, 0.196675
fs: 0.208633, 0.196210, 0.166500, 0.156286
rl: 0.266187, 0.250628, 0.174775, 0.172323

0.19144680851063828
0.18, 0.19, 0.18, 0.18, 0.18, 0.20, 0.18, 0.18, 0.19, 0.18, 0.19, 0.18, 0.19, 0.19, 0.17, 0.16, 0.20, 0.19, 0.18, 0.19, 0.19, 0.17, 0.19, 0.18, 0.19, 0.19, 0.20, 0.17, 0.20, 0.2, 0.17, 0.20, 0.19, 0.18, 0.17, 0.19, 0.20, 0.19, 0.18, 0.19, 0.19, 0.2, 0.19, 0.18, 0.18, 0.18, 0.19, 0.20, 0.20, 0.18

0.198531914893617
0.18, 0.20, 0.19, 0.19, 0.20, 0.20, 0.17, 0.19, 0.20, 0.19, 0.19, 0.19, 0.22, 0.19, 0.18, 0.18, 0.22, 0.19, 0.19, 0.19, 0.20, 0.19, 0.20, 0.18, 0.21, 0.19, 0.21, 0.17, 0.21, 0.21, 0.17, 0.2, 0.19, 0.18, 0.18, 0.20, 0.21, 0.19, 0.19, 0.19, 0.20, 0.20, 0.20, 0.18, 0.19, 0.20, 0.20, 0.21, 0.21, 0.19

0.1993285371702638
0.15, 0.18, 0.20, 0.19, 0.23, 0.18, 0.20, 0.20, 0.17, 0.21, 0.23, 0.21, 0.16, 0.17, 0.20, 0.17, 0.17, 0.18, 0.23, 0.22, 0.22, 0.22, 0.20, 0.17, 0.20, 0.23, 0.24, 0.21, 0.17, 0.19, 0.19, 0.14, 0.18, 0.18, 0.19, 0.19, 0.19, 0.18, 0.20, 0.21, 0.18, 0.20, 0.19, 0.21, 0.19, 0.17, 0.21, 0.19, 0.20, 0.23

0.1897841726618705
0.17, 0.18, 0.19, 0.16, 0.18, 0.18, 0.21, 0.20, 0.18, 0.21, 0.16, 0.20, 0.17, 0.21, 0.18, 0.18, 0.20, 0.17, 0.17, 0.20, 0.20, 0.18, 0.17, 0.17, 0.21, 0.20, 0.19, 0.17, 0.20, 0.20, 0.19, 0.20, 0.18, 0.18, 0.21, 0.15, 0.21, 0.17, 0.14, 0.21, 0.18, 0.18, 0.17, 0.17, 0.17, 0.20, 0.17, 0.21, 0.17, 0.19

    accuracy, precision, recall, f_score
mv: 0.243006, 0.233334, 0.148515, 0.146212
wv: 0.244683, 0.234874, 0.149441, 0.146714
fs: 0.230302, 0.220415, 0.143183, 0.137337
rl: 0.243245, 0.235504, 0.149467, 0.146003

fs avg size: 17.80000, rl avg size: 77.76695
full test avg accu: 0.38760, test avg accu: 0.39164

training takes 67573.983 sec
