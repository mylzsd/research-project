{'dataset': 'abalone', 'algorithm': 'ptdqn', 'num_clf': 50, 'num_training': 500000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 796, 'portion': 0.5, 'sequential': False}
(4177, 11)
reading data takes 3.296 sec
number of labels: 28

Running iteration 1 of 10 fold...
[9, 0, 1, 11, 33, 30, 8, 2, 7, 46, 31]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.244279, 0.231694, 0.211197, 0.207769

    accuracy, precision, recall, f_score
max3: 0.244941, 0.235808, 0.262447, 0.251198

    accuracy, precision, recall, f_score
max1: 0.160287, 0.146581, 0.275227, 0.247695


min loss: 0.002, episode: 157000
max accu: 0.160, episode: 140000

45.18 classifiers used
    accuracy, precision, recall, f_score
mv: 0.150718, 0.147401, 0.212794, 0.186834
wv: 0.157895, 0.143871, 0.230660, 0.201415
fs: 0.160287, 0.163687, 0.255434, 0.235769
rl: 0.160287, 0.146581, 0.275227, 0.247695

0.19743480574773817
0.19, 0.20, 0.21, 0.19, 0.19, 0.18, 0.19, 0.19, 0.19, 0.21, 0.19, 0.21, 0.19, 0.20, 0.19, 0.20, 0.19, 0.20, 0.18, 0.19, 0.19, 0.20, 0.19, 0.20, 0.19, 0.19, 0.19, 0.20, 0.18, 0.17, 0.19, 0.19, 0.21, 0.20, 0.18, 0.19, 0.20, 0.19, 0.18, 0.18, 0.19, 0.19, 0.19, 0.19, 0.20, 0.19, 0.19, 0.18, 0.19, 0.21

0.19925452609158678
0.20, 0.20, 0.21, 0.19, 0.19, 0.19, 0.18, 0.21, 0.20, 0.22, 0.19, 0.20, 0.19, 0.21, 0.19, 0.21, 0.19, 0.20, 0.17, 0.20, 0.20, 0.21, 0.20, 0.19, 0.19, 0.18, 0.19, 0.19, 0.18, 0.18, 0.19, 0.21, 0.20, 0.20, 0.18, 0.21, 0.20, 0.18, 0.17, 0.17, 0.19, 0.18, 0.20, 0.20, 0.21, 0.20, 0.19, 0.17, 0.18, 0.20

0.12947368421052632
0.14, 0.10, 0.14, 0.12, 0.16, 0.14, 0.13, 0.13, 0.12, 0.12, 0.15, 0.15, 0.11, 0.12, 0.12, 0.11, 0.11, 0.10, 0.12, 0.11, 0.13, 0.14, 0.10, 0.11, 0.12, 0.14, 0.12, 0.14, 0.10, 0.13, 0.12, 0.13, 0.13, 0.13, 0.12, 0.12, 0.14, 0.11, 0.10, 0.11, 0.12, 0.12, 0.17, 0.12, 0.13, 0.13, 0.12, 0.13, 0.10, 0.13

0.13411483253588516
0.11, 0.11, 0.11, 0.13, 0.13, 0.09, 0.14, 0.13, 0.14, 0.11, 0.13, 0.16, 0.13, 0.14, 0.13, 0.15, 0.13, 0.13, 0.13, 0.13, 0.15, 0.15, 0.12, 0.16, 0.16, 0.15, 0.12, 0.13, 0.12, 0.12, 0.13, 0.15, 0.11, 0.12, 0.14, 0.15, 0.12, 0.13, 0.11, 0.11, 0.16, 0.11, 0.13, 0.13, 0.12, 0.11, 0.14, 0.12, 0.09, 0.12


Running iteration 2 of 10 fold...
[44, 0, 1, 36, 46, 28, 30, 49, 4]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.246408, 0.233529, 0.224041, 0.229474

    accuracy, precision, recall, f_score
max3: 0.264111, 0.252562, 0.253437, 0.264880

    accuracy, precision, recall, f_score
max1: 0.138756, 0.164329, 0.218018, 0.186996


min loss: 0.001, episode: 227000
max accu: 0.139, episode: 290000

33.99 classifiers used
    accuracy, precision, recall, f_score
mv: 0.117225, 0.113703, 0.173786, 0.141474
wv: 0.112440, 0.110405, 0.168175, 0.136644
fs: 0.131579, 0.120849, 0.216904, 0.185907
rl: 0.138756, 0.164329, 0.218018, 0.186996

0.20300159659393294
0.21, 0.20, 0.19, 0.19, 0.20, 0.20, 0.18, 0.20, 0.19, 0.21, 0.18, 0.18, 0.19, 0.20, 0.21, 0.19, 0.19, 0.20, 0.20, 0.19, 0.20, 0.21, 0.19, 0.19, 0.20, 0.21, 0.19, 0.20, 0.21, 0.20, 0.20, 0.20, 0.20, 0.18, 0.19, 0.20, 0.20, 0.19, 0.20, 0.18, 0.20, 0.20, 0.20, 0.20, 0.22, 0.19, 0.22, 0.19, 0.21, 0.20

0.2033226837060703
0.21, 0.20, 0.18, 0.19, 0.20, 0.19, 0.18, 0.21, 0.20, 0.21, 0.18, 0.18, 0.19, 0.21, 0.21, 0.19, 0.20, 0.19, 0.22, 0.18, 0.20, 0.21, 0.19, 0.21, 0.20, 0.23, 0.18, 0.20, 0.22, 0.20, 0.19, 0.19, 0.20, 0.20, 0.20, 0.20, 0.21, 0.21, 0.20, 0.18, 0.21, 0.19, 0.20, 0.20, 0.22, 0.17, 0.23, 0.18, 0.21, 0.21

0.1169377990430622
0.11, 0.11, 0.09, 0.09, 0.12, 0.10, 0.11, 0.11, 0.13, 0.09, 0.12, 0.10, 0.13, 0.11, 0.13, 0.12, 0.09, 0.10, 0.11, 0.13, 0.12, 0.10, 0.12, 0.10, 0.10, 0.12, 0.12, 0.10, 0.15, 0.14, 0.10, 0.13, 0.12, 0.12, 0.12, 0.11, 0.11, 0.13, 0.13, 0.11, 0.10, 0.11, 0.11, 0.12, 0.14, 0.09, 0.11, 0.11, 0.08, 0.12

0.11751196172248804
0.11, 0.11, 0.12, 0.13, 0.08, 0.15, 0.11, 0.12, 0.12, 0.10, 0.11, 0.12, 0.08, 0.14, 0.10, 0.12, 0.11, 0.11, 0.11, 0.10, 0.16, 0.13, 0.10, 0.12, 0.12, 0.13, 0.08, 0.10, 0.10, 0.11, 0.11, 0.12, 0.15, 0.12, 0.09, 0.09, 0.13, 0.12, 0.10, 0.11, 0.12, 0.07, 0.13, 0.12, 0.09, 0.11, 0.12, 0.11, 0.11, 0.13


Running iteration 3 of 10 fold...
[16, 0, 1, 42, 43]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.230974, 0.219096, 0.200557, 0.206985

    accuracy, precision, recall, f_score
max3: 0.223642, 0.227790, 0.200793, 0.211781

    accuracy, precision, recall, f_score
max1: 0.318182, 0.328451, 0.302371, 0.312919


min loss: 0.003, episode: 159000
max accu: 0.318, episode: 160000

49.89 classifiers used
    accuracy, precision, recall, f_score
mv: 0.320574, 0.327377, 0.311737, 0.318410
wv: 0.327751, 0.333046, 0.317158, 0.323782
fs: 0.253589, 0.267842, 0.240820, 0.238105
rl: 0.318182, 0.328451, 0.302371, 0.312919

0.1844385311335817
0.18, 0.18, 0.19, 0.18, 0.18, 0.17, 0.17, 0.17, 0.17, 0.18, 0.19, 0.18, 0.18, 0.17, 0.19, 0.18, 0.20, 0.19, 0.18, 0.18, 0.18, 0.18, 0.19, 0.17, 0.17, 0.17, 0.19, 0.19, 0.16, 0.17, 0.17, 0.17, 0.20, 0.18, 0.17, 0.17, 0.19, 0.19, 0.17, 0.19, 0.17, 0.18, 0.18, 0.18, 0.18, 0.18, 0.18, 0.18, 0.18, 0.18

0.18200212992545262
0.17, 0.17, 0.19, 0.19, 0.18, 0.18, 0.18, 0.16, 0.16, 0.18, 0.18, 0.17, 0.18, 0.16, 0.19, 0.17, 0.21, 0.19, 0.18, 0.18, 0.17, 0.18, 0.18, 0.16, 0.15, 0.17, 0.18, 0.19, 0.17, 0.18, 0.17, 0.16, 0.19, 0.17, 0.18, 0.16, 0.19, 0.18, 0.17, 0.17, 0.17, 0.19, 0.18, 0.18, 0.18, 0.18, 0.18, 0.18, 0.18, 0.17

0.22942583732057417
0.22, 0.25, 0.24, 0.27, 0.27, 0.20, 0.19, 0.24, 0.19, 0.21, 0.23, 0.23, 0.22, 0.22, 0.20, 0.22, 0.22, 0.21, 0.26, 0.22, 0.21, 0.23, 0.21, 0.22, 0.23, 0.22, 0.22, 0.23, 0.23, 0.23, 0.24, 0.23, 0.21, 0.23, 0.21, 0.24, 0.22, 0.22, 0.22, 0.22, 0.23, 0.21, 0.24, 0.22, 0.22, 0.22, 0.22, 0.23, 0.21, 0.26

0.23569377990430623
0.27, 0.24, 0.23, 0.24, 0.26, 0.23, 0.21, 0.25, 0.22, 0.21, 0.23, 0.25, 0.29, 0.21, 0.24, 0.26, 0.25, 0.23, 0.21, 0.25, 0.23, 0.26, 0.24, 0.21, 0.23, 0.27, 0.22, 0.23, 0.19, 0.22, 0.23, 0.23, 0.21, 0.23, 0.23, 0.22, 0.23, 0.22, 0.25, 0.22, 0.25, 0.26, 0.22, 0.21, 0.22, 0.17, 0.22, 0.20, 0.26, 0.21


Running iteration 4 of 10 fold...
[25, 0, 48, 16, 36, 46, 1, 37, 12, 8, 44]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.208089, 0.191880, 0.175159, 0.178418

    accuracy, precision, recall, f_score
max3: 0.215122, 0.211320, 0.198385, 0.205862

    accuracy, precision, recall, f_score
max1: 0.291866, 0.294951, 0.334217, 0.340548


min loss: 0.003, episode: 251000
max accu: 0.292, episode: 300000

3.11 classifiers used
    accuracy, precision, recall, f_score
mv: 0.308612, 0.312806, 0.264479, 0.263601
wv: 0.315789, 0.317937, 0.269961, 0.268504
fs: 0.267943, 0.275237, 0.246558, 0.251185
rl: 0.291866, 0.294951, 0.334217, 0.340548

0.18348057477381588
0.17, 0.18, 0.17, 0.18, 0.18, 0.18, 0.18, 0.18, 0.18, 0.17, 0.18, 0.18, 0.19, 0.18, 0.19, 0.19, 0.17, 0.19, 0.19, 0.17, 0.16, 0.18, 0.18, 0.16, 0.19, 0.20, 0.17, 0.17, 0.18, 0.19, 0.17, 0.16, 0.18, 0.17, 0.17, 0.17, 0.19, 0.18, 0.18, 0.18, 0.17, 0.17, 0.17, 0.19, 0.19, 0.18, 0.19, 0.18, 0.19, 0.18

0.1810862619808307
0.18, 0.18, 0.15, 0.18, 0.18, 0.19, 0.18, 0.19, 0.17, 0.17, 0.19, 0.18, 0.19, 0.16, 0.20, 0.19, 0.16, 0.20, 0.17, 0.16, 0.15, 0.16, 0.18, 0.17, 0.17, 0.20, 0.17, 0.17, 0.18, 0.19, 0.18, 0.17, 0.18, 0.16, 0.18, 0.17, 0.19, 0.16, 0.17, 0.17, 0.17, 0.16, 0.14, 0.18, 0.19, 0.18, 0.19, 0.18, 0.19, 0.17

0.2305741626794258
0.22, 0.21, 0.20, 0.27, 0.26, 0.26, 0.22, 0.19, 0.21, 0.22, 0.23, 0.18, 0.22, 0.22, 0.26, 0.19, 0.27, 0.24, 0.25, 0.22, 0.24, 0.24, 0.23, 0.19, 0.21, 0.26, 0.21, 0.20, 0.25, 0.23, 0.25, 0.26, 0.22, 0.22, 0.25, 0.23, 0.22, 0.21, 0.21, 0.20, 0.20, 0.20, 0.21, 0.23, 0.23, 0.26, 0.23, 0.22, 0.24, 0.22

0.2345933014354067
0.19, 0.28, 0.22, 0.22, 0.22, 0.22, 0.22, 0.23, 0.20, 0.22, 0.20, 0.22, 0.21, 0.24, 0.25, 0.20, 0.26, 0.25, 0.27, 0.29, 0.22, 0.23, 0.22, 0.22, 0.23, 0.23, 0.22, 0.24, 0.23, 0.23, 0.22, 0.22, 0.24, 0.26, 0.27, 0.23, 0.19, 0.23, 0.20, 0.19, 0.26, 0.23, 0.22, 0.21, 0.24, 0.22, 0.25, 0.22, 0.26, 0.23


Running iteration 5 of 10 fold...
[0, 1, 38, 21, 40, 6]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.235232, 0.224604, 0.196206, 0.205587

    accuracy, precision, recall, f_score
max3: 0.215122, 0.205188, 0.215253, 0.219269

    accuracy, precision, recall, f_score
max1: 0.320574, 0.315135, 0.363338, 0.353693


min loss: 0.001, episode: 209000
max accu: 0.321, episode: 150000

44.13 classifiers used
    accuracy, precision, recall, f_score
mv: 0.311005, 0.310256, 0.287908, 0.283899
wv: 0.315789, 0.316903, 0.292326, 0.288701
fs: 0.267943, 0.283684, 0.316044, 0.305260
rl: 0.320574, 0.315135, 0.363338, 0.353693

0.18680149015433745
0.20, 0.18, 0.19, 0.18, 0.18, 0.18, 0.19, 0.19, 0.16, 0.19, 0.19, 0.19, 0.18, 0.16, 0.19, 0.19, 0.18, 0.19, 0.17, 0.18, 0.19, 0.20, 0.18, 0.17, 0.20, 0.18, 0.20, 0.18, 0.17, 0.18, 0.18, 0.18, 0.18, 0.18, 0.17, 0.17, 0.18, 0.16, 0.19, 0.19, 0.19, 0.17, 0.19, 0.19, 0.18, 0.18, 0.18, 0.19, 0.18, 0.18

0.17921192758253457
0.20, 0.19, 0.18, 0.16, 0.18, 0.17, 0.18, 0.16, 0.16, 0.18, 0.16, 0.18, 0.16, 0.14, 0.20, 0.18, 0.18, 0.18, 0.17, 0.18, 0.16, 0.20, 0.18, 0.17, 0.19, 0.16, 0.18, 0.17, 0.16, 0.15, 0.18, 0.18, 0.17, 0.16, 0.17, 0.17, 0.18, 0.16, 0.20, 0.19, 0.19, 0.17, 0.18, 0.18, 0.15, 0.17, 0.17, 0.18, 0.16, 0.17

0.22076555023923444
0.21, 0.21, 0.27, 0.22, 0.20, 0.19, 0.20, 0.25, 0.24, 0.19, 0.23, 0.22, 0.22, 0.25, 0.20, 0.25, 0.23, 0.19, 0.22, 0.18, 0.20, 0.22, 0.23, 0.27, 0.23, 0.20, 0.22, 0.21, 0.22, 0.22, 0.21, 0.23, 0.23, 0.19, 0.24, 0.22, 0.18, 0.20, 0.23, 0.20, 0.20, 0.25, 0.23, 0.19, 0.18, 0.20, 0.17, 0.24, 0.23, 0.18

0.22066985645933013
0.22, 0.23, 0.22, 0.24, 0.18, 0.23, 0.24, 0.23, 0.20, 0.25, 0.20, 0.22, 0.21, 0.21, 0.18, 0.21, 0.20, 0.22, 0.19, 0.20, 0.20, 0.23, 0.20, 0.20, 0.26, 0.18, 0.19, 0.21, 0.25, 0.24, 0.19, 0.18, 0.23, 0.22, 0.24, 0.20, 0.25, 0.24, 0.22, 0.25, 0.18, 0.22, 0.24, 0.21, 0.22, 0.25, 0.22, 0.21, 0.17, 0.19


Running iteration 6 of 10 fold...
[23, 0, 25, 38, 21, 19, 36]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.193720, 0.194675, 0.171272, 0.171394

    accuracy, precision, recall, f_score
max3: 0.195953, 0.196296, 0.211656, 0.210110

    accuracy, precision, recall, f_score
max1: 0.155502, 0.179150, 0.168476, 0.169598


min loss: 0.002, episode: 271000
max accu: 0.156, episode: 110000

1.47 classifiers used
    accuracy, precision, recall, f_score
mv: 0.143541, 0.137185, 0.199492, 0.180434
wv: 0.143541, 0.124504, 0.218201, 0.193269
fs: 0.138756, 0.137944, 0.188381, 0.168281
rl: 0.155502, 0.179150, 0.168476, 0.169598

0.19990420436402342
0.19, 0.19, 0.20, 0.19, 0.18, 0.19, 0.20, 0.18, 0.19, 0.20, 0.20, 0.21, 0.20, 0.19, 0.20, 0.19, 0.20, 0.20, 0.17, 0.20, 0.19, 0.20, 0.20, 0.21, 0.18, 0.18, 0.20, 0.19, 0.19, 0.20, 0.20, 0.20, 0.19, 0.19, 0.18, 0.19, 0.20, 0.21, 0.19, 0.20, 0.20, 0.19, 0.19, 0.18, 0.19, 0.20, 0.20, 0.20, 0.20, 0.20

0.1946325878594249
0.20, 0.18, 0.19, 0.19, 0.18, 0.19, 0.19, 0.18, 0.17, 0.17, 0.20, 0.21, 0.20, 0.18, 0.19, 0.20, 0.20, 0.20, 0.17, 0.19, 0.18, 0.21, 0.20, 0.20, 0.18, 0.20, 0.20, 0.19, 0.19, 0.19, 0.20, 0.18, 0.18, 0.18, 0.17, 0.20, 0.21, 0.19, 0.18, 0.19, 0.20, 0.17, 0.17, 0.19, 0.18, 0.20, 0.21, 0.18, 0.19, 0.19

0.1279425837320574
0.13, 0.15, 0.10, 0.10, 0.10, 0.14, 0.13, 0.12, 0.15, 0.11, 0.10, 0.16, 0.15, 0.11, 0.13, 0.12, 0.11, 0.12, 0.12, 0.14, 0.13, 0.14, 0.11, 0.11, 0.14, 0.13, 0.11, 0.12, 0.12, 0.14, 0.12, 0.12, 0.12, 0.11, 0.11, 0.12, 0.10, 0.12, 0.14, 0.13, 0.11, 0.13, 0.11, 0.10, 0.12, 0.13, 0.11, 0.13, 0.14, 0.12

0.12688995215311005
0.10, 0.11, 0.14, 0.10, 0.11, 0.11, 0.15, 0.12, 0.11, 0.10, 0.13, 0.12, 0.11, 0.16, 0.11, 0.12, 0.11, 0.11, 0.11, 0.13, 0.13, 0.12, 0.13, 0.11, 0.14, 0.12, 0.14, 0.12, 0.13, 0.12, 0.13, 0.14, 0.12, 0.14, 0.12, 0.11, 0.14, 0.11, 0.10, 0.10, 0.14, 0.12, 0.13, 0.13, 0.13, 0.12, 0.13, 0.12, 0.12, 0.13


Running iteration 7 of 10 fold...
[37, 0, 3, 6, 41, 26, 32, 34, 16, 28]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.207557, 0.194500, 0.182738, 0.185180

    accuracy, precision, recall, f_score
max3: 0.202343, 0.193093, 0.201321, 0.204132

    accuracy, precision, recall, f_score
max1: 0.325359, 0.340169, 0.326387, 0.333330


min loss: 0.001, episode: 175000
max accu: 0.325, episode: 300000

13.15 classifiers used
    accuracy, precision, recall, f_score
mv: 0.361244, 0.366715, 0.347282, 0.356315
wv: 0.363636, 0.365868, 0.348965, 0.358220
fs: 0.318182, 0.342020, 0.308401, 0.323017
rl: 0.325359, 0.340169, 0.326387, 0.333330

0.17967003725385844
0.18, 0.16, 0.18, 0.18, 0.17, 0.17, 0.20, 0.16, 0.17, 0.18, 0.16, 0.18, 0.18, 0.17, 0.16, 0.18, 0.17, 0.16, 0.17, 0.17, 0.17, 0.16, 0.17, 0.16, 0.18, 0.16, 0.18, 0.19, 0.17, 0.17, 0.17, 0.19, 0.18, 0.17, 0.19, 0.18, 0.18, 0.20, 0.18, 0.17, 0.18, 0.19, 0.18, 0.18, 0.17, 0.18, 0.16, 0.17, 0.17, 0.18

0.17439829605963791
0.18, 0.17, 0.17, 0.16, 0.18, 0.16, 0.17, 0.15, 0.17, 0.18, 0.16, 0.16, 0.18, 0.17, 0.16, 0.17, 0.17, 0.14, 0.16, 0.17, 0.17, 0.15, 0.18, 0.16, 0.17, 0.15, 0.18, 0.18, 0.16, 0.17, 0.17, 0.20, 0.18, 0.16, 0.18, 0.17, 0.17, 0.20, 0.18, 0.18, 0.17, 0.19, 0.17, 0.17, 0.16, 0.17, 0.15, 0.17, 0.17, 0.16

0.2441626794258373
0.26, 0.21, 0.23, 0.22, 0.21, 0.25, 0.25, 0.23, 0.26, 0.22, 0.21, 0.20, 0.23, 0.24, 0.21, 0.18, 0.25, 0.25, 0.22, 0.26, 0.26, 0.27, 0.22, 0.22, 0.23, 0.20, 0.21, 0.27, 0.26, 0.27, 0.28, 0.20, 0.25, 0.24, 0.24, 0.29, 0.26, 0.25, 0.27, 0.24, 0.24, 0.29, 0.27, 0.25, 0.22, 0.25, 0.21, 0.26, 0.23, 0.25

0.25631578947368416
0.26, 0.22, 0.26, 0.24, 0.18, 0.26, 0.21, 0.23, 0.24, 0.28, 0.22, 0.27, 0.27, 0.28, 0.25, 0.23, 0.26, 0.25, 0.28, 0.28, 0.25, 0.29, 0.26, 0.24, 0.26, 0.27, 0.26, 0.23, 0.27, 0.24, 0.25, 0.27, 0.25, 0.25, 0.23, 0.24, 0.26, 0.25, 0.29, 0.26, 0.23, 0.25, 0.27, 0.26, 0.21, 0.24, 0.26, 0.26, 0.24, 0.22


Running iteration 8 of 10 fold...
[4, 0, 12, 22, 24, 44, 35, 48]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.209043, 0.195340, 0.191942, 0.193117

    accuracy, precision, recall, f_score
max3: 0.219149, 0.206802, 0.203524, 0.211444

    accuracy, precision, recall, f_score
max1: 0.191847, 0.181132, 0.229155, 0.204887


min loss: 0.002, episode: 166000
max accu: 0.192, episode: 100000

1.76 classifiers used
    accuracy, precision, recall, f_score
mv: 0.189448, 0.166759, 0.260690, 0.229359
wv: 0.194245, 0.172379, 0.266971, 0.235798
fs: 0.141487, 0.131658, 0.142613, 0.136800
rl: 0.191847, 0.181132, 0.229155, 0.204887

0.1950212765957446
0.18, 0.2, 0.16, 0.20, 0.21, 0.2, 0.19, 0.17, 0.20, 0.18, 0.17, 0.19, 0.19, 0.20, 0.17, 0.19, 0.20, 0.18, 0.20, 0.18, 0.20, 0.18, 0.20, 0.20, 0.19, 0.20, 0.18, 0.18, 0.19, 0.18, 0.19, 0.18, 0.20, 0.20, 0.18, 0.20, 0.21, 0.19, 0.18, 0.20, 0.18, 0.2, 0.18, 0.19, 0.18, 0.21, 0.20, 0.19, 0.18, 0.20

0.19453191489361704
0.17, 0.20, 0.16, 0.20, 0.21, 0.18, 0.2, 0.18, 0.21, 0.18, 0.17, 0.18, 0.18, 0.19, 0.19, 0.19, 0.20, 0.16, 0.21, 0.19, 0.20, 0.19, 0.20, 0.2, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.18, 0.19, 0.21, 0.19, 0.18, 0.21, 0.18, 0.18, 0.21, 0.19, 0.20, 0.17, 0.19, 0.17, 0.23, 0.18, 0.18, 0.18, 0.20

0.1556834532374101
0.13, 0.14, 0.16, 0.13, 0.15, 0.13, 0.17, 0.15, 0.15, 0.14, 0.17, 0.16, 0.11, 0.13, 0.13, 0.15, 0.16, 0.17, 0.15, 0.16, 0.17, 0.16, 0.14, 0.12, 0.13, 0.15, 0.17, 0.18, 0.15, 0.16, 0.15, 0.17, 0.15, 0.11, 0.17, 0.15, 0.16, 0.15, 0.19, 0.15, 0.18, 0.13, 0.16, 0.15, 0.15, 0.17, 0.17, 0.13, 0.14, 0.15

0.16086330935251797
0.15, 0.14, 0.14, 0.15, 0.15, 0.14, 0.14, 0.13, 0.17, 0.12, 0.16, 0.17, 0.17, 0.17, 0.16, 0.15, 0.17, 0.13, 0.17, 0.14, 0.14, 0.17, 0.14, 0.12, 0.11, 0.15, 0.18, 0.20, 0.16, 0.17, 0.15, 0.18, 0.17, 0.16, 0.18, 0.14, 0.17, 0.16, 0.14, 0.16, 0.15, 0.18, 0.16, 0.16, 0.16, 0.17, 0.17, 0.14, 0.16, 0.16


Running iteration 9 of 10 fold...
[39, 0, 12, 18, 9]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.203191, 0.188507, 0.183368, 0.185421

    accuracy, precision, recall, f_score
max3: 0.203191, 0.188153, 0.210216, 0.208240

    accuracy, precision, recall, f_score
max1: 0.285372, 0.281549, 0.344014, 0.317905


min loss: 0.002, episode: 198000
max accu: 0.285, episode: 230000

27.66 classifiers used
    accuracy, precision, recall, f_score
mv: 0.302158, 0.297894, 0.319866, 0.337059
wv: 0.297362, 0.292299, 0.322598, 0.337168
fs: 0.230216, 0.244848, 0.256008, 0.258434
rl: 0.285372, 0.281549, 0.344014, 0.317905

0.1840212765957447
0.17, 0.18, 0.20, 0.19, 0.19, 0.18, 0.18, 0.17, 0.18, 0.19, 0.16, 0.18, 0.18, 0.18, 0.17, 0.19, 0.18, 0.17, 0.18, 0.19, 0.18, 0.19, 0.17, 0.18, 0.18, 0.17, 0.17, 0.17, 0.18, 0.17, 0.17, 0.17, 0.18, 0.18, 0.18, 0.18, 0.18, 0.18, 0.17, 0.20, 0.18, 0.18, 0.16, 0.17, 0.18, 0.18, 0.17, 0.17, 0.18, 0.18

0.18995744680851065
0.19, 0.20, 0.20, 0.20, 0.19, 0.18, 0.19, 0.19, 0.19, 0.18, 0.17, 0.21, 0.17, 0.17, 0.17, 0.19, 0.18, 0.18, 0.20, 0.19, 0.18, 0.20, 0.17, 0.18, 0.19, 0.2, 0.18, 0.17, 0.20, 0.17, 0.17, 0.18, 0.19, 0.19, 0.17, 0.19, 0.19, 0.19, 0.19, 0.21, 0.18, 0.18, 0.16, 0.18, 0.19, 0.2, 0.18, 0.16, 0.19, 0.18

0.21952038369304558
0.21, 0.22, 0.24, 0.22, 0.24, 0.19, 0.21, 0.23, 0.20, 0.23, 0.20, 0.22, 0.21, 0.19, 0.20, 0.17, 0.21, 0.24, 0.19, 0.23, 0.20, 0.22, 0.19, 0.24, 0.20, 0.23, 0.23, 0.23, 0.21, 0.24, 0.21, 0.20, 0.20, 0.24, 0.23, 0.19, 0.22, 0.22, 0.23, 0.18, 0.21, 0.22, 0.23, 0.22, 0.22, 0.20, 0.20, 0.21, 0.20, 0.24

0.22374100719424458
0.23, 0.23, 0.25, 0.22, 0.21, 0.20, 0.22, 0.24, 0.23, 0.23, 0.20, 0.21, 0.23, 0.20, 0.21, 0.27, 0.21, 0.21, 0.24, 0.23, 0.22, 0.23, 0.23, 0.23, 0.23, 0.22, 0.22, 0.21, 0.19, 0.19, 0.20, 0.25, 0.20, 0.19, 0.23, 0.24, 0.21, 0.23, 0.23, 0.22, 0.20, 0.21, 0.21, 0.23, 0.19, 0.20, 0.22, 0.19, 0.23, 0.24


Running iteration 10 of 10 fold...
[28, 0, 9, 4, 17, 7, 18, 19]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.210106, 0.199736, 0.197000, 0.202958

    accuracy, precision, recall, f_score
max3: 0.217021, 0.214412, 0.208116, 0.218070

    accuracy, precision, recall, f_score
max1: 0.306954, 0.308106, 0.315191, 0.317608


min loss: 0.002, episode: 243000
max accu: 0.307, episode: 250000

34.55 classifiers used
    accuracy, precision, recall, f_score
mv: 0.297362, 0.306931, 0.275311, 0.282249
wv: 0.285372, 0.294907, 0.257672, 0.264121
fs: 0.270983, 0.281941, 0.265775, 0.265468
rl: 0.306954, 0.308106, 0.315191, 0.317608

0.18851063829787232
0.18, 0.19, 0.19, 0.17, 0.18, 0.18, 0.17, 0.19, 0.19, 0.18, 0.18, 0.19, 0.17, 0.19, 0.17, 0.19, 0.16, 0.18, 0.18, 0.18, 0.18, 0.20, 0.18, 0.20, 0.19, 0.18, 0.17, 0.19, 0.20, 0.19, 0.18, 0.19, 0.19, 0.18, 0.17, 0.18, 0.18, 0.18, 0.19, 0.17, 0.19, 0.17, 0.18, 0.18, 0.19, 0.20, 0.19, 0.18, 0.19, 0.20

0.19038297872340423
0.18, 0.19, 0.20, 0.17, 0.18, 0.19, 0.18, 0.19, 0.18, 0.2, 0.19, 0.21, 0.18, 0.18, 0.17, 0.19, 0.15, 0.19, 0.19, 0.18, 0.18, 0.20, 0.19, 0.19, 0.19, 0.18, 0.17, 0.2, 0.20, 0.20, 0.2, 0.20, 0.19, 0.19, 0.16, 0.16, 0.20, 0.18, 0.19, 0.18, 0.19, 0.18, 0.19, 0.19, 0.20, 0.20, 0.19, 0.17, 0.19, 0.20

0.21323741007194244
0.21, 0.24, 0.19, 0.19, 0.20, 0.20, 0.16, 0.24, 0.23, 0.22, 0.22, 0.23, 0.23, 0.17, 0.21, 0.22, 0.17, 0.22, 0.21, 0.21, 0.22, 0.22, 0.18, 0.20, 0.22, 0.18, 0.20, 0.18, 0.21, 0.21, 0.21, 0.23, 0.20, 0.22, 0.19, 0.20, 0.22, 0.22, 0.20, 0.20, 0.19, 0.21, 0.20, 0.21, 0.20, 0.23, 0.23, 0.23, 0.23, 0.22

0.20959232613908874
0.21, 0.21, 0.21, 0.18, 0.20, 0.20, 0.22, 0.21, 0.19, 0.19, 0.23, 0.19, 0.22, 0.18, 0.23, 0.21, 0.22, 0.21, 0.20, 0.19, 0.22, 0.21, 0.23, 0.21, 0.20, 0.21, 0.23, 0.20, 0.18, 0.20, 0.19, 0.21, 0.22, 0.23, 0.17, 0.21, 0.23, 0.17, 0.19, 0.19, 0.21, 0.22, 0.18, 0.22, 0.19, 0.16, 0.20, 0.21, 0.20, 0.21

    accuracy, precision, recall, f_score
mv: 0.250189, 0.248703, 0.265334, 0.257963
wv: 0.251382, 0.247212, 0.269269, 0.260762
fs: 0.218096, 0.224971, 0.243694, 0.236822
rl: 0.249470, 0.253955, 0.287639, 0.278518

fs avg size: 8.00000, rl avg size: 25.48779
full test avg accu: 0.19200, test avg accu: 0.18877

training takes 59552.488 sec
