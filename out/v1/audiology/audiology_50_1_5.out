{'dataset': 'audiology', 'algorithm': 'ptdqn', 'num_clf': 50, 'num_training': 350000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 4238, 'portion': 0.5, 'sequential': False}
(226, 95)
reading data takes 3.895 sec
number of labels: 24

Running iteration 1 of 10 fold...
[23, 0, 15, 9, 36]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.702970, 0.627426, 0.354190, 0.334046

    accuracy, precision, recall, f_score
max3: 0.666667, 0.602226, 0.340278, 0.312208

    accuracy, precision, recall, f_score
max1: 0.739130, 0.739130, 0.676667, 0.600000


min loss: 0.006, episode: 299000
max accu: 0.739, episode: 10000

17.83 classifiers used
    accuracy, precision, recall, f_score
mv: 0.869565, 0.807971, 0.780000, 0.745714
wv: 0.869565, 0.807971, 0.780000, 0.745714
fs: 0.739130, 0.742754, 0.690000, 0.577922
rl: 0.739130, 0.739130, 0.676667, 0.600000

0.5675247524752476
0.44, 0.60, 0.63, 0.57, 0.49, 0.54, 0.61, 0.70, 0.32, 0.59, 0.58, 0.55, 0.48, 0.54, 0.59, 0.70, 0.51, 0.58, 0.61, 0.67, 0.41, 0.61, 0.58, 0.72, 0.37, 0.58, 0.56, 0.62, 0.44, 0.60, 0.62, 0.56, 0.45, 0.61, 0.58, 0.65, 0.32, 0.54, 0.69, 0.61, 0.45, 0.62, 0.50, 0.64, 0.50, 0.64, 0.62, 0.57, 0.50, 0.70

0.5823529411764706
0.43, 0.60, 0.68, 0.56, 0.52, 0.54, 0.66, 0.70, 0.31, 0.56, 0.58, 0.50, 0.52, 0.54, 0.66, 0.72, 0.54, 0.58, 0.62, 0.64, 0.47, 0.62, 0.60, 0.74, 0.45, 0.56, 0.60, 0.56, 0.41, 0.60, 0.66, 0.54, 0.43, 0.62, 0.58, 0.64, 0.39, 0.52, 0.70, 0.62, 0.52, 0.70, 0.54, 0.60, 0.49, 0.72, 0.64, 0.54, 0.50, 0.76

0.5547826086956521
0.47, 0.60, 0.69, 0.56, 0.52, 0.52, 0.60, 0.69, 0.30, 0.60, 0.47, 0.60, 0.52, 0.52, 0.56, 0.73, 0.47, 0.60, 0.56, 0.65, 0.30, 0.56, 0.47, 0.69, 0.39, 0.47, 0.52, 0.65, 0.52, 0.52, 0.47, 0.56, 0.52, 0.52, 0.52, 0.65, 0.43, 0.65, 0.56, 0.56, 0.56, 0.56, 0.47, 0.73, 0.47, 0.52, 0.60, 0.65, 0.52, 0.65

0.6556521739130434
0.78, 0.69, 0.56, 0.65, 0.78, 0.69, 0.69, 0.73, 0.69, 0.65, 0.60, 0.73, 0.56, 0.56, 0.65, 0.65, 0.65, 0.65, 0.60, 0.65, 0.69, 0.69, 0.56, 0.73, 0.65, 0.56, 0.56, 0.69, 0.65, 0.65, 0.47, 0.60, 0.56, 0.60, 0.60, 0.69, 0.73, 0.60, 0.60, 0.73, 0.56, 0.73, 0.73, 0.78, 0.65, 0.69, 0.56, 0.69, 0.56, 0.73


Running iteration 2 of 10 fold...
[25, 0, 9, 1, 17, 24, 8, 12, 10, 13]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.584158, 0.575808, 0.276430, 0.238729

    accuracy, precision, recall, f_score
max3: 0.509804, 0.535294, 0.302579, 0.253968

    accuracy, precision, recall, f_score
max1: 0.826087, 0.804348, 0.619048, 0.500000


min loss: 0.008, episode: 259000
max accu: 0.826, episode: 30000

1.00 classifiers used
    accuracy, precision, recall, f_score
mv: 0.869565, 0.830040, 0.571429, 0.439153
wv: 0.869565, 0.830040, 0.571429, 0.439153
fs: 0.782609, 0.757576, 0.476190, 0.351275
rl: 0.826087, 0.804348, 0.619048, 0.500000

0.574059405940594
0.61, 0.65, 0.58, 0.61, 0.44, 0.64, 0.55, 0.54, 0.53, 0.60, 0.51, 0.56, 0.47, 0.68, 0.55, 0.50, 0.35, 0.65, 0.57, 0.58, 0.61, 0.53, 0.53, 0.57, 0.43, 0.73, 0.58, 0.64, 0.65, 0.64, 0.62, 0.69, 0.48, 0.67, 0.50, 0.66, 0.49, 0.57, 0.60, 0.68, 0.48, 0.57, 0.49, 0.55, 0.57, 0.56, 0.53, 0.66, 0.48, 0.56

0.5784313725490197
0.64, 0.68, 0.58, 0.60, 0.49, 0.66, 0.50, 0.50, 0.62, 0.56, 0.54, 0.58, 0.45, 0.66, 0.58, 0.45, 0.27, 0.64, 0.56, 0.50, 0.60, 0.56, 0.58, 0.62, 0.41, 0.74, 0.58, 0.66, 0.70, 0.64, 0.68, 0.70, 0.54, 0.72, 0.50, 0.66, 0.41, 0.54, 0.62, 0.74, 0.47, 0.54, 0.52, 0.52, 0.58, 0.54, 0.54, 0.64, 0.43, 0.54

0.7026086956521739
0.69, 0.65, 0.82, 0.86, 0.65, 0.69, 0.69, 0.69, 0.60, 0.69, 0.69, 0.82, 0.52, 0.65, 0.73, 0.78, 0.52, 0.69, 0.78, 0.82, 0.65, 0.60, 0.69, 0.78, 0.60, 0.73, 0.78, 0.78, 0.60, 0.69, 0.73, 0.78, 0.56, 0.73, 0.73, 0.73, 0.43, 0.82, 0.69, 0.78, 0.47, 0.86, 0.69, 0.86, 0.69, 0.69, 0.73, 0.69, 0.47, 0.78

0.7556521739130434
0.69, 0.82, 0.82, 0.78, 0.73, 0.86, 0.82, 0.82, 0.69, 0.91, 0.82, 0.73, 0.56, 0.82, 0.78, 0.69, 0.65, 0.82, 0.78, 0.78, 0.56, 0.78, 0.73, 0.78, 0.65, 0.73, 0.69, 0.82, 0.78, 0.86, 0.78, 0.78, 0.73, 0.82, 0.69, 0.78, 0.69, 0.91, 0.82, 0.73, 0.30, 0.65, 0.82, 0.69, 0.69, 0.82, 0.73, 0.82, 0.73, 0.78


Running iteration 3 of 10 fold...
[1, 0, 18, 3, 8]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.693069, 0.678966, 0.354420, 0.315129

    accuracy, precision, recall, f_score
max3: 0.686275, 0.710208, 0.379853, 0.369691

    accuracy, precision, recall, f_score
max1: 0.826087, 0.883696, 0.804762, 0.723611


min loss: 0.005, episode: 328000
max accu: 0.826, episode: 300000

45.78 classifiers used
    accuracy, precision, recall, f_score
mv: 0.869565, 0.859627, 0.761905, 0.746032
wv: 0.913043, 0.928986, 0.904762, 0.899711
fs: 0.869565, 0.921739, 0.852381, 0.769444
rl: 0.826087, 0.883696, 0.804762, 0.723611

0.5665346534653465
0.38, 0.69, 0.51, 0.58, 0.53, 0.64, 0.58, 0.55, 0.47, 0.58, 0.55, 0.67, 0.53, 0.63, 0.48, 0.63, 0.46, 0.60, 0.57, 0.62, 0.44, 0.55, 0.67, 0.63, 0.66, 0.62, 0.55, 0.68, 0.36, 0.58, 0.64, 0.61, 0.44, 0.55, 0.59, 0.62, 0.44, 0.68, 0.50, 0.56, 0.51, 0.50, 0.49, 0.61, 0.57, 0.53, 0.64, 0.62, 0.41, 0.61

0.5525490196078432
0.35, 0.74, 0.52, 0.58, 0.47, 0.64, 0.52, 0.54, 0.43, 0.58, 0.50, 0.62, 0.54, 0.60, 0.50, 0.62, 0.49, 0.58, 0.56, 0.60, 0.39, 0.49, 0.66, 0.64, 0.70, 0.60, 0.54, 0.68, 0.31, 0.60, 0.62, 0.58, 0.47, 0.54, 0.56, 0.62, 0.45, 0.68, 0.49, 0.49, 0.54, 0.41, 0.45, 0.60, 0.60, 0.49, 0.66, 0.56, 0.41, 0.52

0.7078260869565217
0.69, 0.86, 0.52, 0.65, 0.91, 0.78, 0.65, 0.73, 0.73, 0.60, 0.65, 0.73, 0.69, 0.78, 0.56, 0.73, 0.56, 0.65, 0.65, 0.73, 0.65, 0.73, 0.65, 0.78, 0.73, 0.86, 0.78, 0.73, 0.60, 0.73, 0.65, 0.69, 0.78, 0.69, 0.69, 0.69, 0.56, 0.78, 0.65, 0.65, 0.78, 0.60, 0.60, 0.78, 0.69, 0.86, 0.65, 0.82, 0.65, 0.78

0.7478260869565219
0.65, 0.78, 0.73, 0.78, 0.69, 0.69, 0.73, 0.86, 0.69, 0.78, 0.65, 0.69, 0.86, 0.82, 0.82, 0.82, 0.56, 0.78, 0.78, 0.86, 0.69, 0.78, 0.65, 0.78, 0.69, 0.65, 0.73, 0.91, 0.69, 0.73, 0.73, 0.78, 0.82, 0.78, 0.69, 0.86, 0.56, 0.86, 0.60, 0.86, 0.69, 0.82, 0.69, 0.82, 0.69, 0.78, 0.69, 0.78, 0.73, 0.56

    accuracy, precision, recall, f_score
mv: 0.869565, 0.832546, 0.704444, 0.643633
wv: 0.884058, 0.855665, 0.752063, 0.694860
fs: 0.797101, 0.807356, 0.672857, 0.566214
rl: 0.797101, 0.809058, 0.700159, 0.607870

fs avg size: 6.66667, rl avg size: 21.53623
full test avg accu: 0.71971, test avg accu: 0.65507

training takes 16320.575 sec
