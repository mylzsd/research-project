{'dataset': 'credit_card', 'algorithm': 'ptdqn', 'num_clf': 50, 'num_training': 400000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 1407, 'portion': 0.5, 'sequential': False}
(30000, 31)
reading data takes 0.238 sec
number of labels: 2

Running iteration 1 of 10 fold...
[28, 0, 44, 25, 23, 11, 17, 46, 47, 36, 13]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.812815, 0.793499, 0.652440, 0.674784

    accuracy, precision, recall, f_score
max3: 0.812148, 0.793976, 0.654924, 0.677874

    accuracy, precision, recall, f_score
max1: 0.814000, 0.795364, 0.653904, 0.676951


min loss: 0.009, episode: 229000
max accu: 0.814, episode: 260000

48.94 classifiers used
    accuracy, precision, recall, f_score
mv: 0.816667, 0.798875, 0.656687, 0.680619
wv: 0.817000, 0.799295, 0.655300, 0.679496
fs: 0.805667, 0.785681, 0.651214, 0.671082
rl: 0.814000, 0.795364, 0.653904, 0.676951

0.7204266666666667
0.72, 0.71, 0.72, 0.72, 0.72, 0.71, 0.71, 0.72, 0.71, 0.71, 0.72, 0.72, 0.71, 0.72, 0.71, 0.71, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.71, 0.71, 0.71, 0.72, 0.72, 0.72, 0.73, 0.72, 0.72, 0.72, 0.71, 0.71, 0.72, 0.71, 0.71, 0.71, 0.72, 0.71, 0.72, 0.71, 0.71, 0.72, 0.72, 0.71, 0.72, 0.71, 0.72, 0.70

0.7199437037037036
0.72, 0.71, 0.72, 0.71, 0.72, 0.71, 0.71, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.73, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.72, 0.71, 0.71, 0.72, 0.73, 0.72, 0.72, 0.73, 0.71, 0.72, 0.72, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.72, 0.71, 0.72, 0.71, 0.71, 0.71, 0.72, 0.71, 0.72, 0.71, 0.72, 0.71

0.7220533333333333
0.72, 0.72, 0.71, 0.71, 0.72, 0.71, 0.70, 0.73, 0.70, 0.72, 0.72, 0.72, 0.72, 0.73, 0.72, 0.71, 0.72, 0.73, 0.72, 0.71, 0.71, 0.72, 0.70, 0.71, 0.71, 0.72, 0.72, 0.72, 0.73, 0.71, 0.71, 0.72, 0.72, 0.71, 0.73, 0.72, 0.71, 0.74, 0.73, 0.72, 0.72, 0.71, 0.72, 0.71, 0.73, 0.72, 0.71, 0.71, 0.71, 0.71

0.7244933333333333
0.72, 0.73, 0.72, 0.71, 0.72, 0.70, 0.73, 0.73, 0.72, 0.71, 0.72, 0.72, 0.73, 0.71, 0.71, 0.73, 0.71, 0.72, 0.72, 0.72, 0.72, 0.71, 0.72, 0.73, 0.71, 0.73, 0.73, 0.72, 0.73, 0.72, 0.72, 0.72, 0.71, 0.72, 0.72, 0.73, 0.71, 0.71, 0.73, 0.71, 0.71, 0.72, 0.72, 0.72, 0.71, 0.72, 0.71, 0.72, 0.72, 0.72


Running iteration 2 of 10 fold...
[34, 0, 12, 1, 41, 19, 47, 36, 26, 39, 9, 4, 16, 31, 42, 35, 28, 27, 32, 20]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.814296, 0.795275, 0.654317, 0.676924

    accuracy, precision, recall, f_score
max3: 0.812593, 0.794386, 0.656091, 0.678952

    accuracy, precision, recall, f_score
max1: 0.809667, 0.792951, 0.654098, 0.677386


min loss: 0.008, episode: 224000
max accu: 0.810, episode: 240000

49.62 classifiers used
    accuracy, precision, recall, f_score
mv: 0.806667, 0.788817, 0.654607, 0.676724
wv: 0.810000, 0.793369, 0.655303, 0.678649
fs: 0.802000, 0.782530, 0.646624, 0.667509
rl: 0.809667, 0.792951, 0.654098, 0.677386

0.7225140740740741
0.72, 0.72, 0.71, 0.71, 0.72, 0.72, 0.72, 0.72, 0.71, 0.71, 0.72, 0.72, 0.72, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.71, 0.72, 0.71, 0.72, 0.71, 0.72, 0.72, 0.71, 0.71, 0.72, 0.72, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.72, 0.72, 0.72, 0.71, 0.71, 0.72, 0.72, 0.72, 0.72

0.7211022222222223
0.72, 0.72, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.71, 0.71, 0.71, 0.72, 0.72, 0.72, 0.71, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.72, 0.71, 0.72, 0.70, 0.72, 0.72, 0.71, 0.71, 0.72, 0.72, 0.73, 0.71, 0.72, 0.71, 0.72, 0.72, 0.71, 0.72, 0.72, 0.72, 0.71, 0.71, 0.71, 0.72, 0.73, 0.72

0.7178466666666666
0.73, 0.72, 0.72, 0.71, 0.72, 0.73, 0.72, 0.72, 0.70, 0.70, 0.70, 0.70, 0.72, 0.72, 0.71, 0.71, 0.71, 0.72, 0.71, 0.71, 0.70, 0.72, 0.71, 0.72, 0.71, 0.70, 0.72, 0.70, 0.71, 0.72, 0.72, 0.71, 0.71, 0.72, 0.71, 0.69, 0.71, 0.71, 0.71, 0.72, 0.71, 0.72, 0.71, 0.72, 0.71, 0.71, 0.71, 0.71, 0.71, 0.73

0.7210933333333334
0.71, 0.72, 0.72, 0.70, 0.70, 0.71, 0.72, 0.73, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.71, 0.71, 0.72, 0.72, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.71, 0.72, 0.71, 0.72, 0.71, 0.71, 0.71, 0.71, 0.72, 0.73, 0.71, 0.73, 0.72, 0.71, 0.71, 0.72, 0.71, 0.71, 0.72, 0.70, 0.71, 0.72, 0.72


Running iteration 3 of 10 fold...
[17, 0, 25, 23, 8, 47, 33, 41, 1, 15, 13, 11, 34, 16, 9, 46, 37, 10]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.815333, 0.796765, 0.657119, 0.679911

    accuracy, precision, recall, f_score
max3: 0.813778, 0.795785, 0.658217, 0.681191

    accuracy, precision, recall, f_score
max1: 0.814333, 0.796480, 0.657849, 0.681124


min loss: 0.009, episode: 209000
max accu: 0.814, episode: 240000

49.21 classifiers used
    accuracy, precision, recall, f_score
mv: 0.815667, 0.798239, 0.659761, 0.683414
wv: 0.814333, 0.796378, 0.654170, 0.677773
fs: 0.808333, 0.788942, 0.652927, 0.674183
rl: 0.814333, 0.796480, 0.657849, 0.681124

0.7212785185185184
0.71, 0.72, 0.72, 0.71, 0.71, 0.72, 0.71, 0.71, 0.72, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.73, 0.72, 0.71, 0.71, 0.71, 0.72, 0.72, 0.72, 0.72, 0.71, 0.71, 0.72, 0.71, 0.71, 0.71, 0.72, 0.72, 0.72, 0.73, 0.71, 0.71, 0.72, 0.73, 0.72, 0.72, 0.71, 0.72, 0.71, 0.72, 0.71, 0.72, 0.72, 0.71

0.7206814814814814
0.71, 0.72, 0.72, 0.72, 0.71, 0.72, 0.72, 0.71, 0.72, 0.71, 0.71, 0.72, 0.71, 0.72, 0.72, 0.72, 0.70, 0.73, 0.72, 0.71, 0.71, 0.71, 0.71, 0.72, 0.72, 0.71, 0.70, 0.71, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.73, 0.72, 0.71, 0.71, 0.72, 0.72, 0.72, 0.72, 0.71, 0.71, 0.71, 0.72, 0.71, 0.72, 0.72, 0.72

0.7222066666666668
0.71, 0.72, 0.72, 0.71, 0.72, 0.73, 0.71, 0.72, 0.71, 0.70, 0.71, 0.72, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.71, 0.70, 0.72, 0.71, 0.72, 0.73, 0.71, 0.71, 0.72, 0.71, 0.72, 0.72, 0.72, 0.71, 0.72, 0.71, 0.72, 0.72, 0.72, 0.70, 0.71, 0.72, 0.72, 0.72, 0.72, 0.74, 0.72, 0.71, 0.72, 0.72, 0.73, 0.72

0.7237266666666667
0.71, 0.73, 0.72, 0.73, 0.72, 0.72, 0.73, 0.72, 0.73, 0.74, 0.72, 0.72, 0.71, 0.72, 0.73, 0.71, 0.72, 0.71, 0.71, 0.72, 0.73, 0.71, 0.72, 0.72, 0.73, 0.72, 0.72, 0.72, 0.72, 0.71, 0.71, 0.71, 0.71, 0.71, 0.72, 0.71, 0.72, 0.72, 0.71, 0.73, 0.72, 0.72, 0.71, 0.72, 0.72, 0.71, 0.73, 0.72, 0.71, 0.72


Running iteration 4 of 10 fold...
[48, 0, 40, 17, 12, 34, 39, 37, 29, 38, 5, 8, 16]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.809481, 0.790330, 0.656165, 0.676683

    accuracy, precision, recall, f_score
max3: 0.808889, 0.790089, 0.657059, 0.678159

    accuracy, precision, recall, f_score
max1: 0.830333, 0.816177, 0.687789, 0.712416


min loss: 0.010, episode: 205000
max accu: 0.830, episode: 320000

21.06 classifiers used
    accuracy, precision, recall, f_score
mv: 0.821000, 0.804162, 0.669192, 0.692574
wv: 0.822000, 0.805230, 0.668185, 0.692237
fs: 0.815667, 0.797652, 0.663034, 0.684811
rl: 0.830333, 0.816177, 0.687789, 0.712416

0.7217570370370371
0.72, 0.71, 0.72, 0.72, 0.71, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.72, 0.72, 0.71, 0.72, 0.72, 0.72, 0.71, 0.71, 0.72, 0.71, 0.72, 0.72, 0.71, 0.71, 0.71, 0.72, 0.72, 0.71, 0.71, 0.72, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.71, 0.72, 0.72, 0.72, 0.71, 0.71, 0.72, 0.72, 0.71, 0.72, 0.73, 0.72

0.722962962962963
0.72, 0.72, 0.72, 0.72, 0.71, 0.71, 0.73, 0.72, 0.72, 0.71, 0.73, 0.71, 0.72, 0.72, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.72, 0.72, 0.72, 0.71, 0.71, 0.72, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.71, 0.72, 0.72, 0.72, 0.71, 0.73, 0.71

0.73102
0.74, 0.72, 0.72, 0.73, 0.73, 0.72, 0.73, 0.73, 0.73, 0.72, 0.73, 0.72, 0.72, 0.73, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.71, 0.72, 0.73, 0.73, 0.72, 0.73, 0.73, 0.74, 0.73, 0.74, 0.72, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.71, 0.70, 0.72, 0.72, 0.72, 0.73, 0.72, 0.73, 0.73, 0.72, 0.73, 0.73, 0.73

0.7304799999999999
0.72, 0.72, 0.73, 0.73, 0.73, 0.72, 0.73, 0.73, 0.73, 0.72, 0.72, 0.74, 0.72, 0.73, 0.73, 0.73, 0.73, 0.72, 0.73, 0.73, 0.72, 0.73, 0.73, 0.73, 0.72, 0.73, 0.72, 0.73, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.73, 0.72, 0.72, 0.71, 0.73, 0.73, 0.72, 0.72, 0.73, 0.73, 0.72, 0.71, 0.72, 0.72, 0.71

    accuracy, precision, recall, f_score
mv: 0.815000, 0.797523, 0.660062, 0.683332
wv: 0.815833, 0.798568, 0.658239, 0.682038
fs: 0.807917, 0.788701, 0.653450, 0.674396
rl: 0.817083, 0.800243, 0.663410, 0.686970

fs avg size: 15.50000, rl avg size: 42.20733
full test avg accu: 0.72495, test avg accu: 0.72328

training takes 38735.837 sec
