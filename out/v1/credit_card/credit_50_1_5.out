{'dataset': 'credit_card', 'algorithm': 'ptdqn', 'num_clf': 50, 'num_training': 450000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 8635, 'portion': 0.5, 'sequential': False}
(30000, 31)
reading data takes 0.190 sec
number of labels: 2

Running iteration 1 of 10 fold...
[5, 0, 13, 38, 44, 28, 48, 27, 8, 36, 16, 20, 12, 24, 32]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.791556, 0.761348, 0.597721, 0.611248

    accuracy, precision, recall, f_score
max3: 0.785778, 0.754773, 0.595243, 0.607381

    accuracy, precision, recall, f_score
max1: 0.807667, 0.773955, 0.587917, 0.601826


min loss: 0.010, episode: 239000
max accu: 0.808, episode: 450000

4.42 classifiers used
    accuracy, precision, recall, f_score
mv: 0.805000, 0.774982, 0.605625, 0.622128
wv: 0.807667, 0.779997, 0.614792, 0.632559
fs: 0.814000, 0.786998, 0.616250, 0.635960
rl: 0.807667, 0.773955, 0.587917, 0.601826

0.6546222222222222
0.71, 0.76, 0.74, 0.36, 0.71, 0.78, 0.75, 0.37, 0.73, 0.77, 0.75, 0.40, 0.72, 0.78, 0.75, 0.37, 0.72, 0.77, 0.75, 0.35, 0.71, 0.76, 0.74, 0.36, 0.71, 0.54, 0.75, 0.35, 0.72, 0.77, 0.75, 0.39, 0.71, 0.77, 0.75, 0.34, 0.71, 0.72, 0.75, 0.40, 0.72, 0.78, 0.75, 0.36, 0.72, 0.76, 0.74, 0.42, 0.72, 0.77

0.6541303703703703
0.71, 0.75, 0.73, 0.37, 0.71, 0.77, 0.75, 0.38, 0.72, 0.76, 0.75, 0.42, 0.71, 0.77, 0.75, 0.39, 0.72, 0.77, 0.74, 0.36, 0.72, 0.76, 0.74, 0.37, 0.71, 0.55, 0.74, 0.36, 0.71, 0.77, 0.74, 0.40, 0.71, 0.76, 0.74, 0.36, 0.71, 0.72, 0.74, 0.41, 0.72, 0.77, 0.74, 0.37, 0.71, 0.76, 0.74, 0.43, 0.71, 0.77

0.6612733333333333
0.71, 0.78, 0.76, 0.35, 0.72, 0.80, 0.76, 0.35, 0.73, 0.79, 0.77, 0.39, 0.71, 0.80, 0.76, 0.36, 0.73, 0.79, 0.76, 0.34, 0.73, 0.78, 0.76, 0.35, 0.72, 0.54, 0.77, 0.34, 0.71, 0.79, 0.76, 0.38, 0.71, 0.78, 0.76, 0.33, 0.71, 0.74, 0.76, 0.40, 0.72, 0.80, 0.76, 0.34, 0.72, 0.78, 0.76, 0.42, 0.72, 0.80

0.65412
0.71, 0.79, 0.77, 0.41, 0.71, 0.33, 0.76, 0.36, 0.71, 0.80, 0.77, 0.41, 0.73, 0.79, 0.76, 0.35, 0.71, 0.63, 0.76, 0.43, 0.72, 0.78, 0.76, 0.39, 0.72, 0.74, 0.77, 0.38, 0.72, 0.79, 0.76, 0.35, 0.73, 0.76, 0.75, 0.35, 0.72, 0.56, 0.76, 0.44, 0.72, 0.80, 0.77, 0.35, 0.72, 0.80, 0.76, 0.40, 0.71, 0.8


Running iteration 2 of 10 fold...
[21, 0, 48, 20, 25, 8, 4, 45, 32, 36, 26, 28]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.801704, 0.775334, 0.608908, 0.626152

    accuracy, precision, recall, f_score
max3: 0.800148, 0.774168, 0.610569, 0.627833

    accuracy, precision, recall, f_score
max1: 0.801000, 0.776425, 0.613494, 0.631389


min loss: 0.013, episode: 197000
max accu: 0.801, episode: 230000

49.65 classifiers used
    accuracy, precision, recall, f_score
mv: 0.796333, 0.768937, 0.598793, 0.612946
wv: 0.803000, 0.779768, 0.627541, 0.647371
fs: 0.805333, 0.783573, 0.615752, 0.634810
rl: 0.801000, 0.776425, 0.613494, 0.631389

0.6483244444444445
0.72, 0.78, 0.75, 0.37, 0.72, 0.55, 0.75, 0.35, 0.73, 0.78, 0.75, 0.34, 0.71, 0.78, 0.75, 0.36, 0.71, 0.77, 0.75, 0.36, 0.72, 0.78, 0.75, 0.36, 0.72, 0.78, 0.75, 0.36, 0.72, 0.72, 0.75, 0.35, 0.72, 0.77, 0.74, 0.40, 0.72, 0.58, 0.75, 0.38, 0.71, 0.78, 0.75, 0.36, 0.72, 0.61, 0.75, 0.37, 0.72, 0.77

0.6490903703703704
0.71, 0.77, 0.75, 0.38, 0.72, 0.55, 0.75, 0.36, 0.73, 0.77, 0.75, 0.35, 0.71, 0.77, 0.75, 0.37, 0.71, 0.76, 0.75, 0.36, 0.72, 0.78, 0.75, 0.37, 0.72, 0.78, 0.75, 0.37, 0.72, 0.72, 0.74, 0.36, 0.72, 0.77, 0.74, 0.42, 0.72, 0.58, 0.75, 0.39, 0.71, 0.78, 0.74, 0.38, 0.71, 0.60, 0.75, 0.38, 0.72, 0.77

0.6444466666666666
0.72, 0.77, 0.76, 0.36, 0.73, 0.57, 0.75, 0.34, 0.72, 0.77, 0.74, 0.32, 0.73, 0.77, 0.74, 0.35, 0.71, 0.77, 0.76, 0.35, 0.73, 0.78, 0.75, 0.35, 0.72, 0.77, 0.75, 0.35, 0.72, 0.72, 0.74, 0.33, 0.72, 0.77, 0.73, 0.39, 0.72, 0.57, 0.75, 0.37, 0.72, 0.77, 0.75, 0.35, 0.73, 0.59, 0.75, 0.36, 0.72, 0.77

0.6496
0.73, 0.79, 0.74, 0.34, 0.72, 0.68, 0.74, 0.36, 0.72, 0.77, 0.74, 0.34, 0.72, 0.78, 0.75, 0.35, 0.72, 0.78, 0.74, 0.38, 0.72, 0.77, 0.75, 0.35, 0.71, 0.67, 0.75, 0.37, 0.72, 0.77, 0.75, 0.38, 0.73, 0.52, 0.74, 0.35, 0.71, 0.77, 0.75, 0.36, 0.73, 0.78, 0.75, 0.35, 0.71, 0.78, 0.75, 0.35, 0.72, 0.77


Running iteration 3 of 10 fold...
[17, 0, 4, 8, 41, 25, 24, 32, 16, 12, 36, 20, 10, 43, 5]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.794963, 0.763802, 0.572759, 0.577805

    accuracy, precision, recall, f_score
max3: 0.791704, 0.758880, 0.570967, 0.574991

    accuracy, precision, recall, f_score
max1: 0.805000, 0.782861, 0.590799, 0.603361


min loss: 0.007, episode: 231000
max accu: 0.805, episode: 270000

42.41 classifiers used
    accuracy, precision, recall, f_score
mv: 0.801667, 0.778073, 0.632779, 0.651574
wv: 0.805000, 0.782646, 0.638770, 0.658479
fs: 0.814000, 0.793702, 0.631291, 0.654018
rl: 0.805000, 0.782861, 0.590799, 0.603361

0.6518474074074073
0.72, 0.75, 0.75, 0.38, 0.72, 0.78, 0.74, 0.35, 0.72, 0.75, 0.75, 0.42, 0.72, 0.77, 0.75, 0.38, 0.72, 0.78, 0.75, 0.34, 0.72, 0.76, 0.75, 0.36, 0.72, 0.48, 0.74, 0.38, 0.71, 0.78, 0.75, 0.43, 0.72, 0.69, 0.75, 0.38, 0.72, 0.55, 0.75, 0.39, 0.71, 0.78, 0.75, 0.52, 0.71, 0.77, 0.74, 0.38, 0.71, 0.66

0.6518785185185184
0.72, 0.75, 0.75, 0.39, 0.72, 0.77, 0.74, 0.36, 0.72, 0.75, 0.74, 0.43, 0.72, 0.77, 0.75, 0.39, 0.72, 0.78, 0.74, 0.35, 0.72, 0.76, 0.75, 0.36, 0.72, 0.48, 0.74, 0.39, 0.71, 0.77, 0.75, 0.44, 0.71, 0.68, 0.75, 0.39, 0.72, 0.56, 0.74, 0.40, 0.72, 0.78, 0.75, 0.52, 0.71, 0.77, 0.74, 0.39, 0.71, 0.66

0.6527133333333335
0.72, 0.75, 0.75, 0.39, 0.72, 0.78, 0.74, 0.35, 0.72, 0.76, 0.75, 0.42, 0.71, 0.77, 0.76, 0.39, 0.72, 0.78, 0.75, 0.34, 0.72, 0.76, 0.75, 0.36, 0.72, 0.49, 0.75, 0.38, 0.72, 0.78, 0.75, 0.43, 0.74, 0.68, 0.74, 0.39, 0.72, 0.55, 0.74, 0.39, 0.71, 0.78, 0.75, 0.53, 0.72, 0.77, 0.75, 0.38, 0.71, 0.67

0.6458466666666667
0.72, 0.64, 0.75, 0.35, 0.71, 0.70, 0.76, 0.38, 0.72, 0.78, 0.75, 0.36, 0.72, 0.55, 0.74, 0.38, 0.72, 0.73, 0.76, 0.41, 0.72, 0.38, 0.76, 0.37, 0.72, 0.79, 0.75, 0.42, 0.72, 0.77, 0.76, 0.46, 0.72, 0.74, 0.75, 0.42, 0.73, 0.74, 0.75, 0.38, 0.71, 0.77, 0.75, 0.34, 0.72, 0.71, 0.74, 0.42, 0.73, 0.63

    accuracy, precision, recall, f_score
mv: 0.801000, 0.773997, 0.612399, 0.628883
wv: 0.805222, 0.780804, 0.627034, 0.646136
fs: 0.811111, 0.788091, 0.621098, 0.641596
rl: 0.804556, 0.777747, 0.597403, 0.631292

fs avg size: 14.00000, rl avg size: 32.15700
full test avg accu: 0.64986, test avg accu: 0.65281

training takes 25794.567 sec
