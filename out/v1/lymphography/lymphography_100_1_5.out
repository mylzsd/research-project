{'dataset': 'lymphography', 'algorithm': 'ptdqn', 'num_clf': 100, 'num_training': 350000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 3336, 'portion': 0.5, 'sequential': False}
(148, 39)
reading data takes 0.543 sec
number of labels: 4

Running iteration 1 of 10 fold...
[1, 0, 40, 5, 60, 12, 76, 88, 15, 20, 36, 52, 19, 63, 2]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.7164, 0.6942, 0.4905, 0.4830

    accuracy, precision, recall, f_score
max3: 0.6667, 0.6459, 0.4550, 0.4485

    accuracy, precision, recall, f_score
max1: 0.8667, 0.8533, 0.6364, 0.5675


min loss: 0.007, episode: 259000
max accu: 0.867, episode: 30000

1.00 classifiers used
    accuracy, precision, recall, f_score
mv: 0.8000, 0.7667, 0.5253, 0.4935
wv: 0.8000, 0.7667, 0.5253, 0.4935
fs: 0.8667, 0.8056, 0.5556, 0.5411
rl: 0.8667, 0.8533, 0.6364, 0.5675

0.7253333333333333
0.66, 0.8, 0.66, 0.8, 0.66, 0.73, 0.73, 0.73, 0.6, 0.73, 0.8, 0.73, 0.53, 0.73, 0.73, 0.73, 0.6, 0.86, 0.86, 0.73, 0.66, 0.66, 0.8, 0.73, 0.46, 0.8, 0.73, 0.8, 0.8, 0.86, 0.73, 0.73, 0.6, 0.73, 0.73, 0.73, 0.86, 0.66, 0.86, 0.66, 0.8, 0.8, 0.8, 0.66, 0.86, 0.73, 0.73, 0.73, 0.8, 0.8, 0.73, 0.73, 0.53, 0.66, 0.73, 0.8, 0.66, 0.53, 0.8, 0.8, 0.66, 0.8, 0.66, 0.53, 0.73, 0.6, 0.8, 0.66, 0.73, 0.8, 0.73, 0.73, 0.66, 0.73, 0.86, 0.8, 0.86, 0.73, 0.73, 0.73, 0.66, 0.66, 0.73, 0.8, 0.8, 0.6, 0.73, 0.73, 0.6, 0.8, 0.73, 0.66, 0.8, 0.86, 0.73, 0.66, 0.4, 0.6, 0.8, 0.66

0.7253333333333333
0.73, 0.8, 0.8, 0.66, 0.4, 0.66, 0.73, 0.66, 0.73, 0.66, 0.66, 0.8, 0.73, 0.73, 0.86, 0.73, 0.73, 0.6, 0.8, 0.73, 0.73, 0.8, 0.73, 0.73, 0.73, 0.8, 0.8, 0.8, 0.66, 0.73, 0.86, 0.8, 0.8, 0.6, 0.8, 0.73, 0.73, 0.66, 0.73, 0.8, 0.73, 0.73, 0.8, 0.73, 0.8, 0.86, 0.66, 0.73, 0.66, 0.8, 0.73, 0.66, 0.66, 0.66, 0.8, 0.8, 0.46, 0.73, 0.73, 0.6, 0.86, 0.73, 0.8, 0.73, 0.86, 0.6, 0.73, 0.73, 0.46, 0.8, 0.73, 0.8, 0.8, 0.73, 0.8, 0.53, 0.46, 0.66, 0.8, 0.86, 0.86, 0.73, 0.8, 0.53, 0.73, 0.73, 0.86, 0.73, 0.66, 0.6, 0.66, 0.73, 0.66, 0.8, 0.73, 0.73, 0.6, 0.66, 0.73, 0.66


Running iteration 2 of 10 fold...
[70, 0, 3, 18, 43, 1, 45, 31, 2, 56, 6, 59, 4, 5, 64, 7, 77, 10, 65, 11, 84, 12, 17, 19, 28, 20, 91, 8]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.5821, 0.5530, 0.3947, 0.3856

    accuracy, precision, recall, f_score
max3: 0.6061, 0.5788, 0.4300, 0.4158

    accuracy, precision, recall, f_score
max1: 0.6667, 0.6726, 0.6696, 0.6667


min loss: 0.009, episode: 271000
max accu: 0.667, episode: 20000

1.00 classifiers used
    accuracy, precision, recall, f_score
mv: 0.6667, 0.7067, 0.6786, 0.6606
wv: 0.6667, 0.7067, 0.6786, 0.6606
fs: 0.6667, 0.7067, 0.6786, 0.6606
rl: 0.6667, 0.6726, 0.6696, 0.6667

0.6786666666666668
0.93, 0.66, 0.6, 0.6, 0.73, 0.73, 0.66, 0.6, 0.8, 0.8, 0.73, 0.66, 0.66, 0.66, 0.66, 0.53, 0.46, 0.73, 0.66, 0.6, 0.66, 0.66, 0.66, 0.66, 0.6, 0.73, 0.6, 0.53, 0.53, 0.66, 0.66, 0.8, 0.8, 0.73, 0.66, 0.8, 0.66, 0.8, 0.66, 0.46, 0.66, 0.73, 0.66, 0.86, 0.8, 0.6, 0.66, 0.73, 0.66, 0.73, 0.66, 0.66, 0.6, 0.86, 0.66, 0.66, 0.86, 0.66, 0.66, 0.6, 0.46, 0.66, 0.66, 0.66, 0.73, 0.8, 0.66, 0.6, 0.73, 0.53, 0.66, 0.6, 0.6, 0.8, 0.66, 0.8, 0.73, 0.6, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.8, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.73, 0.73, 0.6

0.662
0.4, 0.6, 0.73, 0.73, 0.53, 0.86, 0.66, 0.4, 0.73, 0.6, 0.66, 0.66, 0.6, 0.6, 0.73, 0.6, 0.66, 0.66, 0.66, 0.8, 0.6, 0.73, 0.6, 0.8, 0.8, 0.73, 0.73, 0.8, 0.6, 0.73, 0.66, 0.66, 0.6, 0.66, 0.66, 0.66, 0.46, 0.73, 0.66, 0.46, 0.66, 0.66, 0.53, 0.53, 0.86, 0.73, 0.66, 0.46, 0.66, 0.66, 0.66, 0.73, 0.86, 0.6, 0.73, 0.53, 0.8, 0.66, 0.73, 0.73, 0.6, 0.8, 0.66, 0.4, 0.53, 0.46, 0.73, 0.73, 0.73, 0.66, 0.66, 0.6, 0.6, 0.66, 0.66, 0.6, 0.8, 0.66, 0.66, 0.73, 0.73, 0.73, 0.73, 0.46, 0.6, 0.86, 0.66, 0.6, 0.6, 0.73, 0.73, 0.6, 0.93, 0.73, 0.6, 0.46, 0.53, 0.73, 0.66, 0.6


Running iteration 3 of 10 fold...
[19, 0]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.8060, 0.8203, 0.7165, 0.7616

    accuracy, precision, recall, f_score
max3: 0.7576, 0.7578, 0.5317, 0.5126

    accuracy, precision, recall, f_score
max1: 0.8000, 0.7704, 0.6000, 0.5474


min loss: 0.003, episode: 296000
max accu: 0.800, episode: 20000

2.47 classifiers used
    accuracy, precision, recall, f_score
mv: 0.6667, 0.7048, 0.5333, 0.4575
wv: 0.7333, 0.7357, 0.5667, 0.5017
fs: 0.6000, 0.7733, 0.5000, 0.4127
rl: 0.8000, 0.7704, 0.6000, 0.5474

0.632
0.6, 0.66, 0.73, 0.73, 0.66, 0.8, 0.73, 0.4, 0.53, 0.66, 0.4, 0.66, 0.93, 0.53, 0.6, 0.73, 0.33, 0.66, 0.53, 0.6, 0.46, 0.73, 0.66, 0.6, 0.66, 0.66, 0.8, 0.6, 0.86, 0.73, 0.6, 0.33, 0.73, 0.73, 0.6, 0.66, 0.6, 0.73, 0.66, 0.66, 0.73, 0.73, 0.53, 0.6, 0.53, 0.73, 0.66, 0.66, 0.66, 0.73, 0.66, 0.6, 0.6, 0.66, 0.66, 0.6, 0.73, 0.86, 0.53, 0.53, 0.6, 0.8, 0.66, 0.66, 0.66, 0.53, 0.73, 0.66, 0.6, 0.8, 0.53, 0.66, 0.4, 0.66, 0.53, 0.53, 0.6, 0.66, 0.6, 0.6, 0.53, 0.53, 0.46, 0.6, 0.73, 0.66, 0.6, 0.53, 0.46, 0.66, 0.4, 0.73, 0.66, 0.8, 0.46, 0.6, 0.53, 0.73, 0.66, 0.53

0.638
0.73, 0.8, 0.6, 0.33, 0.66, 0.8, 0.6, 0.6, 0.6, 0.73, 0.46, 0.53, 0.73, 0.66, 0.46, 0.66, 0.66, 0.73, 0.8, 0.6, 0.6, 0.73, 0.73, 0.66, 0.46, 0.66, 0.53, 0.73, 0.46, 0.73, 0.66, 0.66, 0.53, 0.66, 0.6, 0.53, 0.73, 0.73, 0.6, 0.53, 0.93, 0.66, 0.46, 0.66, 0.53, 0.8, 0.66, 0.66, 0.4, 0.66, 0.8, 0.6, 0.66, 0.73, 0.66, 0.66, 0.53, 0.66, 0.66, 0.73, 0.8, 0.53, 0.6, 0.4, 0.4, 0.66, 0.53, 0.66, 0.6, 0.73, 0.53, 0.66, 0.73, 0.66, 0.73, 0.66, 0.73, 0.66, 0.66, 0.6, 0.33, 0.66, 0.6, 0.46, 0.8, 0.73, 0.66, 0.73, 0.73, 0.6, 0.6, 0.33, 0.66, 0.66, 0.6, 0.66, 0.6, 0.73, 0.73, 0.66


Running iteration 4 of 10 fold...
[9, 0, 41, 23, 52, 1, 28, 2, 43, 3, 47, 4, 64, 5]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.7612, 0.7664, 0.5129, 0.5116

    accuracy, precision, recall, f_score
max3: 0.7879, 0.7767, 0.5450, 0.5326

    accuracy, precision, recall, f_score
max1: 1.0000, 1.0000, 1.0000, 1.0000


min loss: 0.008, episode: 260000
max accu: 1.000, episode: 220000

2.00 classifiers used
    accuracy, precision, recall, f_score
mv: 0.8667, 0.8061, 0.5833, 0.5675
wv: 0.8667, 0.8222, 0.5833, 0.5887
fs: 0.8667, 0.8222, 0.5833, 0.5887
rl: 1.0000, 1.0000, 1.0000, 1.0000

0.8113333333333334
0.8, 0.93, 0.86, 0.86, 0.86, 0.86, 0.86, 0.66, 0.86, 0.93, 0.86, 0.86, 1.0, 0.8, 0.86, 0.33, 0.73, 1.0, 0.86, 0.73, 0.8, 0.86, 0.86, 0.46, 0.73, 1.0, 0.86, 0.73, 0.73, 0.86, 0.86, 0.46, 0.93, 0.86, 0.86, 0.53, 0.73, 0.8, 0.86, 0.6, 0.86, 0.86, 0.86, 0.66, 0.73, 0.8, 0.86, 0.46, 0.8, 0.86, 0.86, 0.66, 0.86, 0.86, 0.86, 0.86, 0.8, 0.86, 0.86, 0.53, 0.86, 0.93, 0.86, 0.46, 0.8, 0.93, 0.86, 0.66, 0.93, 0.86, 0.93, 0.86, 1.0, 1.0, 0.86, 0.8, 0.73, 0.93, 0.8, 0.86, 0.73, 0.86, 0.86, 0.8, 0.8, 1.0, 0.86, 0.4, 0.73, 0.86, 0.86, 0.8, 0.66, 0.86, 0.86, 0.8, 0.86, 0.93, 0.86, 0.73

0.8146666666666667
0.73, 0.93, 0.93, 0.46, 0.66, 0.8, 0.86, 0.73, 0.53, 0.8, 0.66, 0.53, 0.86, 0.86, 0.93, 0.53, 0.86, 0.93, 0.86, 0.8, 0.6, 0.86, 0.86, 0.86, 0.53, 0.86, 0.86, 0.46, 0.86, 0.8, 0.86, 0.53, 0.93, 0.86, 0.86, 0.73, 0.73, 0.86, 0.86, 0.8, 0.73, 0.93, 0.86, 0.86, 0.8, 0.86, 0.93, 0.8, 0.86, 0.93, 0.86, 0.8, 0.8, 0.93, 0.86, 0.8, 0.73, 0.93, 0.8, 0.86, 0.93, 0.86, 0.8, 0.73, 0.86, 0.93, 0.8, 0.46, 0.93, 0.93, 0.86, 0.4, 0.86, 1.0, 0.86, 0.46, 0.8, 0.86, 0.86, 0.86, 0.8, 0.86, 0.86, 0.93, 0.86, 0.86, 0.86, 0.93, 0.93, 0.93, 0.8, 0.86, 0.73, 0.93, 0.86, 0.73, 0.93, 0.8, 0.86, 0.93

    accuracy, precision, recall, f_score
mv: 0.8222, 0.7460, 0.5801, 0.5182
wv: 0.8222, 0.7578, 0.5885, 0.5252
fs: 0.8667, 0.7769, 0.5794, 0.5570
rl: 0.8889, 0.8241, 0.7265, 0.6050

fs avg size: 14.75000, rl avg size: 1.61667
full test avg accu: 0.71000, test avg accu: 0.71183

training takes 27535.847 sec
