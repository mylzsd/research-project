{'dataset': 'lymphography', 'algorithm': 'ptdqn', 'num_clf': 50, 'num_training': 500000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 2860, 'portion': 0.5, 'sequential': False}
(148, 39)
reading data takes 0.448 sec
number of labels: 4

Running iteration 1 of 10 fold...
[1, 0, 3, 24, 26, 29, 8, 2, 20, 12, 9, 5, 30, 4, 16, 28, 34, 27, 37, 17]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.880597, 0.872601, 0.762596, 0.813601

    accuracy, precision, recall, f_score
max3: 0.818182, 0.796955, 0.716667, 0.762410

    accuracy, precision, recall, f_score
max1: 0.666667, 0.628571, 0.708333, 0.682692


min loss: 0.006, episode: 290000
max accu: 0.881, episode: 490000

10.13 classifiers used
    accuracy, precision, recall, f_score
mv: 0.866667, 0.866667, 0.902778, 0.902778
wv: 0.866667, 0.866667, 0.902778, 0.902778
fs: 0.733333, 0.681481, 0.770833, 0.745098
rl: 0.666667, 0.628571, 0.708333, 0.682692

0.7116417910447762
0.73, 0.80, 0.77, 0.80, 0.70, 0.65, 0.74, 0.71, 0.64, 0.74, 0.70, 0.65, 0.77, 0.79, 0.70, 0.68, 0.68, 0.73, 0.61, 0.65, 0.71, 0.67, 0.73, 0.64, 0.64, 0.67, 0.74, 0.56, 0.76, 0.74, 0.74, 0.67, 0.76, 0.76, 0.67, 0.79, 0.76, 0.79, 0.71, 0.62, 0.71, 0.65, 0.71, 0.64, 0.68, 0.68, 0.67, 0.79, 0.73, 0.76

0.6672727272727272
0.72, 0.78, 0.72, 0.72, 0.60, 0.63, 0.69, 0.69, 0.72, 0.63, 0.63, 0.54, 0.78, 0.78, 0.69, 0.63, 0.66, 0.72, 0.51, 0.63, 0.72, 0.63, 0.60, 0.57, 0.69, 0.63, 0.72, 0.51, 0.57, 0.84, 0.63, 0.66, 0.63, 0.72, 0.63, 0.75, 0.66, 0.75, 0.63, 0.63, 0.75, 0.60, 0.69, 0.60, 0.60, 0.60, 0.57, 0.63, 0.66, 0.69

0.64
0.6, 0.66, 0.6, 0.66, 0.66, 0.6, 0.53, 0.66, 0.73, 0.8, 0.73, 0.66, 0.6, 0.6, 0.6, 0.53, 0.6, 0.66, 0.6, 0.66, 0.66, 0.53, 0.86, 0.73, 0.53, 0.53, 0.66, 0.4, 0.73, 0.53, 0.73, 0.53, 0.86, 0.53, 0.53, 0.6, 0.46, 0.8, 0.53, 0.46, 0.53, 0.46, 0.73, 0.73, 0.66, 0.6, 0.86, 0.93, 0.66, 0.73

0.7226666666666667
0.73, 0.66, 0.8, 0.73, 0.53, 0.66, 0.66, 0.73, 0.8, 0.73, 0.8, 0.66, 0.53, 0.73, 0.86, 0.8, 0.73, 0.6, 0.8, 0.73, 0.6, 0.8, 0.6, 0.93, 0.73, 0.66, 0.6, 0.73, 0.86, 0.73, 0.8, 0.6, 0.73, 0.8, 0.6, 0.93, 0.46, 0.8, 0.8, 0.86, 0.73, 0.73, 0.8, 0.46, 0.66, 0.8, 0.73, 0.8, 0.73, 0.66


Running iteration 2 of 10 fold...
[8, 0, 12, 34]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.820896, 0.821817, 0.685262, 0.722710

    accuracy, precision, recall, f_score
max3: 0.727273, 0.748129, 0.637037, 0.652292

    accuracy, precision, recall, f_score
max1: 0.800000, 0.803704, 0.794643, 0.796380


min loss: 0.006, episode: 224000
max accu: 0.821, episode: 500000

4.80 classifiers used
    accuracy, precision, recall, f_score
mv: 0.866667, 0.893333, 0.857143, 0.861111
wv: 0.866667, 0.893333, 0.857143, 0.861111
fs: 0.933333, 0.941667, 0.937500, 0.933333
rl: 0.800000, 0.803704, 0.794643, 0.796380

0.6788059701492537
0.70, 0.82, 0.71, 0.73, 0.74, 0.67, 0.62, 0.64, 0.83, 0.67, 0.62, 0.62, 0.76, 0.65, 0.65, 0.71, 0.79, 0.70, 0.68, 0.59, 0.67, 0.70, 0.68, 0.53, 0.70, 0.62, 0.59, 0.68, 0.71, 0.76, 0.64, 0.68, 0.74, 0.61, 0.68, 0.73, 0.64, 0.74, 0.73, 0.59, 0.62, 0.62, 0.70, 0.59, 0.65, 0.73, 0.58, 0.55, 0.71, 0.65

0.6187878787878788
0.54, 0.72, 0.57, 0.69, 0.57, 0.60, 0.57, 0.60, 0.78, 0.54, 0.54, 0.60, 0.75, 0.60, 0.60, 0.66, 0.72, 0.60, 0.63, 0.57, 0.60, 0.66, 0.57, 0.51, 0.60, 0.57, 0.48, 0.66, 0.66, 0.66, 0.51, 0.63, 0.63, 0.57, 0.66, 0.69, 0.57, 0.69, 0.54, 0.57, 0.60, 0.60, 0.63, 0.57, 0.72, 0.63, 0.51, 0.60, 0.63, 0.66

0.7146666666666667
0.66, 0.8, 0.53, 0.93, 0.8, 0.73, 0.66, 0.73, 0.86, 0.73, 0.4, 0.6, 0.93, 0.66, 0.66, 0.73, 0.73, 0.66, 0.8, 0.73, 0.66, 0.86, 0.6, 0.73, 0.8, 0.4, 0.66, 0.6, 0.73, 0.8, 0.8, 0.73, 0.73, 0.66, 0.73, 0.8, 0.6, 0.66, 0.93, 0.53, 0.73, 0.8, 0.86, 0.66, 0.6, 0.86, 0.86, 0.6, 0.8, 0.46

0.7799999999999998
0.8, 0.86, 0.86, 0.8, 0.86, 0.8, 0.8, 0.73, 0.8, 0.8, 0.86, 0.86, 0.8, 0.73, 0.93, 0.86, 0.8, 0.66, 0.8, 0.66, 0.93, 0.73, 0.8, 0.73, 0.8, 0.86, 0.93, 0.66, 0.66, 0.86, 0.73, 0.8, 0.6, 0.8, 0.73, 0.8, 0.73, 0.6, 0.73, 0.8, 0.6, 0.6, 0.8, 0.73, 0.8, 0.73, 0.73, 0.86, 0.8, 0.86


Running iteration 3 of 10 fold...
[9, 0, 16, 45, 6, 31, 21, 5]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.850746, 0.818831, 0.860000, 0.853488

    accuracy, precision, recall, f_score
max3: 0.757576, 0.676768, 0.722222, 0.704167

    accuracy, precision, recall, f_score
max1: 0.600000, 0.520000, 0.714286, 0.625000


min loss: 0.006, episode: 285000
max accu: 0.851, episode: 240000

15.40 classifiers used
    accuracy, precision, recall, f_score
mv: 0.666667, 0.723333, 0.642857, 0.654040
wv: 0.666667, 0.723333, 0.642857, 0.654040
fs: 0.533333, 0.451515, 0.642857, 0.534759
rl: 0.600000, 0.520000, 0.714286, 0.625000

0.7059701492537315
0.71, 0.76, 0.65, 0.74, 0.55, 0.77, 0.76, 0.64, 0.67, 0.79, 0.67, 0.77, 0.74, 0.58, 0.71, 0.79, 0.70, 0.67, 0.74, 0.70, 0.71, 0.74, 0.67, 0.68, 0.68, 0.64, 0.65, 0.73, 0.73, 0.71, 0.73, 0.76, 0.77, 0.59, 0.74, 0.68, 0.70, 0.71, 0.64, 0.73, 0.65, 0.70, 0.64, 0.73, 0.73, 0.76, 0.71, 0.64, 0.73, 0.73

0.6460606060606061
0.66, 0.69, 0.63, 0.72, 0.54, 0.69, 0.69, 0.63, 0.54, 0.75, 0.63, 0.72, 0.63, 0.42, 0.69, 0.72, 0.63, 0.57, 0.72, 0.63, 0.60, 0.60, 0.63, 0.60, 0.63, 0.54, 0.57, 0.66, 0.60, 0.66, 0.66, 0.60, 0.75, 0.57, 0.69, 0.63, 0.66, 0.60, 0.57, 0.69, 0.63, 0.66, 0.60, 0.66, 0.66, 0.72, 0.66, 0.60, 0.66, 0.72

0.596
0.46, 0.46, 0.66, 0.66, 0.6, 0.6, 0.53, 0.66, 0.53, 0.6, 0.6, 0.53, 0.66, 0.53, 0.46, 0.53, 0.4, 0.8, 0.4, 0.53, 0.53, 0.6, 0.73, 0.73, 0.6, 0.53, 0.66, 0.4, 0.8, 0.66, 0.66, 0.46, 0.53, 0.66, 0.6, 0.6, 0.6, 0.73, 0.6, 0.53, 0.66, 0.66, 0.6, 0.6, 0.8, 0.53, 0.66, 0.46, 0.6, 0.66

0.6453333333333333
0.4, 0.46, 0.73, 0.66, 0.66, 0.53, 0.8, 0.66, 0.73, 0.73, 0.66, 0.66, 0.8, 0.66, 0.6, 0.6, 0.4, 0.6, 0.6, 0.53, 0.73, 0.6, 0.66, 0.66, 0.53, 0.6, 0.53, 0.86, 0.8, 0.6, 0.26, 0.73, 0.73, 0.73, 0.8, 0.66, 0.8, 0.53, 0.73, 0.6, 0.73, 0.66, 0.66, 0.73, 0.66, 0.66, 0.53, 0.6, 0.73, 0.53


Running iteration 4 of 10 fold...
[21, 0, 30, 38, 45, 20]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.850746, 0.798970, 0.886842, 0.864953

    accuracy, precision, recall, f_score
max3: 0.787879, 0.712121, 0.809524, 0.777778

    accuracy, precision, recall, f_score
max1: 1.000000, 1.000000, 1.000000, 1.000000


min loss: 0.009, episode: 233000
max accu: 0.851, episode: 220000

17.80 classifiers used
    accuracy, precision, recall, f_score
mv: 0.933333, 0.939394, 0.900000, 0.920635
wv: 0.933333, 0.939394, 0.900000, 0.920635
fs: 0.933333, 0.944444, 0.950000, 0.928230
rl: 1.000000, 1.000000, 1.000000, 1.000000

0.6970149253731344
0.76, 0.71, 0.77, 0.59, 0.76, 0.68, 0.73, 0.70, 0.74, 0.77, 0.56, 0.59, 0.65, 0.67, 0.74, 0.68, 0.67, 0.73, 0.70, 0.79, 0.76, 0.80, 0.73, 0.64, 0.74, 0.73, 0.49, 0.64, 0.65, 0.77, 0.79, 0.76, 0.65, 0.70, 0.67, 0.59, 0.73, 0.74, 0.73, 0.67, 0.59, 0.74, 0.70, 0.59, 0.65, 0.67, 0.71, 0.64, 0.64, 0.76

0.6606060606060606
0.63, 0.66, 0.72, 0.51, 0.78, 0.63, 0.63, 0.66, 0.69, 0.72, 0.51, 0.54, 0.63, 0.54, 0.75, 0.60, 0.69, 0.66, 0.66, 0.81, 0.72, 0.78, 0.66, 0.60, 0.69, 0.69, 0.57, 0.63, 0.51, 0.72, 0.69, 0.81, 0.66, 0.69, 0.63, 0.60, 0.69, 0.75, 0.66, 0.66, 0.63, 0.66, 0.66, 0.60, 0.69, 0.54, 0.69, 0.57, 0.51, 0.72

0.7653333333333333
0.86, 0.73, 0.86, 0.86, 0.86, 0.93, 0.53, 0.73, 0.86, 0.73, 0.53, 0.86, 0.53, 0.8, 0.73, 0.86, 0.73, 0.93, 0.73, 0.86, 0.73, 0.8, 0.86, 0.66, 0.8, 0.86, 0.73, 0.6, 0.8, 0.93, 0.73, 0.86, 0.53, 0.73, 0.66, 0.66, 0.86, 0.66, 0.8, 0.66, 0.73, 0.8, 0.73, 0.66, 0.73, 0.8, 0.86, 0.8, 0.66, 0.86

0.7706666666666666
0.8, 0.93, 0.86, 0.86, 0.8, 0.86, 0.6, 0.66, 0.6, 0.53, 0.8, 0.73, 0.73, 0.8, 0.73, 0.86, 0.66, 0.73, 0.8, 0.86, 0.73, 0.73, 0.8, 0.86, 0.66, 0.93, 0.73, 0.8, 0.86, 0.86, 0.53, 0.66, 0.86, 0.93, 0.8, 0.8, 0.73, 0.8, 0.73, 0.8, 0.8, 0.73, 0.73, 0.73, 0.86, 0.66, 0.6, 0.93, 0.8, 0.73


Running iteration 5 of 10 fold...
[22, 0, 18]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.910448, 0.901871, 0.833333, 0.876216

    accuracy, precision, recall, f_score
max3: 0.848485, 0.828918, 0.722222, 0.776570

    accuracy, precision, recall, f_score
max1: 0.733333, 0.764286, 0.750000, 0.732143


min loss: 0.008, episode: 227000
max accu: 0.910, episode: 200000

6.20 classifiers used
    accuracy, precision, recall, f_score
mv: 0.800000, 0.866667, 0.833333, 0.800000
wv: 0.800000, 0.866667, 0.833333, 0.800000
fs: 0.800000, 0.866667, 0.833333, 0.800000
rl: 0.733333, 0.764286, 0.750000, 0.732143

0.715820895522388
0.67, 0.79, 0.62, 0.73, 0.74, 0.77, 0.76, 0.79, 0.73, 0.67, 0.74, 0.71, 0.68, 0.64, 0.65, 0.71, 0.70, 0.73, 0.79, 0.76, 0.71, 0.61, 0.85, 0.59, 0.68, 0.61, 0.82, 0.80, 0.70, 0.76, 0.70, 0.80, 0.70, 0.70, 0.67, 0.71, 0.65, 0.85, 0.65, 0.65, 0.76, 0.76, 0.70, 0.71, 0.71, 0.68, 0.71, 0.70, 0.62, 0.67

0.6666666666666667
0.60, 0.69, 0.60, 0.66, 0.78, 0.72, 0.78, 0.63, 0.66, 0.63, 0.63, 0.69, 0.66, 0.60, 0.57, 0.66, 0.57, 0.78, 0.63, 0.69, 0.66, 0.57, 0.87, 0.51, 0.63, 0.57, 0.78, 0.78, 0.57, 0.66, 0.60, 0.81, 0.63, 0.63, 0.69, 0.63, 0.72, 0.75, 0.57, 0.57, 0.60, 0.75, 0.57, 0.69, 0.69, 0.72, 0.63, 0.66, 0.60, 0.66

0.7240000000000001
0.73, 0.8, 0.66, 0.73, 0.8, 0.73, 0.53, 0.73, 0.6, 0.66, 0.8, 0.73, 0.86, 0.66, 0.73, 0.66, 0.66, 0.6, 0.73, 0.8, 0.73, 0.66, 0.66, 0.93, 0.66, 0.53, 0.8, 0.8, 0.8, 0.6, 0.93, 0.86, 0.73, 0.73, 0.6, 0.66, 0.73, 0.73, 0.66, 0.8, 0.8, 0.8, 0.86, 0.66, 0.73, 0.6, 0.73, 0.73, 0.66, 0.66

0.752
0.73, 0.8, 0.8, 0.66, 0.66, 0.86, 0.8, 0.66, 0.93, 0.73, 0.66, 0.86, 0.66, 0.8, 0.66, 0.8, 0.73, 0.86, 0.86, 0.73, 0.66, 0.73, 0.8, 0.66, 0.86, 0.8, 0.8, 0.73, 0.73, 0.66, 0.8, 0.8, 0.8, 0.86, 0.66, 0.6, 0.73, 0.8, 0.66, 0.8, 0.86, 0.86, 0.53, 0.73, 0.66, 0.73, 0.93, 0.8, 0.73, 0.4


Running iteration 6 of 10 fold...
[40, 0, 34, 2, 38, 4, 1, 8, 19, 20, 3]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.865672, 0.843947, 0.903904, 0.886806

    accuracy, precision, recall, f_score
max3: 0.818182, 0.774892, 0.864035, 0.831984

    accuracy, precision, recall, f_score
max1: 0.666667, 0.622222, 0.708333, 0.686275


min loss: 0.007, episode: 259000
max accu: 0.866, episode: 490000

4.53 classifiers used
    accuracy, precision, recall, f_score
mv: 0.866667, 0.809524, 0.937500, 0.899038
wv: 0.866667, 0.809524, 0.937500, 0.899038
fs: 0.866667, 0.809524, 0.937500, 0.899038
rl: 0.666667, 0.622222, 0.708333, 0.686275

0.7056716417910448
0.73, 0.70, 0.76, 0.77, 0.68, 0.61, 0.76, 0.74, 0.74, 0.50, 0.64, 0.61, 0.71, 0.70, 0.62, 0.71, 0.65, 0.76, 0.73, 0.71, 0.70, 0.53, 0.76, 0.71, 0.73, 0.71, 0.74, 0.73, 0.73, 0.68, 0.73, 0.67, 0.74, 0.62, 0.73, 0.74, 0.62, 0.62, 0.77, 0.73, 0.83, 0.68, 0.74, 0.77, 0.73, 0.61, 0.68, 0.77, 0.74, 0.70

0.667878787878788
0.63, 0.69, 0.72, 0.78, 0.66, 0.51, 0.75, 0.66, 0.63, 0.42, 0.66, 0.60, 0.66, 0.63, 0.51, 0.60, 0.57, 0.78, 0.72, 0.72, 0.72, 0.63, 0.63, 0.66, 0.63, 0.63, 0.84, 0.66, 0.63, 0.63, 0.66, 0.66, 0.75, 0.63, 0.66, 0.72, 0.51, 0.63, 0.75, 0.69, 0.81, 0.75, 0.69, 0.78, 0.78, 0.45, 0.63, 0.66, 0.72, 0.57

0.7226666666666667
0.66, 0.53, 0.86, 0.73, 0.73, 0.53, 0.8, 0.53, 0.93, 0.8, 0.86, 0.86, 0.8, 0.8, 0.8, 0.6, 0.8, 0.53, 0.8, 0.8, 0.53, 0.6, 0.8, 0.8, 0.6, 0.73, 0.6, 0.73, 0.86, 0.8, 0.66, 0.8, 0.66, 0.66, 0.66, 0.66, 0.73, 0.66, 0.73, 0.6, 0.8, 0.8, 0.8, 0.8, 0.66, 0.6, 0.86, 0.53, 0.73, 0.8

0.7373333333333332
0.86, 0.66, 0.8, 0.73, 0.8, 0.8, 0.6, 0.66, 0.8, 0.73, 0.73, 0.66, 0.8, 0.73, 0.66, 0.73, 0.86, 1.0, 0.6, 0.86, 0.86, 0.6, 0.86, 0.73, 0.8, 0.6, 0.93, 0.53, 0.73, 0.66, 0.66, 0.66, 0.46, 0.53, 0.73, 0.8, 0.86, 0.8, 0.93, 0.6, 0.86, 0.66, 0.8, 0.66, 0.86, 0.6, 0.66, 0.73, 0.8, 0.66


Running iteration 7 of 10 fold...
[40, 0, 1, 8, 4, 2, 19, 6, 3, 10, 28, 5, 12, 11, 14, 15, 20, 22, 13, 47, 23, 17, 32, 36, 33, 18, 42]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.835821, 0.861940, 0.888889, 0.885714

    accuracy, precision, recall, f_score
max3: 0.818182, 0.867769, 0.866667, 0.864035

    accuracy, precision, recall, f_score
max1: 0.800000, 0.820000, 0.784091, 0.761905


min loss: 0.008, episode: 230000
max accu: 0.836, episode: 410000

3.00 classifiers used
    accuracy, precision, recall, f_score
mv: 0.800000, 0.820000, 0.784091, 0.761905
wv: 0.800000, 0.820000, 0.784091, 0.761905
fs: 0.733333, 0.785185, 0.738636, 0.700000
rl: 0.800000, 0.820000, 0.784091, 0.761905

0.7131343283582089
0.82, 0.73, 0.59, 0.74, 0.73, 0.76, 0.76, 0.55, 0.71, 0.62, 0.68, 0.73, 0.76, 0.62, 0.70, 0.80, 0.80, 0.65, 0.64, 0.76, 0.82, 0.65, 0.76, 0.62, 0.62, 0.74, 0.70, 0.70, 0.71, 0.80, 0.76, 0.71, 0.77, 0.70, 0.70, 0.74, 0.80, 0.68, 0.74, 0.65, 0.83, 0.58, 0.74, 0.73, 0.49, 0.70, 0.74, 0.74, 0.76, 0.62

0.6830303030303031
0.78, 0.72, 0.48, 0.72, 0.63, 0.63, 0.78, 0.48, 0.63, 0.66, 0.63, 0.75, 0.75, 0.60, 0.66, 0.75, 0.81, 0.72, 0.60, 0.75, 0.78, 0.72, 0.66, 0.57, 0.60, 0.69, 0.60, 0.63, 0.69, 0.75, 0.72, 0.66, 0.72, 0.60, 0.69, 0.72, 0.78, 0.72, 0.72, 0.63, 0.81, 0.60, 0.66, 0.72, 0.48, 0.69, 0.63, 0.72, 0.75, 0.57

0.6946666666666665
0.86, 0.73, 0.66, 0.53, 0.8, 0.73, 0.6, 0.53, 0.66, 0.4, 0.4, 0.6, 0.8, 0.66, 0.8, 0.73, 0.86, 0.73, 0.73, 0.8, 0.86, 0.8, 0.53, 0.66, 0.73, 0.73, 0.6, 0.73, 0.53, 0.73, 0.8, 0.86, 0.86, 0.6, 0.66, 0.73, 0.66, 0.6, 0.6, 0.73, 0.66, 0.73, 0.6, 0.8, 0.4, 0.73, 0.6, 0.8, 0.93, 0.73

0.7199999999999999
0.8, 0.73, 0.73, 0.86, 0.66, 0.93, 0.73, 0.86, 0.6, 0.66, 0.8, 0.73, 0.8, 0.26, 0.73, 0.66, 0.6, 0.86, 0.6, 0.8, 0.73, 0.53, 0.93, 0.73, 0.73, 0.6, 0.6, 0.73, 0.8, 0.66, 0.73, 0.8, 0.66, 0.73, 0.73, 0.86, 0.73, 0.6, 0.46, 0.6, 0.53, 0.93, 0.8, 0.53, 0.73, 0.8, 0.73, 0.8, 0.8, 0.86


Running iteration 8 of 10 fold...
[22, 0, 37, 1, 35, 26]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.820896, 0.809136, 0.895238, 0.781251

    accuracy, precision, recall, f_score
max3: 0.818182, 0.798347, 0.848684, 0.848115

    accuracy, precision, recall, f_score
max1: 0.800000, 0.866667, 0.833333, 0.800000


min loss: 0.005, episode: 296000
max accu: 0.821, episode: 30000

2.60 classifiers used
    accuracy, precision, recall, f_score
mv: 0.933333, 0.942857, 0.944444, 0.932127
wv: 0.933333, 0.942857, 0.944444, 0.932127
fs: 0.733333, 0.764286, 0.750000, 0.732143
rl: 0.800000, 0.866667, 0.833333, 0.800000

0.6817910447761193
0.70, 0.70, 0.74, 0.53, 0.71, 0.68, 0.70, 0.56, 0.68, 0.52, 0.46, 0.73, 0.73, 0.71, 0.68, 0.70, 0.71, 0.76, 0.58, 0.76, 0.64, 0.68, 0.85, 0.64, 0.77, 0.68, 0.65, 0.68, 0.64, 0.71, 0.62, 0.64, 0.56, 0.74, 0.64, 0.73, 0.68, 0.74, 0.73, 0.82, 0.71, 0.74, 0.71, 0.59, 0.68, 0.59, 0.64, 0.68, 0.68, 0.67

0.673939393939394
0.69, 0.75, 0.72, 0.42, 0.69, 0.66, 0.75, 0.51, 0.78, 0.60, 0.36, 0.75, 0.75, 0.69, 0.60, 0.72, 0.69, 0.72, 0.54, 0.72, 0.60, 0.66, 0.84, 0.57, 0.81, 0.66, 0.66, 0.69, 0.60, 0.72, 0.66, 0.66, 0.66, 0.72, 0.60, 0.66, 0.63, 0.78, 0.63, 0.84, 0.63, 0.72, 0.69, 0.63, 0.66, 0.60, 0.54, 0.75, 0.72, 0.66

0.6586666666666666
0.6, 0.6, 0.73, 0.6, 0.66, 0.8, 0.66, 0.46, 0.8, 0.6, 0.46, 0.8, 0.53, 0.86, 0.73, 0.8, 0.73, 0.8, 0.66, 0.53, 0.4, 0.66, 0.73, 0.66, 0.73, 0.8, 0.53, 0.53, 0.66, 0.53, 0.6, 0.73, 0.53, 0.4, 0.66, 0.73, 0.8, 0.66, 0.53, 0.8, 0.73, 0.8, 0.8, 0.53, 0.73, 0.66, 0.6, 0.6, 0.6, 0.66

0.7439999999999999
0.66, 0.6, 0.8, 0.73, 0.66, 0.66, 0.8, 0.86, 0.73, 0.73, 0.73, 0.6, 0.73, 0.93, 0.8, 0.66, 0.8, 0.6, 0.6, 0.6, 1.0, 0.73, 0.73, 0.8, 0.66, 0.6, 0.86, 0.73, 0.66, 0.66, 0.8, 0.73, 0.66, 0.66, 0.66, 0.86, 0.93, 0.93, 0.73, 0.73, 0.6, 0.66, 0.66, 0.66, 0.86, 0.86, 0.73, 0.8, 0.86, 0.93


Running iteration 9 of 10 fold...
[1, 0, 11, 9, 20, 28, 23, 19, 3]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.835821, 0.815397, 0.698646, 0.736772

    accuracy, precision, recall, f_score
max3: 0.818182, 0.767145, 0.863445, 0.837302

    accuracy, precision, recall, f_score
max1: 0.928571, 0.942857, 0.950000, 0.918129


min loss: 0.008, episode: 238000
max accu: 0.836, episode: 360000

21.79 classifiers used
    accuracy, precision, recall, f_score
mv: 0.928571, 0.942857, 0.950000, 0.918129
wv: 0.928571, 0.942857, 0.950000, 0.918129
fs: 0.928571, 0.942857, 0.950000, 0.918129
rl: 0.928571, 0.942857, 0.950000, 0.918129

0.6868656716417911
0.73, 0.79, 0.74, 0.58, 0.70, 0.73, 0.71, 0.59, 0.58, 0.67, 0.62, 0.74, 0.70, 0.68, 0.68, 0.70, 0.67, 0.55, 0.71, 0.59, 0.73, 0.70, 0.73, 0.64, 0.73, 0.73, 0.68, 0.70, 0.73, 0.70, 0.53, 0.70, 0.61, 0.67, 0.79, 0.79, 0.68, 0.67, 0.71, 0.76, 0.74, 0.64, 0.64, 0.74, 0.71, 0.68, 0.64, 0.71, 0.61, 0.62

0.6721212121212122
0.75, 0.78, 0.75, 0.63, 0.69, 0.72, 0.72, 0.57, 0.57, 0.66, 0.57, 0.78, 0.63, 0.66, 0.63, 0.72, 0.63, 0.51, 0.66, 0.57, 0.72, 0.63, 0.69, 0.63, 0.75, 0.78, 0.72, 0.63, 0.72, 0.75, 0.54, 0.69, 0.60, 0.66, 0.78, 0.84, 0.60, 0.63, 0.69, 0.72, 0.72, 0.57, 0.57, 0.72, 0.75, 0.66, 0.57, 0.66, 0.54, 0.54

0.8028571428571429
0.78, 0.71, 0.78, 0.71, 0.78, 0.92, 0.71, 0.78, 0.92, 0.57, 0.64, 0.85, 0.78, 0.92, 0.71, 1.0, 0.92, 0.71, 0.85, 0.85, 0.64, 0.92, 0.92, 0.71, 0.85, 1.0, 0.71, 0.57, 0.85, 0.57, 0.78, 0.78, 0.92, 0.85, 0.85, 0.71, 0.85, 0.92, 0.64, 0.71, 0.85, 0.85, 0.78, 0.85, 0.85, 0.92, 0.85, 0.85, 0.78, 0.64

0.8028571428571428
0.78, 0.78, 0.71, 0.71, 0.78, 0.92, 0.78, 0.78, 0.92, 0.85, 0.92, 0.85, 0.78, 0.85, 0.78, 0.92, 0.92, 0.85, 0.71, 0.85, 0.71, 1.0, 0.64, 0.85, 0.92, 0.78, 0.92, 0.64, 0.78, 0.78, 0.71, 0.64, 0.78, 0.71, 0.92, 0.85, 0.85, 0.85, 0.71, 0.85, 0.64, 0.71, 0.78, 0.71, 0.78, 0.85, 0.78, 0.78, 0.85, 0.64


Running iteration 10 of 10 fold...
[35, 0, 31, 8, 21, 27, 9, 13, 17, 45, 1]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.865672, 0.829178, 0.901961, 0.883089

    accuracy, precision, recall, f_score
max3: 0.878788, 0.858510, 0.906250, 0.890476

    accuracy, precision, recall, f_score
max1: 0.642857, 0.542857, 0.687500, 0.638889


min loss: 0.010, episode: 235000
max accu: 0.866, episode: 370000

25.07 classifiers used
    accuracy, precision, recall, f_score
mv: 0.642857, 0.614286, 0.750000, 0.731481
wv: 0.642857, 0.614286, 0.750000, 0.731481
fs: 0.642857, 0.542857, 0.687500, 0.638889
rl: 0.642857, 0.542857, 0.687500, 0.638889

0.739402985074627
0.70, 0.71, 0.67, 0.65, 0.73, 0.71, 0.79, 0.76, 0.73, 0.76, 0.76, 0.80, 0.68, 0.59, 0.79, 0.76, 0.70, 0.71, 0.76, 0.70, 0.68, 0.77, 0.82, 0.79, 0.68, 0.67, 0.80, 0.73, 0.71, 0.74, 0.77, 0.80, 0.74, 0.79, 0.79, 0.83, 0.82, 0.58, 0.70, 0.70, 0.82, 0.70, 0.82, 0.67, 0.71, 0.76, 0.67, 0.73, 0.80, 0.76

0.749090909090909
0.66, 0.78, 0.72, 0.69, 0.75, 0.69, 0.75, 0.75, 0.78, 0.72, 0.75, 0.75, 0.69, 0.66, 0.72, 0.72, 0.69, 0.81, 0.72, 0.75, 0.72, 0.78, 0.84, 0.75, 0.75, 0.69, 0.84, 0.81, 0.72, 0.78, 0.72, 0.81, 0.72, 0.78, 0.81, 0.81, 0.87, 0.60, 0.69, 0.72, 0.81, 0.75, 0.81, 0.57, 0.72, 0.72, 0.72, 0.72, 0.78, 0.72

0.5485714285714285
0.42, 0.57, 0.57, 0.5, 0.64, 0.35, 0.71, 0.57, 0.71, 0.57, 0.57, 0.42, 0.5, 0.28, 0.5, 0.57, 0.5, 0.57, 0.64, 0.42, 0.57, 0.71, 0.57, 0.42, 0.64, 0.57, 0.5, 0.64, 0.71, 0.42, 0.57, 0.5, 0.57, 0.5, 0.42, 0.64, 0.64, 0.5, 0.57, 0.42, 0.64, 0.64, 0.5, 0.5, 0.5, 0.71, 0.57, 0.5, 0.5, 0.57

0.5828571428571429
0.5, 0.64, 0.57, 0.57, 0.57, 0.71, 0.35, 0.57, 0.64, 0.5, 0.5, 0.57, 0.5, 0.57, 0.5, 0.57, 0.64, 0.42, 0.57, 0.57, 0.64, 0.57, 0.57, 0.35, 0.57, 0.42, 0.71, 0.71, 0.78, 0.64, 0.78, 0.57, 0.57, 0.78, 0.35, 0.64, 0.64, 0.57, 0.71, 0.57, 0.64, 0.5, 0.5, 0.71, 0.57, 0.42, 0.57, 0.64, 0.71, 0.57

    accuracy, precision, recall, f_score
mv: 0.830476, 0.841892, 0.850215, 0.838124
wv: 0.830476, 0.841892, 0.850215, 0.838124
fs: 0.783810, 0.773048, 0.819816, 0.782962
rl: 0.763810, 0.751116, 0.793052, 0.764141

fs avg size: 10.50000, rl avg size: 11.13238
full test avg accu: 0.72577, test avg accu: 0.68674

training takes 48295.762 sec
