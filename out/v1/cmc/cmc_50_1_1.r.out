{'dataset': 'cmc', 'algorithm': 'ptdqn', 'num_clf': 50, 'num_training': 400000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 5353, 'portion': 0.5, 'sequential': False}
(1473, 22)
reading data takes 5.756 sec
number of labels: 3

Running iteration 1 of 10 fold...
[3, 0, 32, 8, 5, 12, 14, 19, 34, 2, 37, 38, 33]
using cpu
using cpu
    accuracy, precision, recall, f_score
mdl: 0.445946, 0.440738, 0.409427, 0.409478

    accuracy, precision, recall, f_score
max: 0.552870, 0.549586, 0.537639, 0.539192

    accuracy, precision, recall, f_score
max: 0.533784, 0.531772, 0.495054, 0.494046


min loss: 0.006, episode: 185000
max accu: 0.553, episode: 300000

17.29 classifiers used
    accuracy, precision, recall, f_score
mv: 0.486486, 0.491771, 0.463514, 0.456408
wv: 0.493243, 0.494884, 0.462188, 0.458901
fs: 0.486486, 0.494376, 0.472204, 0.464672
rl: 0.533784, 0.531772, 0.495054, 0.494046

0.44874811463046754
0.43, 0.42, 0.43, 0.48, 0.47, 0.47, 0.42, 0.44, 0.48, 0.45, 0.43, 0.42, 0.44, 0.46, 0.45, 0.43, 0.42, 0.47, 0.42, 0.44, 0.42, 0.46, 0.43, 0.44, 0.44, 0.46, 0.45, 0.44, 0.43, 0.47, 0.45, 0.48, 0.46, 0.43, 0.46, 0.45, 0.46, 0.46, 0.43, 0.42, 0.41, 0.46, 0.46, 0.41, 0.44, 0.42, 0.43, 0.45, 0.44, 0.44

0.47069486404833827
0.44, 0.45, 0.49, 0.48, 0.47, 0.49, 0.47, 0.45, 0.49, 0.49, 0.42, 0.43, 0.46, 0.46, 0.48, 0.46, 0.44, 0.51, 0.45, 0.44, 0.46, 0.49, 0.46, 0.46, 0.48, 0.47, 0.47, 0.43, 0.45, 0.48, 0.48, 0.52, 0.50, 0.45, 0.49, 0.48, 0.47, 0.48, 0.45, 0.47, 0.44, 0.47, 0.47, 0.44, 0.48, 0.48, 0.46, 0.46, 0.45, 0.47

0.4616216216216217
0.47, 0.43, 0.46, 0.46, 0.49, 0.45, 0.42, 0.47, 0.45, 0.45, 0.47, 0.45, 0.41, 0.48, 0.43, 0.45, 0.47, 0.52, 0.43, 0.48, 0.44, 0.49, 0.48, 0.47, 0.50, 0.45, 0.44, 0.50, 0.48, 0.5, 0.43, 0.47, 0.47, 0.40, 0.53, 0.47, 0.46, 0.44, 0.49, 0.41, 0.42, 0.43, 0.41, 0.35, 0.46, 0.43, 0.49, 0.46, 0.46, 0.43

0.46324324324324323
0.39, 0.48, 0.51, 0.47, 0.51, 0.48, 0.44, 0.39, 0.5, 0.45, 0.49, 0.45, 0.48, 0.50, 0.42, 0.45, 0.47, 0.48, 0.48, 0.43, 0.52, 0.42, 0.43, 0.44, 0.45, 0.43, 0.44, 0.45, 0.48, 0.49, 0.43, 0.41, 0.48, 0.53, 0.52, 0.48, 0.46, 0.42, 0.45, 0.46, 0.44, 0.38, 0.42, 0.45, 0.39, 0.43, 0.52, 0.5, 0.43, 0.47


Running iteration 2 of 10 fold...
[33, 0, 48, 43, 22]
using cpu
using cpu
    accuracy, precision, recall, f_score
mdl: 0.520270, 0.511592, 0.490079, 0.487539

    accuracy, precision, recall, f_score
max: 0.531722, 0.522710, 0.494066, 0.494155

    accuracy, precision, recall, f_score
max: 0.547297, 0.549784, 0.528279, 0.534108


min loss: 0.006, episode: 221000
max accu: 0.532, episode: 270000

41.71 classifiers used
    accuracy, precision, recall, f_score
mv: 0.547297, 0.550418, 0.538993, 0.541662
wv: 0.560811, 0.563345, 0.550898, 0.555102
fs: 0.513514, 0.514746, 0.491374, 0.495410
rl: 0.547297, 0.549784, 0.528279, 0.534108

0.4488989441930618
0.46, 0.44, 0.43, 0.45, 0.45, 0.44, 0.42, 0.42, 0.46, 0.44, 0.45, 0.44, 0.43, 0.43, 0.43, 0.40, 0.44, 0.47, 0.45, 0.47, 0.42, 0.48, 0.44, 0.43, 0.43, 0.46, 0.44, 0.45, 0.42, 0.41, 0.46, 0.40, 0.47, 0.50, 0.47, 0.43, 0.45, 0.45, 0.45, 0.46, 0.41, 0.45, 0.45, 0.49, 0.42, 0.48, 0.42, 0.45, 0.46, 0.44

0.46290030211480354
0.51, 0.46, 0.47, 0.48, 0.46, 0.45, 0.44, 0.44, 0.47, 0.48, 0.45, 0.44, 0.45, 0.43, 0.44, 0.42, 0.46, 0.46, 0.46, 0.46, 0.43, 0.49, 0.45, 0.41, 0.45, 0.49, 0.44, 0.46, 0.42, 0.41, 0.48, 0.43, 0.49, 0.51, 0.49, 0.44, 0.44, 0.45, 0.46, 0.47, 0.44, 0.46, 0.50, 0.48, 0.45, 0.49, 0.42, 0.48, 0.50, 0.47

0.4752702702702704
0.43, 0.43, 0.48, 0.47, 0.51, 0.45, 0.47, 0.44, 0.46, 0.52, 0.43, 0.57, 0.45, 0.45, 0.38, 0.42, 0.51, 0.42, 0.47, 0.52, 0.43, 0.56, 0.47, 0.46, 0.45, 0.46, 0.41, 0.56, 0.56, 0.48, 0.47, 0.48, 0.43, 0.49, 0.47, 0.49, 0.49, 0.51, 0.47, 0.54, 0.48, 0.41, 0.46, 0.45, 0.44, 0.46, 0.45, 0.48, 0.44, 0.46

0.4710810810810811
0.46, 0.50, 0.47, 0.45, 0.44, 0.41, 0.47, 0.44, 0.51, 0.45, 0.45, 0.50, 0.52, 0.49, 0.46, 0.39, 0.43, 0.43, 0.41, 0.47, 0.43, 0.45, 0.43, 0.50, 0.49, 0.48, 0.45, 0.47, 0.45, 0.47, 0.47, 0.45, 0.43, 0.42, 0.53, 0.43, 0.45, 0.47, 0.47, 0.51, 0.5, 0.52, 0.53, 0.45, 0.45, 0.52, 0.5, 0.45, 0.52, 0.43


Running iteration 3 of 10 fold...
[49, 0, 43, 25, 2, 30, 1, 37]
using cpu
using cpu
    accuracy, precision, recall, f_score
mdl: 0.466216, 0.504386, 0.425463, 0.403278

    accuracy, precision, recall, f_score
max: 0.519637, 0.511690, 0.489000, 0.489064

    accuracy, precision, recall, f_score
max: 0.540541, 0.549967, 0.471944, 0.465520


min loss: 0.005, episode: 257000
max accu: 0.520, episode: 290000

41.66 classifiers used
    accuracy, precision, recall, f_score
mv: 0.540541, 0.568646, 0.466944, 0.456393
wv: 0.527027, 0.557053, 0.456111, 0.444212
fs: 0.527027, 0.534992, 0.465463, 0.450086
rl: 0.540541, 0.549967, 0.471944, 0.465520

0.44612368024132737
0.46, 0.46, 0.44, 0.46, 0.43, 0.42, 0.45, 0.43, 0.41, 0.43, 0.43, 0.44, 0.46, 0.44, 0.40, 0.45, 0.42, 0.44, 0.47, 0.46, 0.43, 0.44, 0.44, 0.42, 0.44, 0.49, 0.42, 0.41, 0.45, 0.43, 0.46, 0.46, 0.42, 0.44, 0.42, 0.44, 0.44, 0.47, 0.39, 0.43, 0.46, 0.42, 0.47, 0.46, 0.45, 0.41, 0.45, 0.47, 0.43, 0.49

0.45691842900302115
0.45, 0.47, 0.46, 0.46, 0.46, 0.45, 0.46, 0.43, 0.38, 0.44, 0.42, 0.48, 0.47, 0.45, 0.43, 0.45, 0.46, 0.45, 0.49, 0.49, 0.45, 0.45, 0.45, 0.41, 0.46, 0.51, 0.45, 0.41, 0.48, 0.40, 0.46, 0.45, 0.45, 0.45, 0.39, 0.49, 0.46, 0.47, 0.41, 0.45, 0.45, 0.43, 0.49, 0.47, 0.48, 0.43, 0.47, 0.48, 0.45, 0.50

0.45459459459459467
0.47, 0.47, 0.47, 0.47, 0.44, 0.45, 0.37, 0.44, 0.43, 0.48, 0.45, 0.43, 0.41, 0.43, 0.46, 0.45, 0.41, 0.47, 0.45, 0.34, 0.51, 0.41, 0.50, 0.45, 0.48, 0.5, 0.5, 0.41, 0.51, 0.41, 0.40, 0.41, 0.42, 0.46, 0.45, 0.44, 0.42, 0.50, 0.45, 0.42, 0.49, 0.48, 0.49, 0.44, 0.47, 0.41, 0.47, 0.5, 0.42, 0.46

0.4636486486486487
0.47, 0.45, 0.43, 0.49, 0.46, 0.46, 0.44, 0.46, 0.43, 0.45, 0.45, 0.45, 0.42, 0.46, 0.5, 0.47, 0.48, 0.51, 0.5, 0.45, 0.39, 0.42, 0.45, 0.44, 0.50, 0.47, 0.40, 0.39, 0.52, 0.43, 0.47, 0.39, 0.50, 0.48, 0.39, 0.46, 0.5, 0.43, 0.51, 0.50, 0.47, 0.45, 0.39, 0.45, 0.45, 0.51, 0.46, 0.48, 0.52, 0.47


Running iteration 4 of 10 fold...
[46, 0, 18, 1, 44, 22]
using cpu
using cpu
    accuracy, precision, recall, f_score
mdl: 0.442177, 0.449592, 0.418656, 0.418001

    accuracy, precision, recall, f_score
max: 0.492447, 0.486068, 0.470316, 0.470229

    accuracy, precision, recall, f_score
max: 0.496599, 0.495247, 0.460311, 0.460601


min loss: 0.007, episode: 171000
max accu: 0.492, episode: 300000

12.60 classifiers used
    accuracy, precision, recall, f_score
mv: 0.503401, 0.512831, 0.474218, 0.468109
wv: 0.503401, 0.515145, 0.474218, 0.467969
fs: 0.503401, 0.518933, 0.469083, 0.470617
rl: 0.496599, 0.495247, 0.460311, 0.460601

0.4488386123680241
0.44, 0.45, 0.47, 0.46, 0.43, 0.45, 0.44, 0.46, 0.44, 0.42, 0.46, 0.42, 0.45, 0.46, 0.45, 0.45, 0.44, 0.44, 0.49, 0.45, 0.44, 0.40, 0.46, 0.41, 0.45, 0.45, 0.44, 0.46, 0.42, 0.46, 0.43, 0.46, 0.44, 0.42, 0.45, 0.46, 0.44, 0.46, 0.41, 0.42, 0.48, 0.47, 0.42, 0.44, 0.46, 0.42, 0.49, 0.41, 0.39, 0.44

0.45069486404833836
0.41, 0.47, 0.48, 0.48, 0.45, 0.45, 0.45, 0.45, 0.45, 0.43, 0.46, 0.40, 0.46, 0.45, 0.47, 0.45, 0.45, 0.43, 0.49, 0.45, 0.45, 0.39, 0.45, 0.42, 0.46, 0.45, 0.45, 0.47, 0.40, 0.48, 0.39, 0.47, 0.43, 0.44, 0.44, 0.47, 0.44, 0.45, 0.44, 0.45, 0.50, 0.46, 0.44, 0.42, 0.47, 0.40, 0.50, 0.43, 0.38, 0.42

0.4421768707482993
0.50, 0.47, 0.42, 0.40, 0.46, 0.48, 0.44, 0.41, 0.46, 0.44, 0.36, 0.42, 0.38, 0.48, 0.42, 0.38, 0.42, 0.46, 0.53, 0.47, 0.49, 0.33, 0.47, 0.41, 0.47, 0.42, 0.44, 0.44, 0.41, 0.39, 0.44, 0.44, 0.51, 0.39, 0.44, 0.43, 0.45, 0.42, 0.41, 0.43, 0.44, 0.49, 0.40, 0.38, 0.51, 0.45, 0.45, 0.41, 0.46, 0.44

0.445578231292517
0.48, 0.44, 0.44, 0.42, 0.42, 0.49, 0.42, 0.44, 0.52, 0.37, 0.48, 0.43, 0.40, 0.43, 0.44, 0.48, 0.38, 0.44, 0.44, 0.45, 0.46, 0.52, 0.42, 0.41, 0.45, 0.41, 0.55, 0.39, 0.47, 0.51, 0.45, 0.36, 0.50, 0.36, 0.46, 0.40, 0.46, 0.42, 0.45, 0.44, 0.45, 0.42, 0.42, 0.42, 0.44, 0.41, 0.41, 0.53, 0.43, 0.38


Running iteration 5 of 10 fold...
[10, 0, 48, 21, 45, 46, 13, 18, 23, 27]
using cpu
using cpu
    accuracy, precision, recall, f_score
mdl: 0.455782, 0.452376, 0.448527, 0.441308

    accuracy, precision, recall, f_score
max: 0.498489, 0.492240, 0.477361, 0.477232

    accuracy, precision, recall, f_score
max: 0.482993, 0.484952, 0.478124, 0.471240


min loss: 0.005, episode: 218000
max accu: 0.498, episode: 320000

14.64 classifiers used
    accuracy, precision, recall, f_score
mv: 0.462585, 0.460946, 0.460216, 0.447069
wv: 0.462585, 0.458491, 0.460216, 0.447180
fs: 0.523810, 0.524751, 0.519758, 0.507960
rl: 0.482993, 0.484952, 0.478124, 0.471240

0.44736048265460027
0.42, 0.44, 0.45, 0.42, 0.45, 0.42, 0.46, 0.43, 0.44, 0.42, 0.50, 0.44, 0.43, 0.46, 0.40, 0.41, 0.46, 0.45, 0.45, 0.44, 0.45, 0.44, 0.45, 0.41, 0.45, 0.43, 0.44, 0.45, 0.45, 0.45, 0.41, 0.44, 0.45, 0.41, 0.41, 0.43, 0.45, 0.46, 0.47, 0.44, 0.45, 0.48, 0.46, 0.47, 0.42, 0.46, 0.44, 0.45, 0.44, 0.48

0.45522658610271904
0.43, 0.41, 0.44, 0.44, 0.44, 0.39, 0.46, 0.45, 0.45, 0.42, 0.53, 0.42, 0.45, 0.47, 0.44, 0.45, 0.41, 0.46, 0.46, 0.46, 0.43, 0.45, 0.43, 0.40, 0.45, 0.44, 0.47, 0.46, 0.45, 0.46, 0.43, 0.45, 0.46, 0.42, 0.43, 0.46, 0.45, 0.48, 0.50, 0.42, 0.48, 0.51, 0.46, 0.48, 0.44, 0.48, 0.42, 0.50, 0.47, 0.47

0.4461224489795918
0.46, 0.42, 0.44, 0.39, 0.43, 0.40, 0.42, 0.40, 0.54, 0.41, 0.44, 0.46, 0.44, 0.51, 0.43, 0.42, 0.48, 0.40, 0.46, 0.41, 0.47, 0.44, 0.36, 0.43, 0.41, 0.45, 0.45, 0.49, 0.42, 0.51, 0.43, 0.48, 0.40, 0.37, 0.46, 0.50, 0.49, 0.46, 0.46, 0.36, 0.47, 0.40, 0.42, 0.51, 0.39, 0.49, 0.45, 0.42, 0.38, 0.53

0.43306122448979595
0.42, 0.41, 0.39, 0.37, 0.41, 0.48, 0.48, 0.41, 0.46, 0.37, 0.37, 0.40, 0.46, 0.38, 0.47, 0.44, 0.44, 0.48, 0.43, 0.48, 0.40, 0.40, 0.42, 0.46, 0.46, 0.42, 0.47, 0.37, 0.37, 0.48, 0.46, 0.45, 0.44, 0.38, 0.42, 0.38, 0.51, 0.44, 0.40, 0.44, 0.43, 0.45, 0.36, 0.46, 0.46, 0.44, 0.42, 0.44, 0.44, 0.39


Running iteration 6 of 10 fold...
[5, 0, 18, 10, 41, 28, 2]
using cpu
using cpu
    accuracy, precision, recall, f_score
mdl: 0.523810, 0.518915, 0.498633, 0.498652

    accuracy, precision, recall, f_score
max: 0.519637, 0.507346, 0.483477, 0.482776

    accuracy, precision, recall, f_score
max: 0.530612, 0.513629, 0.500491, 0.488052


min loss: 0.006, episode: 200000
max accu: 0.520, episode: 300000

35.24 classifiers used
    accuracy, precision, recall, f_score
mv: 0.530612, 0.532308, 0.524847, 0.516461
wv: 0.530612, 0.527612, 0.516729, 0.508605
fs: 0.428571, 0.413238, 0.400989, 0.382694
rl: 0.530612, 0.513629, 0.500491, 0.488052

0.4527903469079939
0.46, 0.45, 0.44, 0.47, 0.43, 0.49, 0.44, 0.45, 0.41, 0.46, 0.48, 0.47, 0.41, 0.41, 0.46, 0.46, 0.43, 0.45, 0.47, 0.45, 0.46, 0.43, 0.49, 0.43, 0.43, 0.42, 0.42, 0.46, 0.43, 0.44, 0.45, 0.44, 0.45, 0.45, 0.42, 0.46, 0.45, 0.46, 0.45, 0.44, 0.45, 0.47, 0.45, 0.46, 0.45, 0.46, 0.44, 0.44, 0.47, 0.44

0.45039274924471295
0.42, 0.42, 0.40, 0.45, 0.42, 0.49, 0.42, 0.47, 0.42, 0.48, 0.48, 0.45, 0.40, 0.42, 0.46, 0.49, 0.42, 0.48, 0.45, 0.45, 0.44, 0.40, 0.49, 0.42, 0.39, 0.40, 0.42, 0.45, 0.42, 0.45, 0.45, 0.44, 0.42, 0.49, 0.44, 0.47, 0.43, 0.47, 0.45, 0.47, 0.46, 0.49, 0.42, 0.48, 0.46, 0.48, 0.41, 0.46, 0.46, 0.44

0.4474829931972789
0.40, 0.40, 0.41, 0.44, 0.48, 0.44, 0.46, 0.46, 0.42, 0.40, 0.48, 0.39, 0.43, 0.52, 0.52, 0.40, 0.45, 0.48, 0.46, 0.44, 0.44, 0.46, 0.44, 0.48, 0.38, 0.39, 0.40, 0.37, 0.36, 0.46, 0.48, 0.40, 0.46, 0.49, 0.41, 0.39, 0.50, 0.48, 0.48, 0.46, 0.50, 0.42, 0.50, 0.45, 0.44, 0.49, 0.44, 0.40, 0.41, 0.44

0.4699319727891156
0.43, 0.44, 0.47, 0.47, 0.46, 0.46, 0.46, 0.48, 0.48, 0.49, 0.48, 0.47, 0.47, 0.43, 0.46, 0.53, 0.48, 0.50, 0.44, 0.57, 0.42, 0.49, 0.42, 0.47, 0.46, 0.47, 0.46, 0.42, 0.42, 0.44, 0.47, 0.48, 0.42, 0.46, 0.48, 0.46, 0.44, 0.46, 0.48, 0.46, 0.50, 0.47, 0.49, 0.45, 0.44, 0.37, 0.46, 0.52, 0.48, 0.50


Running iteration 7 of 10 fold...
[12, 0, 24, 44, 21]
using cpu
using cpu
    accuracy, precision, recall, f_score
mdl: 0.408163, 0.432678, 0.385397, 0.379160

    accuracy, precision, recall, f_score
max: 0.507553, 0.498664, 0.475254, 0.474632

    accuracy, precision, recall, f_score
max: 0.469388, 0.478591, 0.426984, 0.417763


min loss: 0.007, episode: 210000
max accu: 0.508, episode: 300000

28.64 classifiers used
    accuracy, precision, recall, f_score
mv: 0.503401, 0.511690, 0.459048, 0.454788
wv: 0.496599, 0.511670, 0.461270, 0.456226
fs: 0.476190, 0.498010, 0.454603, 0.446579
rl: 0.469388, 0.478591, 0.426984, 0.417763

0.4535143288084464
0.42, 0.46, 0.47, 0.46, 0.46, 0.43, 0.44, 0.49, 0.47, 0.43, 0.43, 0.47, 0.49, 0.44, 0.44, 0.43, 0.43, 0.44, 0.45, 0.45, 0.45, 0.47, 0.46, 0.45, 0.49, 0.45, 0.42, 0.46, 0.43, 0.45, 0.45, 0.44, 0.48, 0.43, 0.43, 0.44, 0.41, 0.45, 0.43, 0.44, 0.46, 0.46, 0.48, 0.47, 0.45, 0.43, 0.46, 0.43, 0.44, 0.42

0.450392749244713
0.42, 0.45, 0.46, 0.46, 0.42, 0.44, 0.44, 0.50, 0.49, 0.43, 0.45, 0.49, 0.49, 0.44, 0.43, 0.41, 0.42, 0.42, 0.42, 0.43, 0.48, 0.47, 0.44, 0.45, 0.47, 0.42, 0.41, 0.45, 0.41, 0.45, 0.44, 0.45, 0.48, 0.43, 0.46, 0.43, 0.43, 0.43, 0.44, 0.43, 0.47, 0.47, 0.50, 0.48, 0.46, 0.42, 0.45, 0.40, 0.40, 0.41

0.42435374149659866
0.44, 0.43, 0.49, 0.39, 0.31, 0.42, 0.44, 0.40, 0.44, 0.38, 0.40, 0.44, 0.45, 0.44, 0.45, 0.42, 0.48, 0.37, 0.40, 0.42, 0.40, 0.48, 0.42, 0.44, 0.44, 0.43, 0.40, 0.38, 0.38, 0.38, 0.40, 0.43, 0.48, 0.38, 0.37, 0.44, 0.38, 0.51, 0.41, 0.37, 0.44, 0.46, 0.41, 0.38, 0.42, 0.43, 0.42, 0.43, 0.43, 0.42

0.45687074829931973
0.46, 0.49, 0.44, 0.48, 0.48, 0.41, 0.46, 0.49, 0.48, 0.48, 0.46, 0.40, 0.44, 0.34, 0.46, 0.51, 0.46, 0.41, 0.44, 0.40, 0.46, 0.44, 0.48, 0.42, 0.50, 0.41, 0.47, 0.55, 0.44, 0.39, 0.46, 0.44, 0.45, 0.44, 0.44, 0.48, 0.48, 0.43, 0.44, 0.46, 0.42, 0.47, 0.48, 0.42, 0.49, 0.40, 0.44, 0.46, 0.45, 0.44


Running iteration 8 of 10 fold...
[8, 0, 17, 27, 20, 40]
using cpu
using cpu
    accuracy, precision, recall, f_score
mdl: 0.387755, 0.411394, 0.361372, 0.356928

    accuracy, precision, recall, f_score
max: 0.534743, 0.529282, 0.511420, 0.513177

    accuracy, precision, recall, f_score
max: 0.510204, 0.499861, 0.448328, 0.448816


min loss: 0.006, episode: 223000
max accu: 0.535, episode: 300000

28.79 classifiers used
    accuracy, precision, recall, f_score
mv: 0.482993, 0.491719, 0.438224, 0.438039
wv: 0.482993, 0.491246, 0.438224, 0.438367
fs: 0.482993, 0.479875, 0.436519, 0.437121
rl: 0.510204, 0.499861, 0.448328, 0.448816

0.45740573152337854
0.43, 0.45, 0.46, 0.42, 0.47, 0.45, 0.45, 0.47, 0.50, 0.43, 0.44, 0.47, 0.45, 0.44, 0.43, 0.45, 0.47, 0.49, 0.46, 0.42, 0.48, 0.49, 0.44, 0.43, 0.45, 0.48, 0.45, 0.46, 0.45, 0.41, 0.45, 0.43, 0.45, 0.45, 0.47, 0.44, 0.42, 0.43, 0.48, 0.43, 0.48, 0.42, 0.47, 0.45, 0.44, 0.46, 0.46, 0.47, 0.47, 0.46

0.4590936555891238
0.43, 0.49, 0.42, 0.42, 0.49, 0.46, 0.48, 0.49, 0.53, 0.44, 0.44, 0.47, 0.47, 0.41, 0.44, 0.48, 0.47, 0.49, 0.44, 0.44, 0.50, 0.49, 0.40, 0.46, 0.46, 0.48, 0.45, 0.45, 0.44, 0.43, 0.43, 0.41, 0.47, 0.47, 0.45, 0.43, 0.42, 0.39, 0.49, 0.42, 0.44, 0.44, 0.48, 0.43, 0.41, 0.46, 0.50, 0.47, 0.45, 0.44

0.44693877551020406
0.34, 0.46, 0.41, 0.34, 0.50, 0.44, 0.55, 0.43, 0.46, 0.44, 0.39, 0.38, 0.40, 0.51, 0.44, 0.46, 0.45, 0.45, 0.44, 0.40, 0.45, 0.40, 0.44, 0.47, 0.39, 0.44, 0.42, 0.46, 0.46, 0.43, 0.44, 0.44, 0.44, 0.46, 0.47, 0.43, 0.47, 0.44, 0.49, 0.42, 0.52, 0.42, 0.48, 0.44, 0.42, 0.47, 0.49, 0.47, 0.44, 0.40

0.45714285714285713
0.40, 0.44, 0.47, 0.47, 0.49, 0.48, 0.49, 0.42, 0.45, 0.42, 0.52, 0.42, 0.44, 0.50, 0.46, 0.40, 0.51, 0.45, 0.46, 0.45, 0.42, 0.48, 0.48, 0.45, 0.48, 0.47, 0.45, 0.44, 0.55, 0.42, 0.44, 0.45, 0.39, 0.40, 0.38, 0.46, 0.42, 0.43, 0.42, 0.38, 0.44, 0.44, 0.48, 0.53, 0.46, 0.47, 0.48, 0.44, 0.44, 0.46


Running iteration 9 of 10 fold...
[8, 0, 10, 34, 35, 44, 36, 1]
using cpu
using cpu
    accuracy, precision, recall, f_score
mdl: 0.442177, 0.431911, 0.422176, 0.418011

    accuracy, precision, recall, f_score
max: 0.543807, 0.534455, 0.505829, 0.505052

    accuracy, precision, recall, f_score
max: 0.482993, 0.472461, 0.465338, 0.459065


min loss: 0.007, episode: 180000
max accu: 0.544, episode: 250000

46.77 classifiers used
    accuracy, precision, recall, f_score
mv: 0.448980, 0.431911, 0.432083, 0.423700
wv: 0.462585, 0.445547, 0.444324, 0.435864
fs: 0.455782, 0.451886, 0.442202, 0.442314
rl: 0.482993, 0.472461, 0.465338, 0.459065

0.4652187028657616
0.45, 0.48, 0.47, 0.49, 0.46, 0.43, 0.46, 0.48, 0.50, 0.46, 0.49, 0.44, 0.45, 0.43, 0.47, 0.46, 0.47, 0.45, 0.44, 0.47, 0.46, 0.46, 0.48, 0.45, 0.47, 0.44, 0.44, 0.47, 0.46, 0.43, 0.48, 0.49, 0.40, 0.45, 0.49, 0.47, 0.47, 0.44, 0.45, 0.47, 0.46, 0.44, 0.48, 0.47, 0.48, 0.46, 0.45, 0.45, 0.45, 0.49

0.46700906344410875
0.44, 0.50, 0.45, 0.47, 0.46, 0.43, 0.46, 0.51, 0.54, 0.48, 0.48, 0.45, 0.42, 0.45, 0.48, 0.45, 0.45, 0.44, 0.45, 0.46, 0.47, 0.47, 0.48, 0.47, 0.48, 0.43, 0.44, 0.45, 0.48, 0.40, 0.48, 0.48, 0.41, 0.45, 0.48, 0.47, 0.47, 0.44, 0.44, 0.49, 0.50, 0.41, 0.50, 0.45, 0.48, 0.44, 0.46, 0.45, 0.47, 0.50

0.4180952380952381
0.42, 0.45, 0.47, 0.37, 0.44, 0.41, 0.44, 0.39, 0.42, 0.40, 0.38, 0.42, 0.36, 0.40, 0.39, 0.39, 0.41, 0.39, 0.42, 0.42, 0.44, 0.44, 0.44, 0.43, 0.39, 0.36, 0.33, 0.41, 0.40, 0.38, 0.35, 0.44, 0.41, 0.39, 0.44, 0.44, 0.44, 0.39, 0.46, 0.42, 0.46, 0.42, 0.40, 0.47, 0.42, 0.46, 0.39, 0.43, 0.38, 0.42

0.43183673469387757
0.44, 0.43, 0.43, 0.40, 0.46, 0.44, 0.38, 0.46, 0.42, 0.39, 0.44, 0.38, 0.41, 0.39, 0.39, 0.41, 0.47, 0.47, 0.40, 0.42, 0.46, 0.40, 0.36, 0.42, 0.44, 0.44, 0.44, 0.46, 0.44, 0.40, 0.43, 0.43, 0.41, 0.39, 0.42, 0.36, 0.47, 0.47, 0.36, 0.45, 0.47, 0.44, 0.45, 0.47, 0.46, 0.44, 0.46, 0.42, 0.34, 0.49


Running iteration 10 of 10 fold...
[49, 0, 8, 3, 11, 14, 46]
using cpu
using cpu
    accuracy, precision, recall, f_score
mdl: 0.448980, 0.452031, 0.442308, 0.446205

    accuracy, precision, recall, f_score
max: 0.504532, 0.494792, 0.474030, 0.471106

    accuracy, precision, recall, f_score
max: 0.544218, 0.545302, 0.528846, 0.533504


min loss: 0.007, episode: 190000
max accu: 0.505, episode: 280000

39.59 classifiers used
    accuracy, precision, recall, f_score
mv: 0.605442, 0.605523, 0.599359, 0.601802
wv: 0.612245, 0.612002, 0.604915, 0.607222
fs: 0.517007, 0.513508, 0.503846, 0.505182
rl: 0.544218, 0.545302, 0.528846, 0.533504

0.4573755656108597
0.47, 0.46, 0.47, 0.48, 0.45, 0.46, 0.46, 0.45, 0.46, 0.46, 0.42, 0.44, 0.45, 0.46, 0.47, 0.42, 0.44, 0.47, 0.45, 0.41, 0.45, 0.48, 0.43, 0.43, 0.46, 0.44, 0.44, 0.47, 0.47, 0.44, 0.44, 0.45, 0.47, 0.47, 0.44, 0.45, 0.45, 0.46, 0.44, 0.46, 0.44, 0.45, 0.48, 0.42, 0.46, 0.47, 0.46, 0.45, 0.44, 0.48

0.44308157099697887
0.45, 0.46, 0.46, 0.46, 0.45, 0.45, 0.47, 0.44, 0.44, 0.43, 0.40, 0.42, 0.45, 0.45, 0.47, 0.41, 0.43, 0.49, 0.41, 0.40, 0.43, 0.46, 0.41, 0.41, 0.43, 0.45, 0.41, 0.45, 0.43, 0.45, 0.44, 0.45, 0.47, 0.45, 0.43, 0.45, 0.42, 0.41, 0.43, 0.41, 0.45, 0.45, 0.47, 0.41, 0.43, 0.44, 0.42, 0.41, 0.42, 0.48

0.45700680272108846
0.44, 0.40, 0.47, 0.46, 0.45, 0.50, 0.48, 0.40, 0.45, 0.43, 0.46, 0.46, 0.42, 0.42, 0.43, 0.47, 0.47, 0.44, 0.49, 0.43, 0.43, 0.51, 0.42, 0.38, 0.45, 0.44, 0.48, 0.46, 0.44, 0.43, 0.46, 0.44, 0.51, 0.44, 0.46, 0.47, 0.43, 0.40, 0.40, 0.47, 0.51, 0.52, 0.47, 0.46, 0.51, 0.44, 0.46, 0.42, 0.43, 0.48

0.4948299319727891
0.54, 0.47, 0.46, 0.49, 0.52, 0.44, 0.48, 0.48, 0.48, 0.54, 0.48, 0.51, 0.46, 0.40, 0.46, 0.53, 0.55, 0.45, 0.50, 0.53, 0.50, 0.45, 0.45, 0.54, 0.53, 0.45, 0.53, 0.47, 0.48, 0.46, 0.49, 0.48, 0.48, 0.51, 0.51, 0.48, 0.50, 0.49, 0.48, 0.49, 0.50, 0.53, 0.47, 0.49, 0.49, 0.46, 0.46, 0.55, 0.48, 0.53

    accuracy, precision, recall, f_score
mv: 0.511173, 0.515776, 0.485744, 0.480443
wv: 0.513210, 0.517699, 0.486909, 0.481964
fs: 0.491478, 0.494431, 0.465604, 0.460263
rl: 0.513863, 0.512157, 0.480370, 0.477271

fs avg size: 7.50000, rl avg size: 30.69300
full test avg accu: 0.45872, test avg accu: 0.44737

training takes 32416.634 sec
