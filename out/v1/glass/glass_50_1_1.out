{'dataset': 'glass', 'algorithm': 'ptdqn', 'num_clf': 50, 'num_training': 350000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 9781, 'portion': 0.5, 'sequential': False}
(214, 10)
reading data takes 0.011 sec
number of labels: 6

Running iteration 1 of 10 fold...
[27, 0, 49, 2, 3, 40, 1, 5, 6, 8]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.625000, 0.661791, 0.512645, 0.493284

    accuracy, precision, recall, f_score
max3: 0.666667, 0.697618, 0.610946, 0.608325

    accuracy, precision, recall, f_score
max1: 0.772727, 0.700758, 0.461039, 0.444928


min loss: 0.005, episode: 270000
max accu: 0.773, episode: 180000

1.05 classifiers used
    accuracy, precision, recall, f_score
mv: 0.818182, 0.746212, 0.627706, 0.611594
wv: 0.727273, 0.628934, 0.437229, 0.416667
fs: 0.772727, 0.747934, 0.469697, 0.446296
rl: 0.772727, 0.700758, 0.461039, 0.444928

0.5883333333333334
0.5, 0.63, 0.60, 0.65, 0.56, 0.60, 0.47, 0.55, 0.54, 0.61, 0.60, 0.56, 0.56, 0.61, 0.56, 0.62, 0.54, 0.54, 0.61, 0.58, 0.67, 0.64, 0.57, 0.58, 0.64, 0.61, 0.55, 0.68, 0.51, 0.55, 0.64, 0.5, 0.58, 0.62, 0.46, 0.66, 0.67, 0.52, 0.47, 0.62, 0.54, 0.58, 0.58, 0.66, 0.64, 0.47, 0.65, 0.61, 0.62, 0.62

0.6179166666666667
0.52, 0.62, 0.60, 0.64, 0.58, 0.66, 0.52, 0.47, 0.60, 0.60, 0.66, 0.58, 0.62, 0.66, 0.60, 0.64, 0.56, 0.58, 0.66, 0.64, 0.68, 0.66, 0.60, 0.60, 0.62, 0.70, 0.58, 0.68, 0.54, 0.58, 0.66, 0.58, 0.52, 0.64, 0.45, 0.64, 0.66, 0.58, 0.54, 0.56, 0.58, 0.64, 0.60, 0.72, 0.70, 0.58, 0.72, 0.70, 0.64, 0.68

0.5718181818181818
0.40, 0.59, 0.59, 0.45, 0.59, 0.63, 0.54, 0.45, 0.54, 0.54, 0.63, 0.59, 0.63, 0.54, 0.54, 0.54, 0.68, 0.45, 0.72, 0.5, 0.68, 0.54, 0.68, 0.54, 0.68, 0.5, 0.54, 0.5, 0.54, 0.54, 0.63, 0.54, 0.40, 0.72, 0.5, 0.36, 0.68, 0.68, 0.5, 0.59, 0.68, 0.54, 0.59, 0.68, 0.54, 0.45, 0.86, 0.59, 0.45, 0.54

0.6054545454545454
0.59, 0.72, 0.59, 0.40, 0.54, 0.59, 0.40, 0.59, 0.45, 0.59, 0.54, 0.59, 0.45, 0.59, 0.63, 0.59, 0.45, 0.5, 0.59, 0.77, 0.77, 0.72, 0.5, 0.72, 0.81, 0.72, 0.5, 0.54, 0.63, 0.54, 0.63, 0.59, 0.63, 0.54, 0.54, 0.63, 0.63, 0.72, 0.72, 0.54, 0.72, 0.63, 0.63, 0.54, 0.68, 0.68, 0.63, 0.59, 0.63, 0.54


Running iteration 2 of 10 fold...
[49, 0, 37, 3, 42, 14, 44]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.677083, 0.730382, 0.643841, 0.618485

    accuracy, precision, recall, f_score
max3: 0.708333, 0.771724, 0.645655, 0.631000

    accuracy, precision, recall, f_score
max1: 0.863636, 0.912338, 0.883333, 0.842593


min loss: 0.006, episode: 252000
max accu: 0.864, episode: 200000

6.91 classifiers used
    accuracy, precision, recall, f_score
mv: 0.772727, 0.823052, 0.833333, 0.796296
wv: 0.772727, 0.823052, 0.833333, 0.796296
fs: 0.772727, 0.674242, 0.616667, 0.590909
rl: 0.863636, 0.912338, 0.883333, 0.842593

0.585
0.66, 0.62, 0.63, 0.60, 0.61, 0.57, 0.54, 0.56, 0.58, 0.52, 0.53, 0.59, 0.65, 0.58, 0.64, 0.57, 0.54, 0.58, 0.57, 0.56, 0.54, 0.55, 0.56, 0.57, 0.58, 0.60, 0.61, 0.51, 0.64, 0.57, 0.54, 0.56, 0.37, 0.56, 0.61, 0.54, 0.61, 0.63, 0.62, 0.63, 0.55, 0.48, 0.62, 0.59, 0.59, 0.61, 0.60, 0.61, 0.63, 0.68

0.6020833333333333
0.66, 0.58, 0.66, 0.62, 0.60, 0.58, 0.62, 0.72, 0.60, 0.56, 0.54, 0.54, 0.68, 0.58, 0.62, 0.56, 0.54, 0.62, 0.62, 0.58, 0.54, 0.58, 0.62, 0.58, 0.58, 0.58, 0.64, 0.45, 0.70, 0.58, 0.58, 0.54, 0.43, 0.54, 0.62, 0.58, 0.58, 0.66, 0.68, 0.68, 0.56, 0.54, 0.64, 0.64, 0.58, 0.62, 0.62, 0.56, 0.58, 0.72

0.6100000000000001
0.68, 0.72, 0.68, 0.72, 0.45, 0.72, 0.68, 0.36, 0.5, 0.63, 0.68, 0.5, 0.63, 0.72, 0.59, 0.77, 0.45, 0.54, 0.54, 0.68, 0.5, 0.54, 0.63, 0.54, 0.63, 0.63, 0.59, 0.72, 0.59, 0.63, 0.63, 0.68, 0.40, 0.40, 0.68, 0.5, 0.72, 0.68, 0.54, 0.59, 0.5, 0.54, 0.63, 0.68, 0.72, 0.63, 0.59, 0.54, 0.63, 0.77

0.64
0.54, 0.77, 0.77, 0.68, 0.54, 0.68, 0.72, 0.63, 0.63, 0.54, 0.63, 0.68, 0.68, 0.68, 0.54, 0.54, 0.72, 0.59, 0.63, 0.68, 0.77, 0.86, 0.77, 0.63, 0.77, 0.59, 0.5, 0.45, 0.54, 0.63, 0.81, 0.59, 0.40, 0.63, 0.59, 0.63, 0.68, 0.63, 0.77, 0.72, 0.59, 0.63, 0.54, 0.59, 0.45, 0.63, 0.59, 0.68, 0.59, 0.68


Running iteration 3 of 10 fold...
[28, 0, 23, 14]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.739583, 0.692434, 0.642006, 0.616436

    accuracy, precision, recall, f_score
max3: 0.750000, 0.708243, 0.625000, 0.596261

    accuracy, precision, recall, f_score
max1: 0.909091, 0.882576, 0.805556, 0.777602


min loss: 0.010, episode: 253000
max accu: 0.909, episode: 330000

27.14 classifiers used
    accuracy, precision, recall, f_score
mv: 0.863636, 0.863636, 0.803030, 0.737302
wv: 0.863636, 0.863636, 0.803030, 0.737302
fs: 0.772727, 0.741259, 0.527778, 0.541667
rl: 0.909091, 0.882576, 0.805556, 0.777602

0.5808333333333333
0.52, 0.61, 0.55, 0.58, 0.5, 0.51, 0.59, 0.58, 0.65, 0.48, 0.58, 0.5, 0.61, 0.52, 0.59, 0.62, 0.63, 0.5, 0.58, 0.41, 0.61, 0.52, 0.65, 0.66, 0.63, 0.52, 0.59, 0.51, 0.70, 0.57, 0.54, 0.62, 0.60, 0.58, 0.66, 0.66, 0.63, 0.59, 0.52, 0.65, 0.65, 0.54, 0.58, 0.64, 0.61, 0.55, 0.53, 0.62, 0.5, 0.52

0.5975
0.54, 0.64, 0.52, 0.60, 0.56, 0.45, 0.60, 0.60, 0.64, 0.58, 0.62, 0.47, 0.56, 0.58, 0.68, 0.60, 0.62, 0.54, 0.66, 0.37, 0.56, 0.62, 0.66, 0.68, 0.66, 0.62, 0.60, 0.56, 0.68, 0.58, 0.54, 0.60, 0.62, 0.56, 0.64, 0.68, 0.64, 0.56, 0.56, 0.64, 0.66, 0.56, 0.56, 0.62, 0.68, 0.54, 0.60, 0.64, 0.54, 0.56

0.6599999999999998
0.72, 0.68, 0.59, 0.77, 0.72, 0.77, 0.68, 0.77, 0.77, 0.54, 0.63, 0.5, 0.72, 0.72, 0.63, 0.59, 0.72, 0.5, 0.5, 0.45, 0.63, 0.68, 0.81, 0.77, 0.54, 0.59, 0.77, 0.59, 0.68, 0.63, 0.54, 0.68, 0.68, 0.45, 0.72, 0.59, 0.72, 0.77, 0.77, 0.72, 0.90, 0.77, 0.59, 0.68, 0.5, 0.5, 0.68, 0.59, 0.68, 0.63

0.6772727272727274
0.63, 0.77, 0.63, 0.45, 0.5, 0.72, 0.68, 0.72, 0.77, 0.68, 0.63, 0.81, 0.63, 0.63, 0.81, 0.81, 0.59, 0.72, 0.54, 0.63, 0.77, 0.81, 0.68, 0.54, 0.68, 0.40, 0.77, 0.59, 0.72, 0.72, 0.63, 0.95, 0.68, 0.77, 0.59, 0.77, 0.72, 0.5, 0.68, 0.63, 0.72, 0.81, 0.72, 0.63, 0.54, 0.59, 0.72, 0.77, 0.59, 0.59


Running iteration 4 of 10 fold...
[36, 0, 21, 41, 34]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.635417, 0.581896, 0.531790, 0.486793

    accuracy, precision, recall, f_score
max3: 0.604167, 0.556630, 0.472002, 0.446360

    accuracy, precision, recall, f_score
max1: 0.681818, 0.592424, 0.439815, 0.369109


min loss: 0.005, episode: 238000
max accu: 0.682, episode: 190000

10.77 classifiers used
    accuracy, precision, recall, f_score
mv: 0.818182, 0.901515, 0.856481, 0.763228
wv: 0.818182, 0.901515, 0.856481, 0.763228
fs: 0.636364, 0.619697, 0.483796, 0.421418
rl: 0.681818, 0.592424, 0.439815, 0.369109

0.5508333333333334
0.53, 0.60, 0.52, 0.61, 0.51, 0.60, 0.42, 0.48, 0.55, 0.56, 0.58, 0.58, 0.44, 0.61, 0.53, 0.56, 0.58, 0.55, 0.58, 0.54, 0.44, 0.58, 0.58, 0.53, 0.5, 0.58, 0.53, 0.54, 0.57, 0.48, 0.57, 0.52, 0.54, 0.55, 0.58, 0.5, 0.64, 0.55, 0.59, 0.56, 0.42, 0.56, 0.57, 0.53, 0.53, 0.58, 0.61, 0.60, 0.51, 0.61

0.53875
0.58, 0.52, 0.52, 0.56, 0.47, 0.56, 0.37, 0.43, 0.47, 0.56, 0.5, 0.58, 0.45, 0.62, 0.5, 0.54, 0.56, 0.54, 0.56, 0.56, 0.47, 0.60, 0.58, 0.58, 0.54, 0.56, 0.52, 0.54, 0.58, 0.54, 0.58, 0.5, 0.56, 0.52, 0.58, 0.43, 0.64, 0.56, 0.62, 0.58, 0.43, 0.5, 0.58, 0.5, 0.54, 0.60, 0.54, 0.56, 0.45, 0.54

0.510909090909091
0.63, 0.72, 0.45, 0.40, 0.45, 0.45, 0.54, 0.45, 0.68, 0.45, 0.45, 0.45, 0.5, 0.68, 0.45, 0.40, 0.5, 0.36, 0.5, 0.68, 0.45, 0.59, 0.45, 0.45, 0.45, 0.5, 0.31, 0.68, 0.5, 0.36, 0.54, 0.54, 0.54, 0.5, 0.59, 0.40, 0.54, 0.45, 0.40, 0.54, 0.59, 0.5, 0.59, 0.5, 0.59, 0.45, 0.68, 0.45, 0.5, 0.54

0.6063636363636363
0.59, 0.72, 0.63, 0.59, 0.45, 0.59, 0.63, 0.68, 0.59, 0.59, 0.5, 0.45, 0.63, 0.63, 0.63, 0.63, 0.5, 0.63, 0.63, 0.59, 0.63, 0.59, 0.54, 0.54, 0.63, 0.68, 0.63, 0.5, 0.59, 0.63, 0.72, 0.63, 0.5, 0.54, 0.59, 0.54, 0.5, 0.63, 0.59, 0.59, 0.72, 0.72, 0.45, 0.72, 0.59, 0.68, 0.72, 0.63, 0.59, 0.63


Running iteration 5 of 10 fold...
[3, 0, 31, 16, 25, 14, 19, 35]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.639175, 0.669055, 0.616244, 0.623368

    accuracy, precision, recall, f_score
max3: 0.591837, 0.606061, 0.499013, 0.487821

    accuracy, precision, recall, f_score
max1: 0.761905, 0.707483, 0.569444, 0.544444


min loss: 0.006, episode: 263000
max accu: 0.762, episode: 200000

2.19 classifiers used
    accuracy, precision, recall, f_score
mv: 0.761905, 0.786092, 0.645833, 0.676571
wv: 0.761905, 0.786092, 0.645833, 0.676571
fs: 0.666667, 0.748677, 0.451389, 0.476937
rl: 0.761905, 0.707483, 0.569444, 0.544444

0.5800000000000001
0.58, 0.61, 0.56, 0.70, 0.62, 0.54, 0.48, 0.55, 0.58, 0.57, 0.61, 0.62, 0.56, 0.52, 0.56, 0.50, 0.61, 0.53, 0.63, 0.67, 0.47, 0.48, 0.57, 0.55, 0.54, 0.67, 0.58, 0.59, 0.55, 0.51, 0.59, 0.67, 0.59, 0.52, 0.61, 0.61, 0.56, 0.59, 0.57, 0.56, 0.59, 0.58, 0.58, 0.61, 0.50, 0.54, 0.52, 0.62, 0.58, 0.57

0.5518367346938775
0.59, 0.59, 0.53, 0.67, 0.59, 0.53, 0.44, 0.61, 0.55, 0.53, 0.57, 0.59, 0.51, 0.44, 0.57, 0.48, 0.57, 0.44, 0.65, 0.67, 0.48, 0.36, 0.61, 0.59, 0.51, 0.63, 0.59, 0.53, 0.51, 0.51, 0.59, 0.69, 0.59, 0.55, 0.59, 0.59, 0.57, 0.53, 0.55, 0.55, 0.55, 0.53, 0.57, 0.53, 0.57, 0.44, 0.44, 0.55, 0.53, 0.51

0.5923809523809525
0.76, 0.61, 0.47, 0.57, 0.61, 0.57, 0.42, 0.71, 0.52, 0.61, 0.52, 0.61, 0.57, 0.42, 0.61, 0.71, 0.76, 0.61, 0.66, 0.47, 0.52, 0.66, 0.61, 0.52, 0.57, 0.61, 0.66, 0.71, 0.61, 0.47, 0.66, 0.57, 0.66, 0.66, 0.52, 0.61, 0.66, 0.66, 0.66, 0.66, 0.57, 0.57, 0.42, 0.42, 0.57, 0.38, 0.42, 0.71, 0.57, 0.66

0.6371428571428572
0.47, 0.71, 0.85, 0.61, 0.61, 0.61, 0.52, 0.71, 0.57, 0.61, 0.80, 0.61, 0.71, 0.76, 0.52, 0.66, 0.66, 0.61, 0.52, 0.66, 0.76, 0.52, 0.52, 0.76, 0.57, 0.71, 0.42, 0.61, 0.47, 0.76, 0.57, 0.76, 0.52, 0.57, 0.66, 0.76, 0.52, 0.61, 0.85, 0.57, 0.66, 0.61, 0.71, 0.61, 0.66, 0.61, 0.71, 0.52, 0.66, 0.57


Running iteration 6 of 10 fold...
[19, 0, 1, 11, 47, 48, 4]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.670103, 0.722420, 0.669949, 0.660546

    accuracy, precision, recall, f_score
max3: 0.632653, 0.707313, 0.580958, 0.590430

    accuracy, precision, recall, f_score
max1: 0.761905, 0.779762, 0.840741, 0.792810


min loss: 0.005, episode: 258000
max accu: 0.762, episode: 190000

3.95 classifiers used
    accuracy, precision, recall, f_score
mv: 0.761905, 0.801020, 0.833333, 0.784314
wv: 0.761905, 0.801020, 0.833333, 0.784314
fs: 0.619048, 0.539683, 0.562963, 0.464983
rl: 0.761905, 0.779762, 0.840741, 0.792810

0.5779381443298969
0.50, 0.53, 0.61, 0.56, 0.57, 0.60, 0.60, 0.55, 0.51, 0.51, 0.61, 0.64, 0.52, 0.62, 0.61, 0.58, 0.56, 0.45, 0.57, 0.68, 0.55, 0.54, 0.64, 0.58, 0.52, 0.63, 0.47, 0.63, 0.60, 0.57, 0.65, 0.49, 0.62, 0.54, 0.50, 0.56, 0.58, 0.53, 0.51, 0.56, 0.63, 0.59, 0.59, 0.54, 0.54, 0.63, 0.61, 0.56, 0.61, 0.59

0.5461224489795918
0.48, 0.46, 0.55, 0.57, 0.59, 0.57, 0.59, 0.53, 0.51, 0.38, 0.53, 0.61, 0.48, 0.55, 0.59, 0.55, 0.55, 0.44, 0.57, 0.65, 0.46, 0.53, 0.61, 0.55, 0.40, 0.63, 0.46, 0.67, 0.57, 0.57, 0.59, 0.42, 0.59, 0.48, 0.46, 0.57, 0.59, 0.48, 0.55, 0.55, 0.59, 0.59, 0.59, 0.48, 0.55, 0.63, 0.55, 0.51, 0.61, 0.55

0.539047619047619
0.42, 0.71, 0.52, 0.47, 0.47, 0.52, 0.66, 0.61, 0.28, 0.66, 0.76, 0.52, 0.57, 0.38, 0.66, 0.61, 0.47, 0.42, 0.61, 0.57, 0.42, 0.42, 0.33, 0.52, 0.61, 0.61, 0.52, 0.71, 0.57, 0.38, 0.61, 0.57, 0.42, 0.57, 0.38, 0.47, 0.71, 0.47, 0.47, 0.61, 0.47, 0.47, 0.61, 0.47, 0.71, 0.42, 0.57, 0.42, 0.71, 0.57

0.6038095238095239
0.47, 0.52, 0.61, 0.61, 0.61, 0.61, 0.57, 0.71, 0.52, 0.61, 0.61, 0.71, 0.66, 0.57, 0.57, 0.71, 0.71, 0.76, 0.66, 0.71, 0.57, 0.47, 0.52, 0.61, 0.61, 0.52, 0.57, 0.61, 0.47, 0.61, 0.66, 0.71, 0.71, 0.66, 0.47, 0.66, 0.61, 0.61, 0.61, 0.71, 0.57, 0.57, 0.66, 0.52, 0.28, 0.47, 0.57, 0.57, 0.61, 0.61


Running iteration 7 of 10 fold...
[29, 0, 25, 15, 46, 18, 24, 28, 3]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.659794, 0.646937, 0.581576, 0.593902

    accuracy, precision, recall, f_score
max3: 0.571429, 0.596259, 0.429825, 0.438462

    accuracy, precision, recall, f_score
max1: 0.809524, 0.839286, 0.833333, 0.839316


min loss: 0.006, episode: 253000
max accu: 0.810, episode: 10000

8.24 classifiers used
    accuracy, precision, recall, f_score
mv: 0.714286, 0.697279, 0.655556, 0.611111
wv: 0.761905, 0.738095, 0.688889, 0.685897
fs: 0.761905, 0.768707, 0.605556, 0.628205
rl: 0.809524, 0.839286, 0.833333, 0.839316

0.5538144329896908
0.45, 0.62, 0.58, 0.62, 0.58, 0.63, 0.50, 0.59, 0.49, 0.45, 0.51, 0.50, 0.54, 0.57, 0.54, 0.57, 0.47, 0.43, 0.63, 0.56, 0.51, 0.52, 0.53, 0.57, 0.51, 0.60, 0.55, 0.54, 0.56, 0.67, 0.61, 0.54, 0.44, 0.46, 0.51, 0.52, 0.54, 0.61, 0.63, 0.50, 0.55, 0.58, 0.58, 0.50, 0.57, 0.52, 0.61, 0.59, 0.55, 0.57

0.5118367346938776
0.46, 0.55, 0.46, 0.59, 0.57, 0.61, 0.44, 0.51, 0.48, 0.34, 0.53, 0.48, 0.48, 0.57, 0.53, 0.48, 0.36, 0.36, 0.55, 0.55, 0.40, 0.46, 0.48, 0.55, 0.51, 0.61, 0.51, 0.55, 0.53, 0.65, 0.59, 0.57, 0.38, 0.36, 0.44, 0.48, 0.53, 0.59, 0.55, 0.53, 0.53, 0.55, 0.51, 0.48, 0.53, 0.48, 0.57, 0.61, 0.48, 0.46

0.5990476190476192
0.66, 0.57, 0.47, 0.76, 0.71, 0.57, 0.71, 0.61, 0.66, 0.52, 0.61, 0.47, 0.61, 0.66, 0.61, 0.66, 0.61, 0.57, 0.47, 0.71, 0.61, 0.47, 0.52, 0.57, 0.52, 0.76, 0.71, 0.71, 0.66, 0.61, 0.66, 0.52, 0.47, 0.42, 0.57, 0.66, 0.61, 0.47, 0.61, 0.52, 0.57, 0.42, 0.66, 0.52, 0.66, 0.57, 0.52, 0.76, 0.61, 0.52

0.6171428571428572
0.47, 0.57, 0.66, 0.57, 0.57, 0.52, 0.71, 0.66, 0.57, 0.66, 0.61, 0.52, 0.66, 0.71, 0.42, 0.52, 0.52, 0.52, 0.76, 0.52, 0.66, 0.71, 0.71, 0.57, 0.66, 0.71, 0.66, 0.52, 0.66, 0.57, 0.76, 0.57, 0.80, 0.66, 0.66, 0.66, 0.61, 0.57, 0.57, 0.66, 0.61, 0.66, 0.71, 0.66, 0.52, 0.42, 0.61, 0.61, 0.57, 0.57


Running iteration 8 of 10 fold...
[3, 0, 39, 10, 2]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.659794, 0.650078, 0.572937, 0.586752

    accuracy, precision, recall, f_score
max3: 0.632653, 0.607805, 0.495370, 0.494865

    accuracy, precision, recall, f_score
max1: 0.761905, 0.801587, 0.800000, 0.777958


min loss: 0.006, episode: 257000
max accu: 0.762, episode: 210000

10.86 classifiers used
    accuracy, precision, recall, f_score
mv: 0.809524, 0.853741, 0.833333, 0.803968
wv: 0.809524, 0.853741, 0.833333, 0.803968
fs: 0.809524, 0.900227, 0.833333, 0.785714
rl: 0.761905, 0.801587, 0.800000, 0.777958

0.5470103092783505
0.52, 0.48, 0.55, 0.65, 0.52, 0.59, 0.53, 0.58, 0.57, 0.50, 0.61, 0.55, 0.53, 0.59, 0.51, 0.52, 0.46, 0.59, 0.52, 0.53, 0.43, 0.49, 0.63, 0.42, 0.46, 0.46, 0.61, 0.59, 0.55, 0.59, 0.58, 0.54, 0.51, 0.57, 0.50, 0.49, 0.54, 0.57, 0.53, 0.53, 0.56, 0.59, 0.60, 0.55, 0.57, 0.50, 0.61, 0.51, 0.55, 0.50

0.5285714285714286
0.44, 0.57, 0.51, 0.65, 0.46, 0.61, 0.57, 0.55, 0.61, 0.51, 0.59, 0.55, 0.51, 0.55, 0.44, 0.42, 0.46, 0.59, 0.55, 0.53, 0.28, 0.48, 0.59, 0.36, 0.44, 0.48, 0.61, 0.61, 0.61, 0.55, 0.57, 0.51, 0.44, 0.55, 0.48, 0.46, 0.48, 0.46, 0.46, 0.53, 0.63, 0.53, 0.61, 0.57, 0.57, 0.53, 0.57, 0.53, 0.51, 0.57

0.5980952380952381
0.66, 0.52, 0.61, 0.66, 0.42, 0.71, 0.52, 0.61, 0.76, 0.47, 0.76, 0.52, 0.61, 0.61, 0.61, 0.57, 0.52, 0.52, 0.57, 0.66, 0.57, 0.57, 0.76, 0.66, 0.66, 0.57, 0.57, 0.57, 0.66, 0.57, 0.47, 0.71, 0.57, 0.61, 0.47, 0.61, 0.66, 0.57, 0.61, 0.57, 0.42, 0.47, 0.76, 0.61, 0.52, 0.52, 0.76, 0.61, 0.61, 0.47

0.6409523809523808
0.71, 0.66, 0.76, 0.61, 0.52, 0.66, 0.66, 0.61, 0.66, 0.66, 0.52, 0.61, 0.57, 0.52, 0.71, 0.61, 0.66, 0.52, 0.76, 0.47, 0.66, 0.66, 0.66, 0.66, 0.71, 0.61, 0.61, 0.61, 0.61, 0.66, 0.57, 0.66, 0.57, 0.61, 0.61, 0.66, 0.66, 0.66, 0.71, 0.57, 0.76, 0.66, 0.57, 0.52, 0.57, 0.61, 0.76, 0.66, 0.71, 0.76


Running iteration 9 of 10 fold...
[46, 0, 7]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.659794, 0.672662, 0.529726, 0.535534

    accuracy, precision, recall, f_score
max3: 0.591837, 0.558905, 0.421351, 0.412879

    accuracy, precision, recall, f_score
max1: 0.761905, 0.670446, 0.779167, 0.748366


min loss: 0.008, episode: 209000
max accu: 0.762, episode: 190000

5.00 classifiers used
    accuracy, precision, recall, f_score
mv: 0.809524, 0.828571, 0.822222, 0.831481
wv: 0.809524, 0.828571, 0.822222, 0.831481
fs: 0.714286, 0.711111, 0.768056, 0.724074
rl: 0.761905, 0.670446, 0.779167, 0.748366

0.551340206185567
0.57, 0.53, 0.55, 0.56, 0.61, 0.51, 0.44, 0.59, 0.55, 0.56, 0.54, 0.56, 0.51, 0.58, 0.58, 0.43, 0.55, 0.48, 0.62, 0.58, 0.58, 0.52, 0.54, 0.61, 0.48, 0.57, 0.56, 0.60, 0.60, 0.54, 0.51, 0.53, 0.52, 0.56, 0.51, 0.54, 0.56, 0.56, 0.52, 0.54, 0.51, 0.54, 0.51, 0.52, 0.49, 0.52, 0.69, 0.55, 0.55, 0.52

0.5093877551020408
0.53, 0.40, 0.48, 0.59, 0.55, 0.48, 0.36, 0.55, 0.57, 0.53, 0.40, 0.53, 0.46, 0.48, 0.57, 0.51, 0.53, 0.48, 0.61, 0.59, 0.51, 0.48, 0.53, 0.53, 0.42, 0.53, 0.48, 0.59, 0.48, 0.51, 0.48, 0.48, 0.55, 0.53, 0.36, 0.42, 0.55, 0.51, 0.51, 0.46, 0.48, 0.53, 0.53, 0.44, 0.46, 0.44, 0.69, 0.55, 0.51, 0.51

0.6276190476190476
0.52, 0.61, 0.61, 0.76, 0.42, 0.71, 0.52, 0.66, 0.66, 0.66, 0.71, 0.61, 0.61, 0.71, 0.71, 0.57, 0.71, 0.57, 0.57, 0.66, 0.80, 0.57, 0.61, 0.71, 0.61, 0.57, 0.61, 0.61, 0.61, 0.71, 0.47, 0.66, 0.61, 0.71, 0.66, 0.57, 0.61, 0.71, 0.47, 0.61, 0.66, 0.57, 0.42, 0.76, 0.38, 0.66, 0.66, 0.61, 0.80, 0.52

0.7009523809523809
0.66, 0.71, 0.66, 0.85, 0.52, 0.66, 0.42, 0.71, 0.66, 0.57, 0.80, 0.76, 0.76, 0.57, 0.76, 0.80, 0.66, 0.61, 0.76, 0.66, 0.71, 0.71, 0.90, 0.66, 0.71, 0.57, 0.61, 0.71, 0.76, 0.76, 0.71, 0.66, 0.61, 0.66, 0.66, 0.76, 0.76, 0.71, 0.71, 0.66, 0.61, 0.85, 0.76, 0.61, 0.76, 0.71, 0.71, 0.66, 0.90, 0.66


Running iteration 10 of 10 fold...
[43, 0, 2, 16]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.659794, 0.674632, 0.629837, 0.617347

    accuracy, precision, recall, f_score
max3: 0.591837, 0.603304, 0.568791, 0.544706

    accuracy, precision, recall, f_score
max1: 0.809524, 0.819048, 0.630556, 0.641082


min loss: 0.005, episode: 232000
max accu: 0.810, episode: 310000

33.19 classifiers used
    accuracy, precision, recall, f_score
mv: 0.809524, 0.830782, 0.652778, 0.513191
wv: 0.809524, 0.830782, 0.652778, 0.513191
fs: 0.714286, 0.727513, 0.597222, 0.553571
rl: 0.809524, 0.819048, 0.630556, 0.641082

0.5305154639175258
0.62, 0.44, 0.59, 0.53, 0.56, 0.48, 0.45, 0.51, 0.44, 0.64, 0.51, 0.51, 0.48, 0.56, 0.53, 0.55, 0.54, 0.57, 0.53, 0.44, 0.59, 0.54, 0.49, 0.58, 0.47, 0.60, 0.45, 0.57, 0.52, 0.54, 0.47, 0.53, 0.51, 0.47, 0.54, 0.62, 0.51, 0.45, 0.52, 0.57, 0.55, 0.51, 0.50, 0.68, 0.49, 0.42, 0.45, 0.51, 0.56, 0.55

0.49714285714285716
0.59, 0.44, 0.57, 0.48, 0.46, 0.44, 0.40, 0.51, 0.40, 0.59, 0.44, 0.44, 0.46, 0.48, 0.51, 0.51, 0.51, 0.48, 0.44, 0.40, 0.63, 0.51, 0.46, 0.57, 0.46, 0.55, 0.40, 0.55, 0.51, 0.55, 0.42, 0.53, 0.38, 0.40, 0.44, 0.55, 0.51, 0.42, 0.48, 0.48, 0.59, 0.55, 0.44, 0.63, 0.44, 0.46, 0.42, 0.44, 0.59, 0.67

0.5980952380952381
0.80, 0.52, 0.61, 0.66, 0.66, 0.57, 0.66, 0.71, 0.66, 0.52, 0.57, 0.66, 0.52, 0.61, 0.61, 0.57, 0.47, 0.76, 0.80, 0.57, 0.61, 0.71, 0.47, 0.61, 0.47, 0.66, 0.66, 0.57, 0.57, 0.57, 0.52, 0.61, 0.47, 0.66, 0.52, 0.52, 0.38, 0.52, 0.61, 0.76, 0.47, 0.71, 0.61, 0.61, 0.57, 0.61, 0.47, 0.61, 0.52, 0.47

0.6914285714285713
0.52, 0.76, 0.71, 0.66, 0.52, 0.57, 0.71, 0.57, 0.71, 0.71, 0.76, 0.80, 0.80, 0.66, 0.61, 0.61, 0.71, 0.61, 0.66, 0.61, 0.76, 0.85, 0.66, 0.80, 0.71, 0.61, 0.76, 0.80, 0.66, 0.66, 0.66, 0.76, 0.71, 0.85, 0.71, 0.61, 0.76, 0.76, 0.66, 0.71, 0.61, 0.71, 0.71, 0.71, 0.57, 0.71, 0.66, 0.47, 0.76, 0.66

    accuracy, precision, recall, f_score
mv: 0.793939, 1.626380, 1.512721, 0.712906
wv: 0.789611, 1.611088, 1.481293, 0.700892
fs: 0.724026, 1.435810, 1.183291, 0.563378
rl: 0.789394, 1.541141, 1.408597, 0.677821

fs avg size: 12.40000, rl avg size: 21.85844
full test avg accu: 1.28410, test avg accu: 1.18140

training takes 60239.195 sec
