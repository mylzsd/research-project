{'dataset': 'glass', 'algorithm': 'ptdqn', 'num_clf': 100, 'num_training': 350000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 4568, 'portion': 0.5, 'sequential': False}
(214, 10)
reading data takes 0.022 sec
number of labels: 6

Running iteration 1 of 10 fold...
[12, 0, 8, 67]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.6771, 0.6339, 0.6545, 0.6120

    accuracy, precision, recall, f_score
max3: 0.6667, 0.6235, 0.7237, 0.6269

    accuracy, precision, recall, f_score
max1: 0.8636, 0.8252, 0.7833, 0.7760


min loss: 0.005, episode: 247000
max accu: 0.864, episode: 230000

10.82 classifiers used
    accuracy, precision, recall, f_score
mv: 0.6364, 0.6488, 0.7000, 0.6450
wv: 0.6818, 0.6467, 0.6933, 0.6622
fs: 0.6364, 0.6061, 0.6533, 0.6133
rl: 0.8636, 0.8252, 0.7833, 0.7760

0.5590909090909091
0.59, 0.45, 0.5, 0.59, 0.59, 0.40, 0.54, 0.5, 0.59, 0.31, 0.68, 0.59, 0.5, 0.5, 0.59, 0.59, 0.59, 0.63, 0.77, 0.54, 0.68, 0.22, 0.77, 0.54, 0.59, 0.63, 0.77, 0.54, 0.59, 0.54, 0.59, 0.59, 0.45, 0.31, 0.77, 0.54, 0.59, 0.59, 0.59, 0.59, 0.59, 0.5, 0.5, 0.54, 0.54, 0.40, 0.72, 0.59, 0.59, 0.45, 0.68, 0.59, 0.81, 0.31, 0.59, 0.59, 0.54, 0.31, 0.63, 0.54, 0.72, 0.40, 0.63, 0.5, 0.54, 0.31, 0.59, 0.63, 0.63, 0.13, 0.72, 0.54, 0.59, 0.40, 0.59, 0.59, 0.68, 0.31, 0.59, 0.40, 0.68, 0.31, 0.59, 0.59, 0.45, 0.40, 0.63, 0.59, 0.59, 0.72, 0.81, 0.63, 0.72, 0.45, 0.81, 0.5, 0.45, 0.31, 0.77, 0.5

0.5363636363636364
0.59, 0.27, 0.63, 0.59, 0.45, 0.22, 0.72, 0.40, 0.59, 0.40, 0.68, 0.59, 0.54, 0.59, 0.68, 0.54, 0.63, 0.40, 0.68, 0.59, 0.45, 0.5, 0.72, 0.59, 0.54, 0.40, 0.63, 0.63, 0.54, 0.22, 0.63, 0.59, 0.59, 0.45, 0.59, 0.5, 0.5, 0.40, 0.63, 0.54, 0.63, 0.40, 0.77, 0.54, 0.54, 0.31, 0.77, 0.54, 0.5, 0.31, 0.59, 0.59, 0.45, 0.40, 0.63, 0.63, 0.59, 0.31, 0.72, 0.54, 0.5, 0.40, 0.68, 0.54, 0.63, 0.36, 0.63, 0.63, 0.5, 0.22, 0.68, 0.59, 0.40, 0.45, 0.77, 0.59, 0.59, 0.45, 0.72, 0.59, 0.45, 0.5, 0.59, 0.54, 0.45, 0.22, 0.59, 0.59, 0.59, 0.22, 0.68, 0.59, 0.5, 0.31, 0.68, 0.59, 0.31, 0.45, 0.63, 0.63


Running iteration 2 of 10 fold...
[40, 0, 84, 20, 8, 19, 63, 28, 55, 76]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.5938, 0.6100, 0.5154, 0.4657

    accuracy, precision, recall, f_score
max3: 0.5833, 0.6631, 0.6509, 0.5190

    accuracy, precision, recall, f_score
max1: 0.5455, 0.4500, 0.3944, 0.3650


min loss: 0.008, episode: 247000
max accu: 0.545, episode: 30000

1.00 classifiers used
    accuracy, precision, recall, f_score
mv: 0.5455, 0.5530, 0.4135, 0.4143
wv: 0.5455, 0.5808, 0.5468, 0.5619
fs: 0.5909, 0.5404, 0.4468, 0.4206
rl: 0.5455, 0.4500, 0.3944, 0.3650

0.4686363636363636
0.5, 0.54, 0.40, 0.54, 0.5, 0.22, 0.5, 0.40, 0.45, 0.45, 0.45, 0.31, 0.59, 0.22, 0.5, 0.54, 0.63, 0.31, 0.54, 0.40, 0.54, 0.40, 0.5, 0.45, 0.40, 0.40, 0.59, 0.54, 0.40, 0.45, 0.5, 0.40, 0.31, 0.27, 0.45, 0.40, 0.54, 0.27, 0.54, 0.54, 0.63, 0.5, 0.45, 0.40, 0.54, 0.31, 0.5, 0.54, 0.45, 0.54, 0.54, 0.63, 0.45, 0.54, 0.45, 0.36, 0.59, 0.36, 0.5, 0.5, 0.59, 0.31, 0.45, 0.40, 0.36, 0.40, 0.40, 0.54, 0.63, 0.45, 0.5, 0.54, 0.36, 0.40, 0.45, 0.59, 0.68, 0.40, 0.5, 0.54, 0.5, 0.5, 0.40, 0.5, 0.45, 0.31, 0.45, 0.36, 0.63, 0.54, 0.54, 0.45, 0.45, 0.13, 0.5, 0.54, 0.45, 0.54, 0.45, 0.54

0.46954545454545454
0.63, 0.31, 0.59, 0.5, 0.5, 0.5, 0.40, 0.59, 0.40, 0.40, 0.54, 0.59, 0.63, 0.40, 0.54, 0.59, 0.5, 0.31, 0.45, 0.45, 0.59, 0.22, 0.45, 0.40, 0.5, 0.27, 0.5, 0.54, 0.45, 0.40, 0.5, 0.54, 0.40, 0.36, 0.5, 0.5, 0.5, 0.36, 0.54, 0.45, 0.5, 0.40, 0.54, 0.5, 0.5, 0.5, 0.5, 0.31, 0.5, 0.40, 0.5, 0.5, 0.40, 0.40, 0.5, 0.45, 0.5, 0.36, 0.68, 0.36, 0.59, 0.45, 0.54, 0.54, 0.5, 0.40, 0.59, 0.54, 0.63, 0.40, 0.45, 0.5, 0.5, 0.40, 0.45, 0.5, 0.40, 0.27, 0.5, 0.45, 0.54, 0.31, 0.54, 0.45, 0.36, 0.27, 0.63, 0.5, 0.40, 0.18, 0.5, 0.54, 0.59, 0.36, 0.40, 0.63, 0.45, 0.27, 0.5, 0.45


Running iteration 3 of 10 fold...
[40, 0, 8, 30, 60, 23, 69, 87]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.6875, 0.6507, 0.6492, 0.6314

    accuracy, precision, recall, f_score
max3: 0.6875, 0.6146, 0.7123, 0.7098

    accuracy, precision, recall, f_score
max1: 0.7273, 0.6818, 0.5333, 0.4933


min loss: 0.006, episode: 265000
max accu: 0.727, episode: 210000

2.45 classifiers used
    accuracy, precision, recall, f_score
mv: 0.7273, 0.6182, 0.5333, 0.4833
wv: 0.7727, 0.6636, 0.5667, 0.5167
fs: 0.8636, 0.8295, 0.7333, 0.7048
rl: 0.7273, 0.6818, 0.5333, 0.4933

0.5854545454545453
0.72, 0.36, 0.59, 0.59, 0.63, 0.45, 0.63, 0.77, 0.72, 0.31, 0.59, 0.59, 0.59, 0.63, 0.59, 0.68, 0.68, 0.54, 0.54, 0.63, 0.72, 0.68, 0.68, 0.59, 0.68, 0.5, 0.68, 0.63, 0.59, 0.31, 0.77, 0.72, 0.45, 0.68, 0.54, 0.68, 0.54, 0.63, 0.54, 0.54, 0.81, 0.54, 0.54, 0.54, 0.68, 0.36, 0.59, 0.5, 0.63, 0.31, 0.59, 0.59, 0.68, 0.5, 0.63, 0.72, 0.59, 0.59, 0.63, 0.63, 0.68, 0.68, 0.59, 0.22, 0.72, 0.63, 0.63, 0.68, 0.63, 0.45, 0.63, 0.59, 0.63, 0.40, 0.63, 0.5, 0.68, 0.13, 0.63, 0.45, 0.68, 0.13, 0.59, 0.45, 0.63, 0.40, 0.59, 0.5, 0.63, 0.45, 0.59, 0.45, 0.63, 0.72, 0.68, 0.5, 0.68, 0.72, 0.63, 0.68

0.5759090909090908
0.72, 0.54, 0.63, 0.68, 0.77, 0.22, 0.59, 0.59, 0.68, 0.45, 0.59, 0.63, 0.72, 0.59, 0.68, 0.31, 0.68, 0.36, 0.63, 0.5, 0.63, 0.40, 0.63, 0.68, 0.45, 0.13, 0.63, 0.5, 0.59, 0.5, 0.68, 0.72, 0.68, 0.13, 0.54, 0.63, 0.68, 0.63, 0.63, 0.63, 0.68, 0.36, 0.68, 0.5, 0.77, 0.31, 0.59, 0.63, 0.77, 0.63, 0.45, 0.5, 0.63, 0.09, 0.68, 0.68, 0.72, 0.54, 0.68, 0.63, 0.68, 0.68, 0.63, 0.68, 0.72, 0.18, 0.59, 0.68, 0.63, 0.5, 0.59, 0.40, 0.68, 0.68, 0.54, 0.72, 0.68, 0.27, 0.59, 0.45, 0.63, 0.18, 0.63, 0.54, 0.5, 0.68, 0.72, 0.59, 0.63, 0.54, 0.59, 0.72, 0.63, 0.5, 0.59, 0.59, 0.72, 0.31, 0.54, 0.63


Running iteration 4 of 10 fold...
[12, 0, 52, 40, 9, 1]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.6146, 0.5682, 0.5219, 0.4473

    accuracy, precision, recall, f_score
max3: 0.5625, 0.5347, 0.5020, 0.4227

    accuracy, precision, recall, f_score
max1: 0.6818, 0.6098, 0.6354, 0.6015


min loss: 0.005, episode: 254000
max accu: 0.682, episode: 220000

30.82 classifiers used
    accuracy, precision, recall, f_score
mv: 0.6818, 0.6098, 0.6354, 0.6015
wv: 0.6818, 0.6374, 0.6354, 0.6042
fs: 0.8182, 0.8788, 0.7778, 0.7937
rl: 0.6818, 0.6098, 0.6354, 0.6015

0.5336363636363637
0.54, 0.5, 0.54, 0.45, 0.63, 0.45, 0.59, 0.45, 0.63, 0.40, 0.45, 0.40, 0.63, 0.54, 0.54, 0.45, 0.63, 0.54, 0.68, 0.54, 0.5, 0.5, 0.59, 0.45, 0.54, 0.54, 0.63, 0.40, 0.54, 0.45, 0.63, 0.5, 0.68, 0.45, 0.63, 0.5, 0.45, 0.40, 0.54, 0.45, 0.63, 0.68, 0.63, 0.5, 0.59, 0.31, 0.59, 0.45, 0.54, 0.54, 0.63, 0.5, 0.68, 0.5, 0.54, 0.40, 0.63, 0.59, 0.59, 0.5, 0.59, 0.36, 0.59, 0.72, 0.63, 0.40, 0.54, 0.5, 0.45, 0.54, 0.54, 0.40, 0.68, 0.45, 0.5, 0.40, 0.54, 0.45, 0.63, 0.45, 0.54, 0.5, 0.59, 0.45, 0.59, 0.45, 0.59, 0.40, 0.59, 0.54, 0.63, 0.45, 0.54, 0.5, 0.54, 0.45, 0.59, 0.54, 0.63, 0.5

0.5181818181818181
0.68, 0.36, 0.5, 0.45, 0.45, 0.36, 0.5, 0.5, 0.5, 0.36, 0.54, 0.40, 0.68, 0.54, 0.63, 0.45, 0.63, 0.45, 0.59, 0.31, 0.59, 0.45, 0.45, 0.40, 0.45, 0.36, 0.63, 0.45, 0.59, 0.5, 0.59, 0.5, 0.59, 0.5, 0.63, 0.45, 0.54, 0.59, 0.59, 0.45, 0.68, 0.59, 0.59, 0.45, 0.5, 0.31, 0.54, 0.45, 0.5, 0.31, 0.63, 0.45, 0.40, 0.54, 0.59, 0.63, 0.5, 0.59, 0.59, 0.45, 0.54, 0.59, 0.59, 0.45, 0.5, 0.40, 0.59, 0.45, 0.63, 0.59, 0.45, 0.40, 0.72, 0.36, 0.63, 0.5, 0.68, 0.45, 0.59, 0.5, 0.63, 0.40, 0.59, 0.45, 0.63, 0.31, 0.59, 0.45, 0.63, 0.40, 0.59, 0.45, 0.59, 0.5, 0.63, 0.45, 0.63, 0.40, 0.63, 0.40

    accuracy, precision, recall, f_score
mv: 0.6477, 0.6075, 0.5706, 0.5360
wv: 0.6705, 0.6321, 0.6106, 0.5862
fs: 0.7273, 0.7137, 0.6528, 0.6331
rl: 0.7045, 0.6417, 0.5866, 0.5590

fs avg size: 7.00000, rl avg size: 11.27273
full test avg accu: 0.52500, test avg accu: 0.53670

training takes 37625.485 sec
