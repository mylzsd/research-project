{'dataset': 'heart', 'algorithm': 'ptdqn', 'num_clf': 50, 'num_training': 350000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 3947, 'portion': 0.5, 'sequential': False}
(270, 21)
reading data takes 0.883 sec
number of labels: 2

Running iteration 1 of 10 fold...
[0, 1, 26, 45, 25, 42, 3, 20, 17, 36, 8, 34, 10, 46, 7, 37, 9, 43, 14]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.694215, 0.694387, 0.684848, 0.685626

    accuracy, precision, recall, f_score
max3: 0.688525, 0.692896, 0.687097, 0.685482

    accuracy, precision, recall, f_score
max1: 0.777778, 0.777778, 0.777473, 0.777473


min loss: 0.007, episode: 239000
max accu: 0.778, episode: 20000

1.00 classifiers used
    accuracy, precision, recall, f_score
mv: 0.777778, 0.806536, 0.782967, 0.775000
wv: 0.814815, 0.832492, 0.818681, 0.813793
fs: 0.777778, 0.785185, 0.780220, 0.777473
rl: 0.777778, 0.777778, 0.777473, 0.777473

0.6872727272727274
0.78, 0.74, 0.69, 0.78, 0.69, 0.69, 0.66, 0.74, 0.77, 0.73, 0.76, 0.65, 0.70, 0.71, 0.78, 0.78, 0.75, 0.61, 0.68, 0.59, 0.68, 0.62, 0.67, 0.65, 0.65, 0.67, 0.68, 0.62, 0.69, 0.59, 0.65, 0.70, 0.66, 0.61, 0.65, 0.65, 0.68, 0.57, 0.72, 0.71, 0.64, 0.70, 0.66, 0.66, 0.64, 0.76, 0.73, 0.58, 0.71, 0.65

0.6659016393442624
0.80, 0.72, 0.70, 0.78, 0.70, 0.67, 0.67, 0.75, 0.78, 0.72, 0.75, 0.63, 0.70, 0.70, 0.78, 0.78, 0.77, 0.62, 0.62, 0.57, 0.68, 0.57, 0.63, 0.59, 0.70, 0.70, 0.70, 0.59, 0.68, 0.59, 0.70, 0.67, 0.62, 0.63, 0.57, 0.57, 0.60, 0.57, 0.67, 0.70, 0.55, 0.67, 0.63, 0.54, 0.62, 0.72, 0.68, 0.54, 0.62, 0.57

0.6651851851851852
0.70, 0.70, 0.51, 0.74, 0.51, 0.51, 0.51, 0.70, 0.70, 0.70, 0.70, 0.48, 0.55, 0.55, 0.70, 0.70, 0.70, 0.77, 0.66, 0.33, 0.66, 0.66, 0.70, 0.66, 0.62, 0.74, 0.74, 0.70, 0.77, 0.62, 0.62, 0.81, 0.70, 0.70, 0.66, 0.66, 0.74, 0.55, 0.70, 0.77, 0.62, 0.74, 0.59, 0.74, 0.62, 0.81, 0.81, 0.62, 0.74, 0.51

0.7162962962962962
0.74, 0.70, 0.74, 0.74, 0.74, 0.74, 0.70, 0.74, 0.70, 0.74, 0.74, 0.74, 0.74, 0.74, 0.70, 0.74, 0.70, 0.66, 0.77, 0.51, 0.74, 0.74, 0.66, 0.77, 0.66, 0.70, 0.74, 0.77, 0.77, 0.77, 0.74, 0.51, 0.70, 0.70, 0.74, 0.66, 0.70, 0.66, 0.70, 0.66, 0.74, 0.70, 0.74, 0.77, 0.74, 0.70, 0.70, 0.74, 0.66, 0.74


Running iteration 2 of 10 fold...
[1, 0, 43, 3, 2, 15]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.768595, 0.768056, 0.764096, 0.764983

    accuracy, precision, recall, f_score
max3: 0.770492, 0.779270, 0.765086, 0.765385

    accuracy, precision, recall, f_score
max1: 0.740741, 0.738344, 0.724432, 0.727273


min loss: 0.007, episode: 232000
max accu: 0.741, episode: 30000

1.00 classifiers used
    accuracy, precision, recall, f_score
mv: 0.666667, 0.660088, 0.633523, 0.634586
wv: 0.740741, 0.738344, 0.724432, 0.727273
fs: 0.740741, 0.738344, 0.724432, 0.727273
rl: 0.740741, 0.738344, 0.724432, 0.727273

0.6985123966942148
0.77, 0.79, 0.67, 0.76, 0.77, 0.74, 0.76, 0.78, 0.76, 0.70, 0.67, 0.74, 0.67, 0.68, 0.77, 0.75, 0.76, 0.66, 0.75, 0.75, 0.75, 0.70, 0.71, 0.71, 0.70, 0.76, 0.71, 0.66, 0.71, 0.61, 0.65, 0.65, 0.62, 0.71, 0.58, 0.66, 0.66, 0.66, 0.60, 0.61, 0.62, 0.65, 0.67, 0.61, 0.65, 0.60, 0.69, 0.74, 0.66, 0.66

0.6659016393442623
0.78, 0.77, 0.63, 0.77, 0.75, 0.72, 0.75, 0.77, 0.75, 0.67, 0.65, 0.73, 0.65, 0.65, 0.75, 0.73, 0.77, 0.65, 0.73, 0.68, 0.75, 0.70, 0.67, 0.72, 0.65, 0.72, 0.68, 0.59, 0.70, 0.57, 0.68, 0.67, 0.59, 0.65, 0.54, 0.59, 0.52, 0.65, 0.59, 0.57, 0.55, 0.59, 0.65, 0.49, 0.55, 0.62, 0.63, 0.68, 0.57, 0.60

0.6562962962962962
0.74, 0.70, 0.62, 0.74, 0.74, 0.66, 0.70, 0.74, 0.70, 0.70, 0.66, 0.66, 0.66, 0.66, 0.70, 0.70, 0.74, 0.62, 0.62, 0.62, 0.66, 0.62, 0.55, 0.66, 0.66, 0.74, 0.62, 0.51, 0.77, 0.66, 0.44, 0.48, 0.48, 0.77, 0.77, 0.70, 0.70, 0.66, 0.77, 0.66, 0.59, 0.74, 0.55, 0.55, 0.66, 0.48, 0.51, 0.55, 0.70, 0.66

0.685185185185185
0.70, 0.70, 0.74, 0.74, 0.74, 0.66, 0.70, 0.70, 0.70, 0.74, 0.70, 0.74, 0.70, 0.70, 0.74, 0.70, 0.70, 0.62, 0.66, 0.59, 0.70, 0.55, 0.55, 0.70, 0.70, 0.66, 0.70, 0.70, 0.59, 0.74, 0.62, 0.77, 0.55, 0.55, 0.62, 0.77, 0.70, 0.62, 0.74, 0.62, 0.74, 0.66, 0.70, 0.62, 0.70, 0.66, 0.74, 0.74, 0.62, 0.74


Running iteration 3 of 10 fold...
[7, 0, 37, 17, 2, 1, 4, 3, 16, 6]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.735537, 0.736593, 0.734848, 0.734066

    accuracy, precision, recall, f_score
max3: 0.672131, 0.671540, 0.664502, 0.664835

    accuracy, precision, recall, f_score
max1: 0.888889, 0.893308, 0.891176, 0.883117


min loss: 0.008, episode: 222000
max accu: 0.889, episode: 200000

8.85 classifiers used
    accuracy, precision, recall, f_score
mv: 0.925926, 0.925926, 0.920588, 0.920588
wv: 0.888889, 0.893308, 0.891176, 0.883117
fs: 0.888889, 0.893308, 0.891176, 0.883117
rl: 0.888889, 0.893308, 0.891176, 0.883117

0.6765289256198348
0.68, 0.67, 0.75, 0.66, 0.76, 0.76, 0.65, 0.77, 0.75, 0.76, 0.67, 0.74, 0.76, 0.66, 0.76, 0.66, 0.76, 0.66, 0.69, 0.65, 0.62, 0.66, 0.68, 0.62, 0.70, 0.71, 0.65, 0.63, 0.71, 0.62, 0.61, 0.66, 0.65, 0.66, 0.58, 0.66, 0.58, 0.67, 0.69, 0.64, 0.61, 0.59, 0.57, 0.65, 0.61, 0.71, 0.65, 0.59, 0.59, 0.74

0.638360655737705
0.65, 0.63, 0.72, 0.65, 0.75, 0.75, 0.62, 0.73, 0.72, 0.73, 0.65, 0.72, 0.73, 0.63, 0.73, 0.63, 0.73, 0.63, 0.63, 0.60, 0.50, 0.59, 0.67, 0.60, 0.63, 0.63, 0.62, 0.60, 0.65, 0.63, 0.59, 0.67, 0.57, 0.67, 0.49, 0.62, 0.57, 0.60, 0.62, 0.60, 0.57, 0.59, 0.54, 0.63, 0.55, 0.65, 0.62, 0.50, 0.57, 0.68

0.7377777777777779
0.77, 0.70, 0.88, 0.77, 0.88, 0.88, 0.70, 0.88, 0.88, 0.88, 0.77, 0.81, 0.88, 0.77, 0.88, 0.77, 0.88, 0.70, 0.70, 0.85, 0.62, 0.62, 0.59, 0.62, 0.77, 0.62, 0.81, 0.66, 0.81, 0.70, 0.81, 0.74, 0.62, 0.74, 0.70, 0.62, 0.81, 0.74, 0.77, 0.62, 0.62, 0.59, 0.62, 0.74, 0.70, 0.70, 0.59, 0.55, 0.66, 0.59

0.7644444444444445
0.81, 0.88, 0.88, 0.88, 0.88, 0.88, 0.81, 0.88, 0.88, 0.88, 0.88, 0.88, 0.81, 0.88, 0.88, 0.88, 0.81, 0.81, 0.70, 0.70, 0.74, 0.70, 0.66, 0.66, 0.77, 0.66, 0.59, 0.70, 0.85, 0.59, 0.62, 0.74, 0.77, 0.59, 0.77, 0.70, 0.74, 0.74, 0.70, 0.62, 0.77, 0.74, 0.74, 0.66, 0.70, 0.62, 0.77, 0.74, 0.66, 0.74

    accuracy, precision, recall, f_score
mv: 0.790123, 0.797517, 0.779026, 0.776725
wv: 0.814815, 0.821381, 0.811430, 0.808061
fs: 0.802469, 0.805612, 0.798609, 0.795954
rl: 0.802469, 0.803143, 0.797694, 0.795954

fs avg size: 11.66667, rl avg size: 3.61728
full test avg accu: 0.72198, test avg accu: 0.68642

training takes 9234.443 sec
