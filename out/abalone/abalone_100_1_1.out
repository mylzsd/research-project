{'dataset': 'abalone', 'algorithm': 'ptdqn', 'num_clf': 100, 'num_training': 400000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 8330, 'portion': 0.5, 'sequential': False}
(4177, 11)
reading data takes 2.961 sec
number of labels: 28

Running iteration 1 of 10 fold...
[10, 0, 54, 69, 13, 15, 46, 70, 99, 75, 53]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.2416, 0.2214, 0.1476, 0.1257

    accuracy, precision, recall, f_score
max3: 0.2322, 0.2146, 0.1250, 0.1189

    accuracy, precision, recall, f_score
max1: 0.2943, 0.2832, 0.1999, 0.1844


min loss: 0.002, episode: 102000
max accu: 0.294, episode: 10000

41.67 classifiers used
    accuracy, precision, recall, f_score
mv: 0.2799, 0.2728, 0.2027, 0.1931
wv: 0.2751, 0.2667, 0.2002, 0.1899
fs: 0.2344, 0.2406, 0.1541, 0.1424
rl: 0.2943, 0.2832, 0.1999, 0.1844

0.2057655502392344
0.22, 0.18, 0.21, 0.18, 0.21, 0.19, 0.19, 0.20, 0.18, 0.21, 0.20, 0.16, 0.20, 0.21, 0.18, 0.16, 0.19, 0.22, 0.22, 0.20, 0.17, 0.22, 0.18, 0.19, 0.23, 0.21, 0.21, 0.21, 0.19, 0.19, 0.18, 0.15, 0.20, 0.23, 0.20, 0.18, 0.23, 0.23, 0.19, 0.22, 0.21, 0.22, 0.21, 0.21, 0.19, 0.16, 0.22, 0.22, 0.23, 0.21, 0.18, 0.21, 0.17, 0.19, 0.18, 0.21, 0.20, 0.19, 0.19, 0.21, 0.20, 0.22, 0.19, 0.18, 0.22, 0.23, 0.17, 0.19, 0.22, 0.19, 0.22, 0.24, 0.21, 0.21, 0.17, 0.18, 0.23, 0.22, 0.19, 0.21, 0.18, 0.18, 0.20, 0.19, 0.23, 0.21, 0.18, 0.21, 0.21, 0.23, 0.18, 0.20, 0.22, 0.19, 0.21, 0.22, 0.23, 0.19, 0.21, 0.20

0.20569377990430623
0.23, 0.23, 0.23, 0.19, 0.18, 0.17, 0.22, 0.21, 0.23, 0.19, 0.20, 0.19, 0.20, 0.23, 0.20, 0.19, 0.20, 0.22, 0.22, 0.20, 0.18, 0.18, 0.24, 0.21, 0.21, 0.20, 0.16, 0.24, 0.20, 0.19, 0.19, 0.19, 0.21, 0.17, 0.19, 0.17, 0.20, 0.22, 0.21, 0.20, 0.20, 0.21, 0.19, 0.18, 0.21, 0.19, 0.20, 0.20, 0.20, 0.20, 0.21, 0.18, 0.19, 0.20, 0.16, 0.20, 0.20, 0.20, 0.18, 0.23, 0.17, 0.17, 0.22, 0.21, 0.22, 0.21, 0.21, 0.21, 0.15, 0.18, 0.21, 0.20, 0.22, 0.22, 0.20, 0.20, 0.22, 0.20, 0.20, 0.20, 0.19, 0.20, 0.24, 0.20, 0.19, 0.21, 0.22, 0.21, 0.22, 0.18, 0.19, 0.20, 0.22, 0.19, 0.20, 0.19, 0.21, 0.22, 0.16, 0.17


Running iteration 2 of 10 fold...
[58, 0, 85, 5, 20, 16, 37, 19, 92, 48, 82, 83, 45, 61]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.2453, 0.2168, 0.1063, 0.1032

    accuracy, precision, recall, f_score
max3: 0.2300, 0.2056, 0.1145, 0.1142

    accuracy, precision, recall, f_score
max1: 0.2368, 0.2297, 0.1520, 0.1475


min loss: 0.002, episode: 144000
max accu: 0.237, episode: 300000

72.48 classifiers used
    accuracy, precision, recall, f_score
mv: 0.2416, 0.2290, 0.1509, 0.1472
wv: 0.2392, 0.2279, 0.1502, 0.1472
fs: 0.2129, 0.1990, 0.1260, 0.1133
rl: 0.2368, 0.2297, 0.1520, 0.1475

0.1865311004784689
0.18, 0.20, 0.18, 0.18, 0.18, 0.15, 0.16, 0.21, 0.18, 0.17, 0.16, 0.17, 0.19, 0.18, 0.21, 0.19, 0.19, 0.17, 0.17, 0.16, 0.17, 0.19, 0.16, 0.19, 0.23, 0.19, 0.23, 0.20, 0.18, 0.15, 0.16, 0.19, 0.13, 0.19, 0.18, 0.20, 0.17, 0.14, 0.19, 0.19, 0.20, 0.18, 0.20, 0.18, 0.19, 0.21, 0.17, 0.19, 0.18, 0.19, 0.18, 0.15, 0.21, 0.17, 0.16, 0.19, 0.21, 0.20, 0.17, 0.20, 0.16, 0.17, 0.15, 0.19, 0.17, 0.19, 0.17, 0.19, 0.16, 0.18, 0.20, 0.22, 0.16, 0.17, 0.15, 0.19, 0.17, 0.18, 0.17, 0.20, 0.21, 0.21, 0.15, 0.17, 0.19, 0.20, 0.16, 0.17, 0.20, 0.21, 0.21, 0.17, 0.19, 0.19, 0.15, 0.18, 0.19, 0.21, 0.19, 0.17

0.18705741626794256
0.17, 0.20, 0.16, 0.19, 0.19, 0.18, 0.22, 0.15, 0.15, 0.18, 0.16, 0.18, 0.18, 0.18, 0.17, 0.17, 0.16, 0.18, 0.17, 0.18, 0.19, 0.20, 0.19, 0.20, 0.21, 0.19, 0.18, 0.19, 0.18, 0.19, 0.22, 0.17, 0.16, 0.19, 0.20, 0.19, 0.15, 0.17, 0.16, 0.18, 0.17, 0.19, 0.16, 0.18, 0.16, 0.19, 0.20, 0.18, 0.18, 0.21, 0.14, 0.20, 0.18, 0.16, 0.18, 0.20, 0.19, 0.19, 0.20, 0.16, 0.17, 0.18, 0.18, 0.19, 0.18, 0.20, 0.21, 0.18, 0.18, 0.17, 0.21, 0.19, 0.20, 0.16, 0.19, 0.17, 0.18, 0.22, 0.18, 0.16, 0.21, 0.19, 0.18, 0.18, 0.16, 0.16, 0.17, 0.20, 0.18, 0.20, 0.15, 0.18, 0.16, 0.17, 0.18, 0.19, 0.17, 0.19, 0.20, 0.19


Running iteration 3 of 10 fold...
[73, 0, 41, 17, 70, 84, 58]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.2565, 0.2360, 0.1131, 0.1106

    accuracy, precision, recall, f_score
max3: 0.2471, 0.2188, 0.1224, 0.1142

    accuracy, precision, recall, f_score
max1: 0.2464, 0.2128, 0.1276, 0.1217


min loss: 0.003, episode: 141000
max accu: 0.246, episode: 340000

42.28 classifiers used
    accuracy, precision, recall, f_score
mv: 0.2416, 0.2056, 0.1264, 0.1195
wv: 0.2416, 0.2043, 0.1262, 0.1195
fs: 0.1986, 0.1684, 0.0979, 0.0895
rl: 0.2464, 0.2128, 0.1276, 0.1217

0.18657894736842104
0.14, 0.16, 0.17, 0.21, 0.17, 0.16, 0.20, 0.18, 0.16, 0.16, 0.17, 0.16, 0.20, 0.17, 0.18, 0.14, 0.15, 0.18, 0.20, 0.19, 0.19, 0.21, 0.20, 0.16, 0.16, 0.21, 0.21, 0.19, 0.18, 0.22, 0.22, 0.20, 0.19, 0.22, 0.19, 0.17, 0.16, 0.21, 0.18, 0.17, 0.15, 0.18, 0.20, 0.13, 0.17, 0.18, 0.18, 0.20, 0.19, 0.17, 0.19, 0.19, 0.21, 0.19, 0.20, 0.19, 0.21, 0.16, 0.18, 0.17, 0.17, 0.19, 0.22, 0.19, 0.13, 0.19, 0.18, 0.18, 0.17, 0.16, 0.18, 0.17, 0.17, 0.21, 0.16, 0.16, 0.17, 0.19, 0.19, 0.16, 0.19, 0.17, 0.19, 0.17, 0.18, 0.19, 0.18, 0.18, 0.23, 0.17, 0.19, 0.19, 0.18, 0.23, 0.20, 0.14, 0.16, 0.21, 0.18, 0.17

0.18815789473684205
0.16, 0.17, 0.18, 0.17, 0.19, 0.19, 0.18, 0.20, 0.18, 0.20, 0.19, 0.19, 0.16, 0.16, 0.19, 0.20, 0.16, 0.15, 0.17, 0.18, 0.21, 0.18, 0.16, 0.19, 0.18, 0.20, 0.16, 0.19, 0.18, 0.20, 0.18, 0.14, 0.18, 0.18, 0.19, 0.19, 0.17, 0.22, 0.17, 0.21, 0.20, 0.18, 0.20, 0.18, 0.21, 0.17, 0.19, 0.18, 0.19, 0.17, 0.19, 0.18, 0.18, 0.17, 0.17, 0.21, 0.19, 0.20, 0.19, 0.18, 0.20, 0.17, 0.17, 0.19, 0.20, 0.20, 0.19, 0.16, 0.15, 0.22, 0.20, 0.16, 0.20, 0.19, 0.19, 0.19, 0.19, 0.15, 0.21, 0.15, 0.16, 0.21, 0.19, 0.16, 0.18, 0.17, 0.21, 0.18, 0.19, 0.18, 0.20, 0.21, 0.18, 0.22, 0.17, 0.14, 0.15, 0.19, 0.20, 0.18


Running iteration 4 of 10 fold...
[81, 0, 49, 83, 80, 11, 5, 7]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.2432, 0.2154, 0.0990, 0.0946

    accuracy, precision, recall, f_score
max3: 0.2386, 0.2100, 0.1124, 0.1056

    accuracy, precision, recall, f_score
max1: 0.2775, 0.2738, 0.1750, 0.1603


min loss: 0.002, episode: 112000
max accu: 0.278, episode: 330000

83.96 classifiers used
    accuracy, precision, recall, f_score
mv: 0.2584, 0.2460, 0.1415, 0.1305
wv: 0.2584, 0.2467, 0.1415, 0.1305
fs: 0.2392, 0.2244, 0.1629, 0.1491
rl: 0.2775, 0.2738, 0.1750, 0.1603

0.20294258373205742
0.17, 0.22, 0.20, 0.17, 0.19, 0.21, 0.17, 0.22, 0.17, 0.22, 0.19, 0.20, 0.19, 0.23, 0.16, 0.19, 0.18, 0.20, 0.19, 0.23, 0.21, 0.22, 0.19, 0.22, 0.22, 0.20, 0.19, 0.21, 0.20, 0.20, 0.21, 0.22, 0.23, 0.20, 0.22, 0.20, 0.21, 0.23, 0.20, 0.20, 0.21, 0.20, 0.21, 0.19, 0.21, 0.16, 0.20, 0.20, 0.17, 0.21, 0.16, 0.21, 0.18, 0.22, 0.18, 0.19, 0.19, 0.19, 0.16, 0.19, 0.22, 0.21, 0.19, 0.21, 0.22, 0.22, 0.17, 0.19, 0.22, 0.18, 0.21, 0.20, 0.18, 0.21, 0.17, 0.20, 0.21, 0.17, 0.16, 0.21, 0.21, 0.18, 0.21, 0.17, 0.22, 0.22, 0.19, 0.20, 0.20, 0.19, 0.19, 0.18, 0.20, 0.18, 0.22, 0.21, 0.22, 0.18, 0.18, 0.19

0.20564593301435402
0.20, 0.20, 0.21, 0.19, 0.21, 0.21, 0.20, 0.19, 0.20, 0.22, 0.22, 0.18, 0.18, 0.18, 0.21, 0.18, 0.18, 0.20, 0.20, 0.21, 0.19, 0.19, 0.21, 0.20, 0.20, 0.17, 0.18, 0.20, 0.20, 0.22, 0.19, 0.19, 0.22, 0.18, 0.19, 0.19, 0.19, 0.23, 0.18, 0.18, 0.20, 0.20, 0.20, 0.19, 0.22, 0.21, 0.22, 0.19, 0.21, 0.20, 0.18, 0.19, 0.21, 0.24, 0.19, 0.26, 0.20, 0.18, 0.19, 0.22, 0.19, 0.22, 0.16, 0.21, 0.20, 0.22, 0.21, 0.22, 0.20, 0.20, 0.21, 0.17, 0.23, 0.22, 0.21, 0.19, 0.22, 0.21, 0.21, 0.22, 0.19, 0.23, 0.20, 0.20, 0.19, 0.20, 0.19, 0.17, 0.23, 0.18, 0.20, 0.19, 0.18, 0.23, 0.21, 0.20, 0.23, 0.20, 0.19, 0.20

    accuracy, precision, recall, f_score
mv: 0.2554, 0.2384, 0.1554, 0.1476
wv: 0.2536, 0.2364, 0.1545, 0.1468
fs: 0.2213, 0.2081, 0.1352, 0.1236
rl: 0.2638, 0.2499, 0.1636, 0.1535

fs avg size: 10.00000, rl avg size: 60.09689
full test avg accu: 0.19664, test avg accu: 0.19545

training takes 97363.325 sec
