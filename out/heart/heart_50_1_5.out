{'dataset': 'heart', 'algorithm': 'ptdqn', 'num_clf': 50, 'num_training': 400000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 5631, 'portion': 0.5, 'sequential': False}
(270, 21)
reading data takes 0.846 sec
number of labels: 2

Running iteration 1 of 10 fold...
[43, 0, 36, 16, 39, 38]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.735537, 0.737193, 0.731513, 0.730212

    accuracy, precision, recall, f_score
max3: 0.672131, 0.694707, 0.676773, 0.664835

    accuracy, precision, recall, f_score
max1: 0.888889, 0.905556, 0.850000, 0.871224


min loss: 0.007, episode: 233000
max accu: 0.889, episode: 10000

12.37 classifiers used
    accuracy, precision, recall, f_score
mv: 0.851852, 0.851852, 0.841176, 0.841176
wv: 0.851852, 0.851852, 0.841176, 0.841176
fs: 0.888889, 0.893308, 0.891176, 0.883117
rl: 0.888889, 0.905556, 0.850000, 0.871224

0.663305785123967
0.71, 0.70, 0.63, 0.76, 0.71, 0.69, 0.61, 0.78, 0.65, 0.52, 0.63, 0.65, 0.73, 0.77, 0.57, 0.70, 0.68, 0.42, 0.65, 0.66, 0.70, 0.42, 0.60, 0.79, 0.67, 0.43, 0.61, 0.79, 0.69, 0.78, 0.57, 0.76, 0.68, 0.38, 0.65, 0.75, 0.73, 0.64, 0.66, 0.77, 0.62, 0.47, 0.61, 0.80, 0.76, 0.44, 0.69, 0.78, 0.73, 0.74

0.6557377049180328
0.70, 0.68, 0.63, 0.77, 0.65, 0.65, 0.59, 0.81, 0.65, 0.54, 0.63, 0.62, 0.67, 0.70, 0.59, 0.62, 0.65, 0.37, 0.63, 0.62, 0.70, 0.42, 0.60, 0.81, 0.65, 0.39, 0.59, 0.77, 0.70, 0.81, 0.59, 0.77, 0.70, 0.40, 0.63, 0.73, 0.73, 0.63, 0.62, 0.75, 0.65, 0.47, 0.65, 0.80, 0.77, 0.44, 0.72, 0.80, 0.73, 0.75

0.7207407407407408
0.92, 0.81, 0.66, 0.74, 0.66, 0.85, 0.66, 0.85, 0.85, 0.74, 0.62, 0.70, 0.70, 0.92, 0.66, 0.74, 0.85, 0.37, 0.74, 0.70, 0.74, 0.59, 0.70, 0.85, 0.70, 0.48, 0.59, 0.85, 0.74, 0.85, 0.66, 0.77, 0.55, 0.33, 0.74, 0.85, 0.81, 0.77, 0.74, 0.77, 0.70, 0.51, 0.62, 0.85, 0.77, 0.48, 0.77, 0.77, 0.77, 0.77

0.7511111111111112
0.81, 0.92, 0.77, 0.81, 0.66, 0.74, 0.59, 0.81, 0.74, 0.81, 0.55, 0.85, 0.66, 0.66, 0.66, 0.70, 0.74, 0.88, 0.59, 0.81, 0.74, 0.85, 0.70, 0.88, 0.70, 0.85, 0.70, 0.85, 0.66, 0.85, 0.59, 0.85, 0.74, 0.85, 0.74, 0.85, 0.74, 0.81, 0.66, 0.88, 0.66, 0.81, 0.74, 0.70, 0.92, 0.77, 0.55, 0.85, 0.74, 0.37


Running iteration 2 of 10 fold...
[49, 0, 9, 13, 20, 25, 11, 2, 43, 10]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.752066, 0.759279, 0.752551, 0.747074

    accuracy, precision, recall, f_score
max3: 0.737705, 0.761443, 0.745338, 0.728889

    accuracy, precision, recall, f_score
max1: 0.888889, 0.912698, 0.906250, 0.888276


min loss: 0.007, episode: 284000
max accu: 0.889, episode: 20000

1.00 classifiers used
    accuracy, precision, recall, f_score
mv: 0.888889, 0.892593, 0.892045, 0.886396
wv: 0.925926, 0.937322, 0.937500, 0.925000
fs: 0.814815, 0.872685, 0.843750, 0.814815
rl: 0.888889, 0.912698, 0.906250, 0.888276

0.6695867768595041
0.73, 0.46, 0.63, 0.73, 0.71, 0.77, 0.62, 0.71, 0.65, 0.78, 0.66, 0.77, 0.71, 0.59, 0.59, 0.78, 0.70, 0.52, 0.58, 0.76, 0.69, 0.39, 0.61, 0.75, 0.74, 0.58, 0.69, 0.77, 0.69, 0.68, 0.63, 0.76, 0.70, 0.69, 0.58, 0.78, 0.67, 0.45, 0.61, 0.64, 0.75, 0.52, 0.63, 0.73, 0.67, 0.51, 0.66, 0.74, 0.67, 0.80

0.6629508196721312
0.75, 0.39, 0.65, 0.73, 0.72, 0.81, 0.63, 0.68, 0.62, 0.75, 0.62, 0.75, 0.75, 0.62, 0.55, 0.80, 0.65, 0.52, 0.55, 0.80, 0.70, 0.36, 0.60, 0.73, 0.68, 0.57, 0.65, 0.73, 0.73, 0.67, 0.65, 0.80, 0.67, 0.70, 0.57, 0.77, 0.70, 0.40, 0.62, 0.60, 0.73, 0.57, 0.62, 0.67, 0.70, 0.47, 0.63, 0.81, 0.63, 0.81

0.7051851851851854
0.85, 0.66, 0.62, 0.88, 0.77, 0.77, 0.55, 0.77, 0.85, 0.74, 0.59, 0.92, 0.66, 0.59, 0.51, 0.92, 0.70, 0.51, 0.59, 0.77, 0.74, 0.40, 0.55, 0.88, 0.85, 0.59, 0.59, 0.92, 0.70, 0.74, 0.59, 0.85, 0.74, 0.74, 0.59, 0.88, 0.70, 0.48, 0.62, 0.74, 0.88, 0.44, 0.62, 0.77, 0.66, 0.59, 0.59, 0.74, 0.81, 0.81

0.7496296296296298
0.74, 0.59, 0.70, 0.74, 0.81, 0.85, 0.74, 0.88, 0.70, 0.88, 0.66, 0.85, 0.70, 0.81, 0.74, 0.85, 0.74, 0.40, 0.62, 0.77, 0.62, 0.74, 0.74, 0.88, 0.59, 0.77, 0.70, 0.81, 0.74, 0.77, 0.74, 0.77, 0.70, 0.88, 0.81, 0.88, 0.74, 0.81, 0.55, 0.88, 0.74, 0.85, 0.66, 0.85, 0.74, 0.48, 0.74, 0.92, 0.59, 0.81


Running iteration 3 of 10 fold...
[17, 0]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.719008, 0.735510, 0.727564, 0.718528

    accuracy, precision, recall, f_score
max3: 0.737705, 0.748021, 0.741111, 0.734205

    accuracy, precision, recall, f_score
max1: 0.888889, 0.896199, 0.878571, 0.861538


min loss: 0.008, episode: 259000
max accu: 0.889, episode: 30000

1.00 classifiers used
    accuracy, precision, recall, f_score
mv: 0.925926, 0.925926, 0.903571, 0.903571
wv: 0.925926, 0.925926, 0.903571, 0.903571
fs: 0.814815, 0.807760, 0.735714, 0.746717
rl: 0.888889, 0.896199, 0.878571, 0.861538

0.6537190082644626
0.68, 0.50, 0.61, 0.71, 0.62, 0.42, 0.64, 0.77, 0.71, 0.39, 0.61, 0.75, 0.72, 0.56, 0.65, 0.71, 0.63, 0.80, 0.66, 0.71, 0.66, 0.38, 0.64, 0.75, 0.68, 0.57, 0.60, 0.74, 0.69, 0.72, 0.60, 0.71, 0.72, 0.76, 0.61, 0.74, 0.72, 0.41, 0.60, 0.73, 0.64, 0.77, 0.62, 0.74, 0.69, 0.44, 0.64, 0.71, 0.73, 0.56

0.6472131147540982
0.73, 0.44, 0.57, 0.68, 0.67, 0.40, 0.62, 0.75, 0.75, 0.37, 0.55, 0.68, 0.70, 0.59, 0.62, 0.68, 0.67, 0.80, 0.65, 0.73, 0.62, 0.42, 0.60, 0.75, 0.68, 0.52, 0.55, 0.73, 0.67, 0.72, 0.59, 0.70, 0.77, 0.80, 0.54, 0.75, 0.72, 0.44, 0.60, 0.77, 0.68, 0.75, 0.59, 0.70, 0.77, 0.47, 0.60, 0.73, 0.68, 0.57

0.702962962962963
0.77, 0.37, 0.59, 0.85, 0.77, 0.25, 0.66, 0.88, 0.74, 0.37, 0.59, 0.85, 0.88, 0.51, 0.62, 0.88, 0.74, 0.81, 0.70, 0.88, 0.88, 0.48, 0.59, 0.88, 0.66, 0.51, 0.48, 0.88, 0.74, 0.77, 0.44, 0.77, 0.88, 0.88, 0.66, 0.88, 0.85, 0.48, 0.62, 0.81, 0.74, 0.88, 0.62, 0.85, 0.85, 0.29, 0.48, 0.81, 0.81, 0.70

0.7977777777777777
0.88, 0.88, 0.55, 0.88, 0.70, 0.88, 0.70, 0.88, 0.77, 0.81, 0.74, 0.92, 0.66, 0.66, 0.74, 0.92, 0.88, 0.81, 0.66, 0.88, 0.77, 0.96, 0.66, 0.88, 0.77, 0.85, 0.62, 0.92, 0.66, 0.96, 0.51, 0.85, 0.81, 0.85, 0.55, 0.88, 0.85, 0.96, 0.59, 0.85, 0.92, 0.92, 0.70, 0.88, 0.77, 0.70, 0.66, 0.92, 0.74, 0.85

    accuracy, precision, recall, f_score
mv: 0.888889, 0.890123, 0.878931, 0.877048
wv: 0.901235, 0.905033, 0.894083, 0.889916
fs: 0.839506, 0.857918, 0.823547, 0.814883
rl: 0.888889, 0.904818, 0.878274, 0.873679

fs avg size: 6.00000, rl avg size: 4.79012
full test avg accu: 0.76617, test avg accu: 0.70963

training takes 12719.120 sec
