{'dataset': 'abalone', 'algorithm': 'ptdqn', 'num_clf': 50, 'num_training': 450000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 9295, 'portion': 0.5, 'sequential': False}
(4177, 11)
reading data takes 2.885 sec
number of labels: 28

Running iteration 1 of 10 fold...
[49, 0, 10, 41, 30, 43, 4]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.274614, 0.256864, 0.134657, 0.120909

    accuracy, precision, recall, f_score
max3: 0.283280, 0.288416, 0.150666, 0.140109

    accuracy, precision, recall, f_score
max1: 0.311005, 0.274003, 0.180548, 0.161337


min loss: 0.002, episode: 185000
max accu: 0.311, episode: 300000

11.26 classifiers used
    accuracy, precision, recall, f_score
mv: 0.301435, 0.247409, 0.169273, 0.149318
wv: 0.246411, 0.201801, 0.139391, 0.114256
fs: 0.284689, 0.264603, 0.162500, 0.155303
rl: 0.311005, 0.274003, 0.180548, 0.161337

0.20684406599254918
0.21, 0.27, 0.24, 0.07, 0.19, 0.26, 0.23, 0.13, 0.19, 0.26, 0.24, 0.09, 0.19, 0.26, 0.23, 0.14, 0.20, 0.27, 0.23, 0.15, 0.19, 0.26, 0.23, 0.08, 0.18, 0.25, 0.21, 0.12, 0.18, 0.27, 0.24, 0.15, 0.19, 0.27, 0.23, 0.09, 0.17, 0.27, 0.23, 0.18, 0.20, 0.27, 0.22, 0.10, 0.18, 0.27, 0.21, 0.15, 0.19, 0.28

0.2100958466453674
0.20, 0.29, 0.24, 0.08, 0.18, 0.28, 0.21, 0.14, 0.20, 0.27, 0.22, 0.09, 0.19, 0.27, 0.23, 0.14, 0.20, 0.29, 0.23, 0.15, 0.17, 0.28, 0.24, 0.07, 0.18, 0.27, 0.21, 0.12, 0.17, 0.28, 0.22, 0.15, 0.19, 0.28, 0.22, 0.08, 0.17, 0.28, 0.24, 0.18, 0.20, 0.28, 0.22, 0.10, 0.19, 0.28, 0.21, 0.15, 0.20, 0.30

0.21684210526315786
0.20, 0.30, 0.23, 0.09, 0.23, 0.29, 0.23, 0.12, 0.16, 0.29, 0.20, 0.11, 0.18, 0.26, 0.22, 0.15, 0.19, 0.26, 0.22, 0.19, 0.20, 0.29, 0.27, 0.10, 0.17, 0.28, 0.22, 0.15, 0.20, 0.29, 0.21, 0.18, 0.20, 0.29, 0.23, 0.10, 0.19, 0.28, 0.23, 0.19, 0.20, 0.28, 0.25, 0.12, 0.21, 0.29, 0.20, 0.15, 0.21, 0.29

0.2152153110047847
0.17, 0.28, 0.24, 0.11, 0.17, 0.27, 0.24, 0.14, 0.24, 0.27, 0.24, 0.11, 0.19, 0.29, 0.26, 0.12, 0.20, 0.28, 0.26, 0.12, 0.18, 0.27, 0.23, 0.12, 0.16, 0.29, 0.23, 0.11, 0.20, 0.28, 0.20, 0.11, 0.20, 0.26, 0.28, 0.13, 0.21, 0.28, 0.23, 0.13, 0.22, 0.28, 0.22, 0.11, 0.19, 0.30, 0.26, 0.12, 0.21, 0.28


Running iteration 2 of 10 fold...
[41, 0, 33, 38, 7, 9, 46]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.275146, 0.273355, 0.136012, 0.129030

    accuracy, precision, recall, f_score
max3: 0.286475, 0.264537, 0.140811, 0.134876

    accuracy, precision, recall, f_score
max1: 0.270335, 0.252904, 0.154965, 0.147149


min loss: 0.005, episode: 3000
max accu: 0.270, episode: 260000

22.77 classifiers used
    accuracy, precision, recall, f_score
mv: 0.255981, 0.238416, 0.142702, 0.129815
wv: 0.227273, 0.206610, 0.192812, 0.142423
fs: 0.253589, 0.240086, 0.146858, 0.143319
rl: 0.270335, 0.252904, 0.154965, 0.147149

0.20274614156466203
0.20, 0.26, 0.22, 0.11, 0.21, 0.27, 0.23, 0.10, 0.18, 0.27, 0.21, 0.10, 0.18, 0.26, 0.23, 0.08, 0.20, 0.26, 0.24, 0.10, 0.19, 0.28, 0.23, 0.10, 0.19, 0.26, 0.22, 0.09, 0.19, 0.27, 0.23, 0.09, 0.19, 0.27, 0.23, 0.10, 0.20, 0.27, 0.24, 0.11, 0.19, 0.29, 0.21, 0.10, 0.20, 0.26, 0.23, 0.09, 0.19, 0.26

0.20692225772097977
0.19, 0.26, 0.22, 0.13, 0.21, 0.28, 0.23, 0.11, 0.16, 0.28, 0.22, 0.12, 0.18, 0.26, 0.23, 0.09, 0.20, 0.28, 0.25, 0.11, 0.19, 0.29, 0.23, 0.11, 0.18, 0.27, 0.22, 0.10, 0.18, 0.27, 0.23, 0.10, 0.19, 0.28, 0.23, 0.11, 0.19, 0.29, 0.24, 0.12, 0.19, 0.29, 0.23, 0.11, 0.20, 0.27, 0.23, 0.10, 0.18, 0.28

0.19143540669856457
0.18, 0.26, 0.22, 0.10, 0.15, 0.28, 0.23, 0.07, 0.20, 0.25, 0.22, 0.08, 0.16, 0.22, 0.20, 0.08, 0.16, 0.21, 0.21, 0.09, 0.25, 0.25, 0.23, 0.09, 0.21, 0.25, 0.24, 0.08, 0.20, 0.25, 0.22, 0.09, 0.19, 0.27, 0.19, 0.09, 0.18, 0.26, 0.22, 0.11, 0.16, 0.25, 0.19, 0.09, 0.18, 0.26, 0.20, 0.10, 0.16, 0.28

0.1867464114832536
0.13, 0.24, 0.20, 0.10, 0.18, 0.25, 0.22, 0.12, 0.18, 0.23, 0.20, 0.10, 0.18, 0.25, 0.21, 0.09, 0.17, 0.24, 0.21, 0.11, 0.14, 0.25, 0.19, 0.10, 0.20, 0.25, 0.22, 0.08, 0.19, 0.24, 0.22, 0.11, 0.16, 0.25, 0.23, 0.09, 0.19, 0.24, 0.20, 0.09, 0.15, 0.25, 0.20, 0.09, 0.17, 0.24, 0.22, 0.09, 0.20, 0.24


Running iteration 3 of 10 fold...
[41, 0, 45, 32, 29, 13, 10, 23]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.293241, 0.299096, 0.140683, 0.136610

    accuracy, precision, recall, f_score
max3: 0.300319, 0.305996, 0.149255, 0.147538

    accuracy, precision, recall, f_score
max1: 0.282297, 0.259237, 0.145109, 0.140169


min loss: 0.004, episode: 174000
max accu: 0.282, episode: 230000

30.16 classifiers used
    accuracy, precision, recall, f_score
mv: 0.258373, 0.234791, 0.139937, 0.132190
wv: 0.244019, 0.233996, 0.166898, 0.161975
fs: 0.244019, 0.222392, 0.145233, 0.135950
rl: 0.282297, 0.259237, 0.145109, 0.140169

0.21093134646088343
0.19, 0.27, 0.24, 0.08, 0.19, 0.28, 0.25, 0.15, 0.20, 0.28, 0.24, 0.11, 0.18, 0.26, 0.22, 0.13, 0.20, 0.27, 0.23, 0.09, 0.18, 0.28, 0.23, 0.09, 0.21, 0.27, 0.22, 0.12, 0.20, 0.28, 0.23, 0.10, 0.20, 0.28, 0.24, 0.19, 0.20, 0.26, 0.23, 0.18, 0.19, 0.28, 0.23, 0.08, 0.20, 0.27, 0.22, 0.14, 0.18, 0.27

0.21371671991480298
0.19, 0.28, 0.22, 0.08, 0.19, 0.29, 0.24, 0.15, 0.20, 0.28, 0.25, 0.12, 0.18, 0.27, 0.24, 0.14, 0.17, 0.28, 0.23, 0.10, 0.17, 0.28, 0.22, 0.10, 0.19, 0.27, 0.22, 0.13, 0.19, 0.28, 0.24, 0.10, 0.20, 0.29, 0.25, 0.19, 0.20, 0.28, 0.23, 0.19, 0.19, 0.29, 0.24, 0.08, 0.20, 0.28, 0.22, 0.15, 0.17, 0.28

0.1966028708133971
0.15, 0.26, 0.22, 0.06, 0.20, 0.25, 0.22, 0.13, 0.19, 0.26, 0.21, 0.12, 0.19, 0.26, 0.24, 0.12, 0.18, 0.25, 0.21, 0.07, 0.16, 0.24, 0.23, 0.09, 0.19, 0.26, 0.22, 0.10, 0.18, 0.25, 0.21, 0.10, 0.20, 0.27, 0.20, 0.20, 0.20, 0.24, 0.23, 0.17, 0.18, 0.24, 0.22, 0.06, 0.17, 0.25, 0.21, 0.13, 0.18, 0.22

0.201866028708134
0.19, 0.26, 0.23, 0.09, 0.19, 0.27, 0.23, 0.10, 0.22, 0.26, 0.24, 0.10, 0.18, 0.28, 0.24, 0.10, 0.15, 0.26, 0.24, 0.10, 0.18, 0.28, 0.22, 0.10, 0.17, 0.25, 0.24, 0.10, 0.19, 0.26, 0.23, 0.10, 0.17, 0.25, 0.20, 0.10, 0.19, 0.26, 0.26, 0.09, 0.19, 0.26, 0.23, 0.09, 0.19, 0.25, 0.27, 0.15, 0.19, 0.26

    accuracy, precision, recall, f_score
mv: 0.271930, 0.240205, 0.150637, 0.137108
wv: 0.239234, 0.214136, 0.166367, 0.139551
fs: 0.260766, 0.242360, 0.151530, 0.144858
rl: 0.287879, 0.262048, 0.160207, 0.149552

fs avg size: 7.33333, rl avg size: 21.39633
full test avg accu: 0.20128, test avg accu: 0.20163

training takes 19024.875 sec
