{'dataset': 'audiology', 'algorithm': 'ptdqn', 'num_clf': 50, 'num_training': 350000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 8768, 'portion': 0.5, 'sequential': False}
(226, 95)
reading data takes 6.302 sec
number of labels: 24

Running iteration 1 of 10 fold...
[18, 0, 19, 23, 2, 42, 5, 26, 33, 47]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.683168, 0.597398, 0.388393, 0.354958

    accuracy, precision, recall, f_score
max3: 0.745098, 0.644071, 0.583333, 0.540222

    accuracy, precision, recall, f_score
max1: 0.869565, 0.869565, 0.802083, 0.807143


min loss: 0.006, episode: 328000
max accu: 0.870, episode: 320000

10.91 classifiers used
    accuracy, precision, recall, f_score
mv: 0.869565, 0.913043, 0.906250, 0.915476
wv: 0.869565, 0.891304, 0.906250, 0.909226
fs: 0.869565, 0.856522, 0.802083, 0.800397
rl: 0.869565, 0.869565, 0.802083, 0.807143

0.4225742574257425
0.32, 0.32, 0.26, 0.33, 0.34, 0.32, 0.29, 0.33, 0.33, 0.39, 0.36, 0.20, 0.36, 0.32, 0.33, 0.30, 0.32, 0.56, 0.70, 0.58, 0.63, 0.55, 0.54, 0.67, 0.57, 0.53, 0.59, 0.61, 0.59, 0.63, 0.59, 0.52, 0.47, 0.55, 0.25, 0.35, 0.32, 0.39, 0.37, 0.37, 0.33, 0.36, 0.28, 0.36, 0.36, 0.37, 0.35, 0.30, 0.37, 0.41

0.43254901960784303
0.37, 0.37, 0.25, 0.33, 0.39, 0.39, 0.25, 0.25, 0.27, 0.39, 0.41, 0.21, 0.33, 0.35, 0.31, 0.35, 0.37, 0.62, 0.74, 0.60, 0.70, 0.58, 0.56, 0.74, 0.54, 0.50, 0.62, 0.60, 0.64, 0.62, 0.58, 0.52, 0.47, 0.60, 0.23, 0.37, 0.31, 0.39, 0.39, 0.37, 0.31, 0.37, 0.25, 0.39, 0.37, 0.39, 0.37, 0.27, 0.37, 0.43

0.42086956521739116
0.30, 0.30, 0.34, 0.30, 0.52, 0.39, 0.26, 0.39, 0.47, 0.39, 0.39, 0.34, 0.34, 0.17, 0.30, 0.39, 0.43, 0.52, 0.82, 0.73, 0.69, 0.52, 0.52, 0.69, 0.65, 0.56, 0.56, 0.78, 0.60, 0.73, 0.60, 0.56, 0.56, 0.56, 0.26, 0.26, 0.26, 0.30, 0.26, 0.26, 0.26, 0.26, 0.30, 0.21, 0.30, 0.26, 0.30, 0.26, 0.21, 0.21

0.5295652173913044
0.52, 0.52, 0.56, 0.43, 0.47, 0.39, 0.43, 0.52, 0.30, 0.52, 0.60, 0.52, 0.47, 0.47, 0.39, 0.34, 0.56, 0.73, 0.82, 0.82, 0.69, 0.91, 0.95, 0.73, 0.78, 0.91, 0.78, 0.78, 0.78, 0.69, 0.82, 0.78, 0.78, 0.86, 0.30, 0.30, 0.26, 0.34, 0.30, 0.30, 0.26, 0.34, 0.21, 0.21, 0.30, 0.21, 0.30, 0.30, 0.34, 0.34


Running iteration 2 of 10 fold...
[21, 0, 20, 32, 10]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.722772, 0.613531, 0.422336, 0.381179

    accuracy, precision, recall, f_score
max3: 0.725490, 0.610008, 0.465385, 0.447018

    accuracy, precision, recall, f_score
max1: 0.782609, 0.725052, 0.636364, 0.601088


min loss: 0.006, episode: 348000
max accu: 0.783, episode: 340000

28.09 classifiers used
    accuracy, precision, recall, f_score
mv: 0.826087, 0.745342, 0.681818, 0.653613
wv: 0.739130, 0.694203, 0.651515, 0.593388
fs: 0.739130, 0.667081, 0.545455, 0.498057
rl: 0.782609, 0.725052, 0.636364, 0.601088

0.4538613861386138
0.33, 0.34, 0.37, 0.32, 0.45, 0.40, 0.29, 0.39, 0.33, 0.44, 0.42, 0.41, 0.40, 0.32, 0.44, 0.40, 0.41, 0.62, 0.60, 0.60, 0.61, 0.66, 0.58, 0.56, 0.63, 0.56, 0.56, 0.62, 0.48, 0.54, 0.60, 0.64, 0.66, 0.64, 0.37, 0.37, 0.36, 0.35, 0.30, 0.35, 0.35, 0.39, 0.40, 0.37, 0.34, 0.38, 0.35, 0.37, 0.41, 0.34

0.472156862745098
0.39, 0.35, 0.39, 0.31, 0.39, 0.41, 0.31, 0.37, 0.35, 0.41, 0.49, 0.41, 0.37, 0.33, 0.45, 0.37, 0.50, 0.68, 0.62, 0.58, 0.56, 0.74, 0.66, 0.60, 0.64, 0.52, 0.60, 0.60, 0.49, 0.58, 0.68, 0.66, 0.70, 0.64, 0.43, 0.37, 0.39, 0.37, 0.39, 0.37, 0.39, 0.43, 0.43, 0.39, 0.35, 0.39, 0.37, 0.39, 0.45, 0.35

0.4365217391304348
0.43, 0.43, 0.39, 0.39, 0.47, 0.30, 0.52, 0.26, 0.47, 0.52, 0.47, 0.47, 0.52, 0.30, 0.39, 0.43, 0.34, 0.65, 0.69, 0.56, 0.69, 0.65, 0.65, 0.56, 0.56, 0.47, 0.56, 0.52, 0.39, 0.65, 0.65, 0.69, 0.56, 0.60, 0.34, 0.30, 0.26, 0.30, 0.21, 0.26, 0.26, 0.21, 0.34, 0.30, 0.30, 0.21, 0.26, 0.30, 0.34, 0.21

0.4808695652173913
0.52, 0.43, 0.30, 0.43, 0.39, 0.43, 0.47, 0.43, 0.39, 0.39, 0.43, 0.52, 0.26, 0.43, 0.43, 0.47, 0.43, 0.56, 0.65, 0.65, 0.65, 0.69, 0.65, 0.65, 0.65, 0.69, 0.73, 0.69, 0.60, 0.69, 0.65, 0.78, 0.73, 0.65, 0.30, 0.34, 0.39, 0.39, 0.26, 0.26, 0.26, 0.39, 0.39, 0.39, 0.34, 0.30, 0.34, 0.34, 0.34, 0.30


Running iteration 3 of 10 fold...
[27, 0, 8, 19]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.673267, 0.574225, 0.344697, 0.305519

    accuracy, precision, recall, f_score
max3: 0.686275, 0.612979, 0.427891, 0.371124

    accuracy, precision, recall, f_score
max1: 0.826087, 0.745411, 0.666667, 0.623056


min loss: 0.007, episode: 303000
max accu: 0.826, episode: 330000

24.30 classifiers used
    accuracy, precision, recall, f_score
mv: 0.739130, 0.684524, 0.533333, 0.466061
wv: 0.739130, 0.738406, 0.608333, 0.502165
fs: 0.739130, 0.689493, 0.541667, 0.445455
rl: 0.826087, 0.745411, 0.666667, 0.623056

0.4358415841584158
0.33, 0.42, 0.34, 0.33, 0.27, 0.35, 0.35, 0.35, 0.44, 0.36, 0.40, 0.36, 0.25, 0.38, 0.44, 0.33, 0.38, 0.64, 0.61, 0.59, 0.60, 0.62, 0.61, 0.63, 0.63, 0.51, 0.56, 0.65, 0.64, 0.63, 0.55, 0.62, 0.57, 0.64, 0.34, 0.32, 0.32, 0.34, 0.30, 0.29, 0.33, 0.38, 0.29, 0.36, 0.32, 0.25, 0.38, 0.29, 0.29, 0.33

0.44745098039215686
0.35, 0.47, 0.35, 0.37, 0.21, 0.35, 0.41, 0.37, 0.49, 0.39, 0.43, 0.41, 0.27, 0.39, 0.45, 0.37, 0.43, 0.62, 0.64, 0.60, 0.56, 0.64, 0.64, 0.62, 0.64, 0.50, 0.54, 0.64, 0.60, 0.62, 0.60, 0.62, 0.52, 0.70, 0.37, 0.31, 0.33, 0.35, 0.31, 0.29, 0.31, 0.39, 0.29, 0.37, 0.31, 0.27, 0.39, 0.37, 0.33, 0.35

0.46347826086956523
0.52, 0.39, 0.26, 0.34, 0.47, 0.21, 0.52, 0.21, 0.26, 0.30, 0.43, 0.47, 0.43, 0.43, 0.43, 0.52, 0.26, 0.73, 0.65, 0.52, 0.73, 0.60, 0.56, 0.69, 0.65, 0.56, 0.60, 0.73, 0.69, 0.69, 0.52, 0.78, 0.73, 0.65, 0.39, 0.30, 0.39, 0.30, 0.30, 0.34, 0.43, 0.34, 0.34, 0.34, 0.34, 0.30, 0.39, 0.17, 0.34, 0.39

0.5165217391304346
0.39, 0.47, 0.43, 0.34, 0.47, 0.39, 0.47, 0.21, 0.47, 0.39, 0.47, 0.43, 0.34, 0.39, 0.43, 0.34, 0.52, 0.82, 0.73, 0.82, 0.73, 0.82, 0.86, 0.73, 0.78, 0.73, 0.86, 0.73, 0.78, 0.86, 0.78, 0.78, 0.73, 0.69, 0.34, 0.17, 0.34, 0.39, 0.34, 0.39, 0.39, 0.17, 0.43, 0.34, 0.34, 0.39, 0.34, 0.39, 0.13, 0.47


Running iteration 4 of 10 fold...
[24, 0, 21, 30, 33, 20, 2, 18, 34]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.653465, 0.634520, 0.418869, 0.318492

    accuracy, precision, recall, f_score
max3: 0.647059, 0.566633, 0.436355, 0.351900

    accuracy, precision, recall, f_score
max1: 0.739130, 0.797101, 0.656250, 0.640476


min loss: 0.007, episode: 302000
max accu: 0.739, episode: 300000

30.65 classifiers used
    accuracy, precision, recall, f_score
mv: 0.739130, 0.808696, 0.625000, 0.635417
wv: 0.826087, 0.759834, 0.729167, 0.657051
fs: 0.739130, 0.818841, 0.656250, 0.575661
rl: 0.739130, 0.797101, 0.656250, 0.640476

0.4116831683168317
0.25, 0.34, 0.33, 0.28, 0.27, 0.34, 0.37, 0.32, 0.34, 0.34, 0.26, 0.27, 0.31, 0.28, 0.31, 0.27, 0.33, 0.56, 0.60, 0.58, 0.65, 0.63, 0.65, 0.54, 0.70, 0.63, 0.61, 0.64, 0.64, 0.54, 0.64, 0.55, 0.61, 0.66, 0.32, 0.29, 0.35, 0.24, 0.26, 0.27, 0.32, 0.30, 0.27, 0.27, 0.30, 0.31, 0.26, 0.31, 0.27, 0.31

0.4098039215686273
0.19, 0.35, 0.31, 0.27, 0.29, 0.35, 0.39, 0.31, 0.31, 0.37, 0.31, 0.25, 0.29, 0.27, 0.33, 0.27, 0.31, 0.54, 0.64, 0.56, 0.66, 0.62, 0.68, 0.54, 0.70, 0.66, 0.62, 0.62, 0.64, 0.50, 0.68, 0.49, 0.62, 0.66, 0.33, 0.27, 0.35, 0.29, 0.25, 0.27, 0.33, 0.31, 0.27, 0.25, 0.31, 0.31, 0.25, 0.31, 0.27, 0.27

0.5156521739130435
0.52, 0.56, 0.43, 0.56, 0.52, 0.65, 0.47, 0.47, 0.56, 0.65, 0.56, 0.34, 0.39, 0.69, 0.47, 0.60, 0.47, 0.65, 0.73, 0.65, 0.60, 0.65, 0.60, 0.65, 0.69, 0.69, 0.69, 0.65, 0.60, 0.56, 0.65, 0.60, 0.56, 0.69, 0.43, 0.39, 0.43, 0.26, 0.26, 0.30, 0.34, 0.34, 0.34, 0.30, 0.34, 0.39, 0.21, 0.43, 0.47, 0.47

0.5582608695652174
0.56, 0.60, 0.47, 0.60, 0.56, 0.43, 0.56, 0.56, 0.47, 0.65, 0.52, 0.56, 0.60, 0.52, 0.60, 0.69, 0.69, 0.65, 0.69, 0.60, 0.60, 0.69, 0.73, 0.69, 0.69, 0.65, 0.69, 0.73, 0.69, 0.69, 0.73, 0.56, 0.69, 0.65, 0.39, 0.47, 0.43, 0.43, 0.39, 0.47, 0.39, 0.43, 0.43, 0.34, 0.47, 0.43, 0.43, 0.26, 0.43, 0.39

    accuracy, precision, recall, f_score
mv: 0.793478, 0.787901, 0.686600, 0.667642
wv: 0.793478, 0.770937, 0.723816, 0.665458
fs: 0.771739, 0.757984, 0.636364, 0.579893
rl: 0.804348, 0.784282, 0.690341, 0.667941

fs avg size: 7.00000, rl avg size: 23.48913
full test avg accu: 0.52130, test avg accu: 0.45913

training takes 7058.344 sec
