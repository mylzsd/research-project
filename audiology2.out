{'dataset': 'audiology', 'algorithm': 'ptdqn', 'num_clf': 20, 'num_training': 50000, 'learning_rate': 0.01, 'discount_factor': 1, 'epsilon': 0.1, 'random_state': 1617, 'portion': 0.5, 'sequential': False}
(226, 95)
Running iteration 1 of 10 fold...

epoch: 999 row: 90 exploration: 0.10000
	 ['V4', 'E'] 

	sample size: 2

	s : N N N N N N N N N N N N N N N N N N N N -> action:  V4
	s': N N N N 6 N N N N N N N N N N N N N N N -> reward:  0.0

	s : N N N N 6 N N N N N N N N N N N N N N N -> action:  E
	s': None -> reward:  1.0

finished epoch 1000
average loss: 0.14210608284850604

epoch: 1999 row: 80 exploration: 0.10000
	 ['V13', 'V4', 'E'] 

	sample size: 2

	s : N N N N N N N N N N N N N 5 N N N N N N -> action:  V4
	s': N N N N 5 N N N N N N N N 5 N N N N N N -> reward:  0.0

	s : N N N N 5 N N N N N N N N 5 N N N N N N -> action:  E
	s': None -> reward:  1.0

finished epoch 2000
average loss: 0.11879826012253761

epoch: 2999 row: 70 exploration: 0.10000
	 ['V17', 'V4', 'E'] 

	sample size: 2

	s : N N N N N N N N N N N N N N N N N 2 N N -> action:  V4
	s': N N N N 2 N N N N N N N N N N N N 2 N N -> reward:  0.0

	s : N N N N 2 N N N N N N N N N N N N 2 N N -> action:  E
	s': None -> reward:  1.0

finished epoch 3000
average loss: 0.11147448968204117

epoch: 3999 row: 60 exploration: 0.10000
	 ['V4', 'E'] 

	sample size: 2

	s : N N N N N N N N N N N N N N N N N N N N -> action:  V4
	s': N N N N 6 N N N N N N N N N N N N N N N -> reward:  0.0

	s : N N N N 6 N N N N N N N N N N N N N N N -> action:  E
	s': None -> reward:  1.0

finished epoch 4000
average loss: 0.10674593515440937

epoch: 4999 row: 50 exploration: 0.10000
	 ['V4', 'V2', 'E'] 

	sample size: 2

	s : N N N N 0 N N N N N N N N N N N N N N N -> action:  V2
	s': N N 6 N 0 N N N N N N N N N N N N N N N -> reward:  0.0

	s : N N 6 N 0 N N N N N N N N N N N N N N N -> action:  E
	s': None -> reward:  0.0

finished epoch 5000
average loss: 0.09921216394238945

epoch: 5999 row: 40 exploration: 0.10000
	 ['V5', 'V2', 'V19', 'V8', 'V4', 'V18', 'V7', 'V9', 'V6', 'V10', 'V11', 'V13', 'V0', 'V3', 'V12', 'V17', 'V1', 'V14', 'V16', 'E'] 

	sample size: 5

	s : 18 N 5 5 5 5 2 5 5 5 5 18 5 5 N N N 2 16 5 -> action:  V1
	s': 18 5 5 5 5 5 2 5 5 5 5 18 5 5 N N N 2 16 5 -> reward:  0.0

	s : 18 5 5 5 5 5 2 5 5 5 5 18 5 5 N N N 2 16 5 -> action:  V14
	s': 18 5 5 5 5 5 2 5 5 5 5 18 5 5 5 N N 2 16 5 -> reward:  0.0

	s : N N 5 N 5 5 N 5 5 5 N N N N N N N N 16 5 -> action:  V6
	s': N N 5 N 5 5 2 5 5 5 N N N N N N N N 16 5 -> reward:  0.0

	s : N N 5 N 5 5 N N 5 N N N N N N N N N 16 5 -> action:  V7
	s': N N 5 N 5 5 N 5 5 N N N N N N N N N 16 5 -> reward:  0.0

	s : 18 5 5 5 5 5 2 5 5 5 5 18 5 5 5 N 5 2 16 5 -> action:  E
	s': None -> reward:  1.0

finished epoch 6000
average loss: 0.035493125595134185

epoch: 6999 row: 30 exploration: 0.10000
	 ['V5', 'V8', 'V2', 'V13', 'V4', 'V11', 'V10', 'V9', 'V18', 'V0', 'V6', 'V12', 'V14', 'V17', 'V3', 'V19', 'V1', 'E'] 

	sample size: 5

	s : N N 0 N 0 6 N N 0 0 4 0 N 0 N N N N N N -> action:  V18
	s': N N 0 N 0 6 N N 0 0 4 0 N 0 N N N N 0 N -> reward:  0.0

	s : N N N N N 6 N N 0 N N N N N N N N N N N -> action:  V2
	s': N N 0 N N 6 N N 0 N N N N N N N N N N N -> reward:  0.0

	s : N N N N N N N N N N N N N N N N N N N N -> action:  V5
	s': N N N N N 6 N N N N N N N N N N N N N N -> reward:  0.0

	s : 6 N 0 0 0 6 0 N 0 0 4 0 0 0 0 N N 0 0 N -> action:  V19
	s': 6 N 0 0 0 6 0 N 0 0 4 0 0 0 0 N N 0 0 0 -> reward:  0.0

	s : 6 0 0 0 0 6 0 N 0 0 4 0 0 0 0 N N 0 0 0 -> action:  E
	s': None -> reward:  1.0

finished epoch 7000
average loss: 0.01648222630237433

epoch: 7999 row: 20 exploration: 0.10000
	 ['V5', 'V8', 'V16', 'V4', 'V13', 'V18', 'V2', 'V11', 'V17', 'V0', 'V10', 'V9', 'V7', 'V15', 'V12', 'V19', 'V1', 'V3', 'V14', 'V6', 'E'] 

	sample size: 6

	s : N N 4 N 4 4 N N 4 N N N N 4 N N 4 N 0 N -> action:  V11
	s': N N 4 N 4 4 N N 4 N N 0 N 4 N N 4 N 0 N -> reward:  0.0

	s : N N 4 N 4 4 N N 4 N N 0 N 4 N N 4 N 0 N -> action:  V17
	s': N N 4 N 4 4 N N 4 N N 0 N 4 N N 4 6 0 N -> reward:  0.0

	s : 4 N 4 N 4 4 N 0 4 0 0 0 N 4 N N 4 6 0 N -> action:  V15
	s': 4 N 4 N 4 4 N 0 4 0 0 0 N 4 N 4 4 6 0 N -> reward:  0.0

	s : N N N N 4 4 N N 4 N N N N 4 N N 4 N N N -> action:  V18
	s': N N N N 4 4 N N 4 N N N N 4 N N 4 N 0 N -> reward:  0.0

	s : N N N N 4 4 N N 4 N N N N N N N 4 N N N -> action:  V13
	s': N N N N 4 4 N N 4 N N N N 4 N N 4 N N N -> reward:  0.0

	s : 4 0 4 4 4 4 4 0 4 0 0 0 4 4 4 4 4 6 0 0 -> action:  E
	s': None -> reward:  1.0

finished epoch 8000
average loss: 0.018814539155355307

epoch: 8999 row: 10 exploration: 0.10000
	 ['V5', 'V10', 'V11', 'V8', 'V0', 'V4', 'V13', 'V9', 'V19', 'V18', 'V2', 'V3', 'V14', 'V6', 'V16', 'V15', 'V1', 'V7', 'V17', 'V12', 'E'] 

	sample size: 6

	s : 4 0 4 4 4 4 4 N 4 0 0 0 N 4 4 4 4 N 0 0 -> action:  V7
	s': 4 0 4 4 4 4 4 0 4 0 0 0 N 4 4 4 4 N 0 0 -> reward:  0.0

	s : 4 N N N 4 4 N N 4 0 0 0 N 4 N N N N 0 0 -> action:  V2
	s': 4 N 4 N 4 4 N N 4 0 0 0 N 4 N N N N 0 0 -> reward:  0.0

	s : N N N N N 4 N N 4 N 0 0 N N N N N N N N -> action:  V0
	s': 4 N N N N 4 N N 4 N 0 0 N N N N N N N N -> reward:  0.0

	s : 4 N 4 4 4 4 4 N 4 0 0 0 N 4 4 N 4 N 0 0 -> action:  V15
	s': 4 N 4 4 4 4 4 N 4 0 0 0 N 4 4 4 4 N 0 0 -> reward:  0.0

	s : N N N N N 4 N N N N N N N N N N N N N N -> action:  V10
	s': N N N N N 4 N N N N 0 N N N N N N N N N -> reward:  0.0

	s : 4 0 4 4 4 4 4 0 4 0 0 0 4 4 4 4 4 6 0 0 -> action:  E
	s': None -> reward:  1.0

finished epoch 9000
average loss: 0.0186046950255477

epoch: 9999 row: 0 exploration: 0.10000
	 ['V8', 'V9', 'V11', 'V10', 'V5', 'V18', 'V4', 'V6', 'V2', 'V13', 'V3', 'V0', 'V19', 'V12', 'V15', 'V14', 'V17', 'V16', 'E'] 

	sample size: 5

	s : N N 0 N 0 0 0 N 0 0 0 14 N N N N N N 0 N -> action:  V13
	s': N N 0 N 0 0 0 N 0 0 0 14 N 0 N N N N 0 N -> reward:  0.0

	s : N N N N N N N N N N N N N N N N N N N N -> action:  V8
	s': N N N N N N N N 0 N N N N N N N N N N N -> reward:  0.0

	s : N N 0 0 0 0 0 N 0 0 0 14 N 0 N N N N 0 N -> action:  V0
	s': 0 N 0 0 0 0 0 N 0 0 0 14 N 0 N N N N 0 N -> reward:  0.0

	s : 0 N 0 0 0 0 0 N 0 0 0 14 N 0 N N N N 0 N -> action:  V19
	s': 0 N 0 0 0 0 0 N 0 0 0 14 N 0 N N N N 0 0 -> reward:  0.0

	s : 0 N 0 0 0 0 0 N 0 0 0 14 0 0 6 0 3 0 0 0 -> action:  E
	s': None -> reward:  1.0

finished epoch 10000
average loss: 0.021818409232131672

epoch: 10999 row: 91 exploration: 0.10000
	 ['V4', 'V0', 'V9', 'V12', 'V5', 'V11', 'V8', 'V7', 'V13', 'V2', 'V18', 'V3', 'V10', 'V14', 'V19', 'V1', 'V6', 'V16', 'E'] 

	sample size: 5

	s : 6 N N N 6 6 N N N 6 N 6 6 N N N N N N N -> action:  V8
	s': 6 N N N 6 6 N N 6 6 N 6 6 N N N N N N N -> reward:  0.0

	s : 6 6 6 3 6 6 N 6 6 6 19 6 6 6 6 N N N 0 6 -> action:  V6
	s': 6 6 6 3 6 6 6 6 6 6 19 6 6 6 6 N N N 0 6 -> reward:  0.0

	s : 6 6 6 3 6 6 6 6 6 6 19 6 6 6 6 N N N 0 6 -> action:  V16
	s': 6 6 6 3 6 6 6 6 6 6 19 6 6 6 6 N 6 N 0 6 -> reward:  0.0

	s : 6 N N N 6 N N N N 6 N N N N N N N N N N -> action:  V12
	s': 6 N N N 6 N N N N 6 N N 6 N N N N N N N -> reward:  0.0

	s : 6 6 6 3 6 6 6 6 6 6 19 6 6 6 6 N 6 N 0 6 -> action:  E
	s': None -> reward:  1.0

finished epoch 11000
average loss: 0.02353370863982127

epoch: 11999 row: 81 exploration: 0.10000
	 ['V7', 'V5', 'V9', 'V0', 'V4', 'E'] 

	sample size: 3

	s : N N N N N N N N N N N N N N N N N N N N -> action:  V7
	s': N N N N N N N 5 N N N N N N N N N N N N -> reward:  0.0

	s : 16 N N N N 16 N 5 N 2 N N N N N N N N N N -> action:  V4
	s': 16 N N N 20 16 N 5 N 2 N N N N N N N N N N -> reward:  0.0

	s : 16 N N N 20 16 N 5 N 2 N N N N N N N N N N -> action:  E
	s': None -> reward:  0.0

finished epoch 12000
average loss: 0.03204076297559004

epoch: 12999 row: 71 exploration: 0.10000
	 ['V8', 'V5', 'V4', 'V18', 'V13', 'V7', 'V3', 'V0', 'V11', 'V9', 'V15', 'V19', 'V6', 'V10', 'V12', 'E'] 

	sample size: 5

	s : N N N N N 5 N N 5 N N N N N N N N N N N -> action:  V4
	s': N N N N 5 5 N N 5 N N N N N N N N N N N -> reward:  0.0

	s : N N N N 5 5 N N 5 N N N N N N N N N N N -> action:  V18
	s': N N N N 5 5 N N 5 N N N N N N N N N 5 N -> reward:  0.0

	s : 5 N N 5 5 5 N 5 5 5 N 5 N 5 N 5 N N 5 5 -> action:  V6
	s': 5 N N 5 5 5 5 5 5 5 N 5 N 5 N 5 N N 5 5 -> reward:  0.0

	s : N N N N N N N N N N N N N N N N N N N N -> action:  V8
	s': N N N N N N N N 5 N N N N N N N N N N N -> reward:  0.0

	s : 5 N N 5 5 5 5 5 5 5 5 5 5 5 N 5 N N 5 5 -> action:  E
	s': None -> reward:  1.0

finished epoch 13000
average loss: 0.02631608234595842

epoch: 13999 row: 61 exploration: 0.10000
	 ['V8', 'V5', 'E'] 

	sample size: 2

	s : N N N N N N N N N N N N N N N N N N N N -> action:  V8
	s': N N N N N N N N 5 N N N N N N N N N N N -> reward:  0.0

	s : N N N N N 2 N N 5 N N N N N N N N N N N -> action:  E
	s': None -> reward:  1.0

finished epoch 14000
average loss: 0.0305340291144239

epoch: 14999 row: 51 exploration: 0.10000
	 ['V5', 'V8', 'V13', 'V4', 'V16', 'V9', 'V19', 'V15', 'V3', 'V11', 'V0', 'V7', 'V2', 'V18', 'V6', 'V12', 'V10', 'V1', 'E'] 

	sample size: 5

	s : N N N N 0 3 N N 3 N N N N 3 N N 3 N N N -> action:  V9
	s': N N N N 0 3 N N 3 3 N N N 3 N N 3 N N N -> reward:  0.0

	s : 3 N 3 3 0 3 3 3 3 3 1 3 11 3 N 3 3 N 11 3 -> action:  V1
	s': 3 3 3 3 0 3 3 3 3 3 1 3 11 3 N 3 3 N 11 3 -> reward:  0.0

	s : 3 N 3 3 0 3 N 3 3 3 N 3 N 3 N 3 3 N 11 3 -> action:  V6
	s': 3 N 3 3 0 3 3 3 3 3 N 3 N 3 N 3 3 N 11 3 -> reward:  0.0

	s : 3 N 3 3 0 3 N 3 3 3 N 3 N 3 N 3 3 N N 3 -> action:  V18
	s': 3 N 3 3 0 3 N 3 3 3 N 3 N 3 N 3 3 N 11 3 -> reward:  0.0

	s : 3 3 3 3 0 3 3 3 3 3 1 3 11 3 N 3 3 N 11 3 -> action:  E
	s': None -> reward:  1.0

finished epoch 15000
average loss: 0.031067730138809566

epoch: 15999 row: 41 exploration: 0.10000
	 ['V5', 'E'] 

	sample size: 2

	s : N N N N N N N N N N N N N N N N N N N N -> action:  V5
	s': N N N N N 5 N N N N N N N N N N N N N N -> reward:  0.0

	s : N N N N N 5 N N N N N N N N N N N N N N -> action:  E
	s': None -> reward:  1.0

finished epoch 16000
average loss: 0.01985526806384587

epoch: 16999 row: 31 exploration: 0.10000
	 ['V4', 'V5', 'V9', 'V15', 'V8', 'V0', 'V16', 'V3', 'V18', 'V19', 'V11', 'V2', 'V12', 'V6', 'V1', 'E'] 

	sample size: 5

	s : N N N N N N N N N N N N N N N N N N N N -> action:  V4
	s': N N N N 0 N N N N N N N N N N N N N N N -> reward:  0.0

	s : 12 N N 11 0 11 N N 1 11 N N N N N 1 1 N 11 3 -> action:  V11
	s': 12 N N 11 0 11 N N 1 11 N 1 N N N 1 1 N 11 3 -> reward:  0.0

	s : 12 N N 11 0 11 N N 1 11 N N N N N 1 1 N 11 N -> action:  V19
	s': 12 N N 11 0 11 N N 1 11 N N N N N 1 1 N 11 3 -> reward:  0.0

	s : N N N N N N N N N N N N N N N N N N N N -> action:  V4
	s': N N N N 0 N N N N N N N N N N N N N N N -> reward:  0.0

	s : 12 1 3 11 0 11 13 N 1 11 N 1 1 N N 1 1 N 11 3 -> action:  E
	s': None -> reward:  1.0

finished epoch 17000
average loss: 0.026948939190773673

epoch: 17999 row: 21 exploration: 0.10000
	 ['V15', 'V4', 'V5', 'V8', 'V16', 'V18', 'V9', 'V2', 'V0', 'V3', 'V13', 'V19', 'V17', 'V11', 'V10', 'V7', 'V12', 'V6', 'V14', 'E'] 

	sample size: 5

	s : N N N N N N N N N N N N N N N 1 N N N N -> action:  V4
	s': N N N N 0 N N N N N N N N N N 1 N N N N -> reward:  0.0

	s : N N N N 0 11 N N 1 N N N N N N 1 1 N N N -> action:  V18
	s': N N N N 0 11 N N 1 N N N N N N 1 1 N 11 N -> reward:  0.0

	s : 12 N 3 11 0 11 N N 1 11 N N N 13 N 1 1 N 11 N -> action:  V19
	s': 12 N 3 11 0 11 N N 1 11 N N N 13 N 1 1 N 11 3 -> reward:  0.0

	s : N N N N 0 N N N N N N N N N N 1 N N N N -> action:  V5
	s': N N N N 0 11 N N N N N N N N N 1 N N N N -> reward:  0.0

	s : 12 N 3 11 0 11 13 1 1 11 1 1 1 13 11 1 1 3 11 3 -> action:  E
	s': None -> reward:  1.0

finished epoch 18000
average loss: 0.023431700645924137

epoch: 18999 row: 11 exploration: 0.10000
	 ['V15', 'V12', 'V4', 'V9', 'V5', 'V10', 'V13', 'V8', 'V0', 'V6', 'V19', 'V18', 'V2', 'E'] 

	sample size: 4

	s : N N N N 4 4 N N N 0 N N 4 N N 4 N N N N -> action:  V10
	s': N N N N 4 4 N N N 0 0 N 4 N N 4 N N N N -> reward:  0.0

	s : N N N N N N N N N N N N N N N 4 N N N N -> action:  V12
	s': N N N N N N N N N N N N 4 N N 4 N N N N -> reward:  0.0

	s : N N N N N N N N N N N N N N N 4 N N N N -> action:  V12
	s': N N N N N N N N N N N N 4 N N 4 N N N N -> reward:  0.0

	s : 19 N 4 N 4 4 4 N 4 0 0 N 4 4 N 4 N N 0 4 -> action:  E
	s': None -> reward:  0.0

finished epoch 19000
average loss: 0.026487653640413555

epoch: 19999 row: 1 exploration: 0.10000
	 ['V9', 'V4', 'V7', 'V11', 'V15', 'V5', 'V17', 'V8', 'V14', 'V10', 'V3', 'V13', 'V16', 'V0', 'V19', 'V12', 'V18', 'V2', 'V6', 'V1', 'E'] 

	sample size: 6

	s : 1 N 3 11 1 11 N 1 1 11 1 1 1 13 13 1 12 12 11 1 -> action:  V6
	s': 1 N 3 11 1 11 13 1 1 11 1 1 1 13 13 1 12 12 11 1 -> reward:  0.0

	s : N N N N 1 N N 1 N 11 N 1 N N N 1 N N N N -> action:  V5
	s': N N N N 1 11 N 1 N 11 N 1 N N N 1 N N N N -> reward:  0.0

	s : N N N N 1 N N 1 N 11 N 1 N N N N N N N N -> action:  V15
	s': N N N N 1 N N 1 N 11 N 1 N N N 1 N N N N -> reward:  0.0

	s : 1 N 3 11 1 11 13 1 1 11 1 1 1 13 13 1 12 12 11 1 -> action:  V1
	s': 1 1 3 11 1 11 13 1 1 11 1 1 1 13 13 1 12 12 11 1 -> reward:  0.0

	s : 1 N N 11 1 11 N 1 1 11 1 1 1 13 13 1 12 12 11 1 -> action:  V2
	s': 1 N 3 11 1 11 N 1 1 11 1 1 1 13 13 1 12 12 11 1 -> reward:  0.0

	s : 1 1 3 11 1 11 13 1 1 11 1 1 1 13 13 1 12 12 11 1 -> action:  E
	s': None -> reward:  1.0

finished epoch 20000
average loss: 0.019989619094340015

epoch: 20999 row: 92 exploration: 0.10000
	 ['V9', 'V4', 'V15', 'V8', 'V17', 'V5', 'V2', 'V13', 'V18', 'V0', 'V3', 'V19', 'V16', 'V10', 'V12', 'V6', 'V11', 'V7', 'V1', 'V14', 'E'] 

	sample size: 6

	s : 9 N 9 9 9 6 N N 9 0 9 N N 0 N 9 9 9 0 9 -> action:  V12
	s': 9 N 9 9 9 6 N N 9 0 9 N 9 0 N 9 9 9 0 9 -> reward:  0.0

	s : N N N N N N N N N 0 N N N N N N N N N N -> action:  V4
	s': N N N N 9 N N N N 0 N N N N N N N N N N -> reward:  0.0

	s : N N N N 9 N N N 9 0 N N N N N 9 N N N N -> action:  V17
	s': N N N N 9 N N N 9 0 N N N N N 9 N 9 N N -> reward:  0.0

	s : 9 N 9 9 9 6 N N 9 0 N N N 0 N 9 N 9 0 N -> action:  V19
	s': 9 N 9 9 9 6 N N 9 0 N N N 0 N 9 N 9 0 9 -> reward:  0.0

	s : N N N N 9 6 N N 9 0 N N N N N 9 N 9 N N -> action:  V2
	s': N N 9 N 9 6 N N 9 0 N N N N N 9 N 9 N N -> reward:  0.0

	s : 9 9 9 9 9 6 9 9 9 0 9 9 9 0 9 9 9 9 0 9 -> action:  E
	s': None -> reward:  1.0

finished epoch 21000
average loss: 0.03000487028877251

epoch: 21999 row: 82 exploration: 0.10000
	 ['V15', 'V4', 'V9', 'V8', 'V5', 'V10', 'V3', 'V2', 'V0', 'E'] 

	sample size: 3

	s : N N N N 2 2 N N 5 5 N N N N N 5 N N N N -> action:  V10
	s': N N N N 2 2 N N 5 5 2 N N N N 5 N N N N -> reward:  0.0

	s : N N N N 2 2 N N 5 5 2 N N N N 5 N N N N -> action:  V3
	s': N N N 2 2 2 N N 5 5 2 N N N N 5 N N N N -> reward:  0.0

	s : 5 N 2 2 2 2 N N 5 5 2 N N N N 5 N N N N -> action:  E
	s': None -> reward:  0.0

finished epoch 22000
average loss: 0.03396707900593174

epoch: 22999 row: 72 exploration: 0.10000
	 ['V4', 'V15', 'V9', 'E'] 

	sample size: 2

	s : N N N N 5 N N N N N N N N N N 20 N N N N -> action:  V9
	s': N N N N 5 N N N N 2 N N N N N 20 N N N N -> reward:  0.0

	s : N N N N 5 N N N N 2 N N N N N 20 N N N N -> action:  E
	s': None -> reward:  1.0

finished epoch 23000
average loss: 0.03526891209667156

epoch: 23999 row: 62 exploration: 0.10000
	 ['V15', 'V5', 'V4', 'V9', 'V8', 'V3', 'V11', 'V14', 'V7', 'V12', 'V0', 'V17', 'V2', 'V10', 'E'] 

	sample size: 4

	s : N N N N 5 5 N N 5 5 N N N N N 5 N N N N -> action:  V3
	s': N N N 5 5 5 N N 5 5 N N N N N 5 N N N N -> reward:  0.0

	s : 5 N N 5 5 5 N 5 5 5 N 5 5 N 5 5 N N N N -> action:  V17
	s': 5 N N 5 5 5 N 5 5 5 N 5 5 N 5 5 N 5 N N -> reward:  0.0

	s : N N N N 5 5 N N N N N N N N N 5 N N N N -> action:  V9
	s': N N N N 5 5 N N N 5 N N N N N 5 N N N N -> reward:  0.0

	s : 5 N 5 5 5 5 N 5 5 5 5 5 5 N 5 5 N 5 N N -> action:  E
	s': None -> reward:  1.0

finished epoch 24000
average loss: 0.03719194854781108

epoch: 24999 row: 52 exploration: 0.10000
	 ['V4', 'E'] 

	sample size: 2

	s : N N N N N N N N N N N N N N N N N N N N -> action:  V4
	s': N N N N 20 N N N N N N N N N N N N N N N -> reward:  0.0

	s : N N N N 20 N N N N N N N N N N N N N N N -> action:  E
	s': None -> reward:  0.0

finished epoch 25000
average loss: 0.03547063699542923

epoch: 25999 row: 42 exploration: 0.10000
	 ['V15', 'V4', 'V3', 'V5', 'V9', 'V11', 'V8', 'E'] 

	sample size: 3

	s : N N N N 10 N N N N N N N N N N 10 N N N N -> action:  V3
	s': N N N 10 10 N N N N N N N N N N 10 N N N N -> reward:  0.0

	s : N N N N N N N N N N N N N N N N N N N N -> action:  V15
	s': N N N N N N N N N N N N N N N 10 N N N N -> reward:  0.0

	s : N N N 10 10 0 N N 0 11 N 13 N N N 10 N N N N -> action:  E
	s': None -> reward:  1.0

finished epoch 26000
average loss: 0.031104228785393387

epoch: 26999 row: 32 exploration: 0.10000
	 ['V15', 'V19', 'V4', 'V3', 'V11', 'V5', 'V17', 'V12', 'V18', 'V16', 'V8', 'V9', 'V1', 'V10', 'V6', 'V7', 'V13', 'V2', 'V14', 'E'] 

	sample size: 5

	s : N N N 4 4 4 N N 4 N N 15 4 N N 4 4 4 15 4 -> action:  V9
	s': N N N 4 4 4 N N 4 0 N 15 4 N N 4 4 4 15 4 -> reward:  0.0

	s : N N N 4 4 N N N N N N 15 N N N 4 N N N 4 -> action:  V5
	s': N N N 4 4 4 N N N N N 15 N N N 4 N N N 4 -> reward:  0.0

	s : N N N 4 4 N N N N N N 15 N N N 4 N N N 4 -> action:  V5
	s': N N N 4 4 4 N N N N N 15 N N N 4 N N N 4 -> reward:  0.0

	s : N N N N N N N N N N N N N N N N N N N N -> action:  V15
	s': N N N N N N N N N N N N N N N 4 N N N N -> reward:  0.0

	s : N 4 4 4 4 4 4 4 4 0 4 15 4 4 14 4 4 4 15 4 -> action:  E
	s': None -> reward:  1.0

finished epoch 27000
average loss: 0.02323913509403792

epoch: 27999 row: 22 exploration: 0.10000
	 ['V15', 'V4', 'V19', 'V2', 'V9', 'V3', 'V5', 'V11', 'E'] 

	sample size: 3

	s : N N 5 5 5 N N N N 5 N N N N N 5 N N N 5 -> action:  V5
	s': N N 5 5 5 5 N N N 5 N N N N N 5 N N N 5 -> reward:  0.0

	s : N N 5 N 5 N N N N N N N N N N 5 N N N 5 -> action:  V9
	s': N N 5 N 5 N N N N 5 N N N N N 5 N N N 5 -> reward:  0.0

	s : N N 5 5 5 5 N N N 5 N 5 N N N 5 N N N 5 -> action:  E
	s': None -> reward:  1.0

finished epoch 28000
average loss: 0.023201000040853615

epoch: 28999 row: 12 exploration: 0.10000
	 ['V11', 'V10', 'V7', 'V15', 'E'] 

	sample size: 2

	s : N N N N N N N N N N N N N N N N N N N N -> action:  V11
	s': N N N N N N N N N N N 16 N N N N N N N N -> reward:  0.0

	s : N N N N N N N 5 N N 16 16 N N N 20 N N N N -> action:  E
	s': None -> reward:  0.0

finished epoch 29000
average loss: 0.030975642505228735

epoch: 29999 row: 2 exploration: 0.10000
	 ['V11', 'V10', 'V7', 'V18', 'V13', 'V16', 'V14', 'E'] 

	sample size: 3

	s : N N N N N N N 6 N N 6 4 N N N N N N N N -> action:  V18
	s': N N N N N N N 6 N N 6 4 N N N N N N 6 N -> reward:  0.0

	s : N N N N N N N N N N N N N N N N N N N N -> action:  V11
	s': N N N N N N N N N N N 4 N N N N N N N N -> reward:  0.0

	s : N N N N N N N 6 N N 6 4 N 6 6 N 6 N 6 N -> action:  E
	s': None -> reward:  0.0

finished epoch 30000
average loss: 0.029269978569132944

epoch: 30999 row: 93 exploration: 0.10000
	 ['V11', 'V16', 'V1', 'V10', 'V15', 'V18', 'V13', 'E'] 

	sample size: 3

	s : N 0 N N N N N N N N 0 0 N N N 4 4 N N N -> action:  V18
	s': N 0 N N N N N N N N 0 0 N N N 4 4 N 0 N -> reward:  0.0

	s : N 0 N N N N N N N N N 0 N N N N 4 N N N -> action:  V10
	s': N 0 N N N N N N N N 0 0 N N N N 4 N N N -> reward:  0.0

	s : N 0 N N N N N N N N 0 0 N 0 N 4 4 N 0 N -> action:  E
	s': None -> reward:  1.0

finished epoch 31000
average loss: 0.030254782500654984

epoch: 31999 row: 83 exploration: 0.10000
	 ['V11', 'V15', 'V4', 'V17', 'V13', 'V9', 'V19', 'V5', 'E'] 

	sample size: 3

	s : N N N N 5 N N N N N N 5 N N N 5 N 5 N N -> action:  V13
	s': N N N N 5 N N N N N N 5 N 5 N 5 N 5 N N -> reward:  0.0

	s : N N N N 5 N N N N N N 5 N N N 5 N N N N -> action:  V17
	s': N N N N 5 N N N N N N 5 N N N 5 N 5 N N -> reward:  0.0

	s : N N N N 5 5 N N N 5 N 5 N 5 N 5 N 5 N 5 -> action:  E
	s': None -> reward:  1.0

finished epoch 32000
average loss: 0.027923259683966535

epoch: 32999 row: 73 exploration: 0.10000
	 ['V11', 'V19', 'V16', 'V13', 'V3', 'V15', 'V4', 'V6', 'V2', 'V12', 'V7', 'V18', 'V17', 'V9', 'V1', 'V14', 'V0', 'V5', 'V8', 'V10', 'E'] 

	sample size: 6

	s : N N 3 3 0 N 3 11 N N N 3 11 22 N 3 1 N 11 3 -> action:  V17
	s': N N 3 3 0 N 3 11 N N N 3 11 22 N 3 1 3 11 3 -> reward:  0.0

	s : N N 3 3 0 N 3 11 N 11 N 3 11 22 N 3 1 3 11 3 -> action:  V1
	s': N 3 3 3 0 N 3 11 N 11 N 3 11 22 N 3 1 3 11 3 -> reward:  0.0

	s : N N N N N N N N N N N 3 N N N N 1 N N 3 -> action:  V13
	s': N N N N N N N N N N N 3 N 22 N N 1 N N 3 -> reward:  0.0

	s : N N N N N N N N N N N 3 N N N N 1 N N 3 -> action:  V13
	s': N N N N N N N N N N N 3 N 22 N N 1 N N 3 -> reward:  0.0

	s : 3 3 3 3 0 3 3 11 3 11 N 3 11 22 6 3 1 3 11 3 -> action:  V10
	s': 3 3 3 3 0 3 3 11 3 11 1 3 11 22 6 3 1 3 11 3 -> reward:  0.0

	s : 3 3 3 3 0 3 3 11 3 11 1 3 11 22 6 3 1 3 11 3 -> action:  E
	s': None -> reward:  1.0

finished epoch 33000
average loss: 0.02638953641255921

epoch: 33999 row: 63 exploration: 0.10000
	 ['V16', 'V7', 'V18', 'V2', 'V9', 'V3', 'E'] 

	sample size: 3

	s : N N N N N N N N N N N N N N N N N N N N -> action:  V16
	s': N N N N N N N N N N N N N N N N 10 N N N -> reward:  0.0

	s : N N N N N N N 2 N N N N N N N N 10 N N N -> action:  V18
	s': N N N N N N N 2 N N N N N N N N 10 N 2 N -> reward:  0.0

	s : N N 2 2 N N N 2 N 2 N N N N N N 10 N 2 N -> action:  E
	s': None -> reward:  0.0

finished epoch 34000
average loss: 0.03072160611972322

epoch: 34999 row: 53 exploration: 0.10000
	 ['V16', 'V7', 'V2', 'V13', 'V4', 'V12', 'V11', 'V15', 'V3', 'V18', 'V9', 'E'] 

	sample size: 4

	s : N N 0 N 0 N N 0 N N N 14 0 0 N N 13 N N N -> action:  V15
	s': N N 0 N 0 N N 0 N N N 14 0 0 N 0 13 N N N -> reward:  0.0

	s : N N N N N N N 0 N N N N N N N N 13 N N N -> action:  V2
	s': N N 0 N N N N 0 N N N N N N N N 13 N N N -> reward:  0.0

	s : N N N N N N N 0 N N N N N N N N 13 N N N -> action:  V2
	s': N N 0 N N N N 0 N N N N N N N N 13 N N N -> reward:  0.0

	s : N N 0 0 0 N N 0 N 0 N 14 0 0 N 0 13 N 0 N -> action:  E
	s': None -> reward:  1.0

finished epoch 35000
average loss: 0.03009957015123382

epoch: 35999 row: 43 exploration: 0.10000
	 ['V11', 'V16', 'V18', 'V7', 'V2', 'V14', 'V1', 'E'] 

	sample size: 3

	s : N N N N N N N 6 N N N 4 N N N N 6 N 6 N -> action:  V2
	s': N N 6 N N N N 6 N N N 4 N N N N 6 N 6 N -> reward:  0.0

	s : N N N N N N N N N N N 4 N N N N 6 N 6 N -> action:  V7
	s': N N N N N N N 6 N N N 4 N N N N 6 N 6 N -> reward:  0.0

	s : N 6 6 N N N N 6 N N N 4 N N 6 N 6 N 6 N -> action:  E
	s': None -> reward:  0.0

finished epoch 36000
average loss: 0.030893285175622624

epoch: 36999 row: 33 exploration: 0.10000
	 ['V16', 'V15', 'V11', 'V13', 'V9', 'V7', 'V4', 'E'] 

	sample size: 3

	s : N N N N N N N 5 N 5 N 5 N 5 N 5 5 N N N -> action:  V4
	s': N N N N 5 N N 5 N 5 N 5 N 5 N 5 5 N N N -> reward:  0.0

	s : N N N N N N N N N N N N N N N 5 5 N N N -> action:  V11
	s': N N N N N N N N N N N 5 N N N 5 5 N N N -> reward:  0.0

	s : N N N N 5 N N 5 N 5 N 5 N 5 N 5 5 N N N -> action:  E
	s': None -> reward:  1.0

finished epoch 37000
average loss: 0.03642402783826037

epoch: 37999 row: 23 exploration: 0.10000
	 ['V16', 'V18', 'E'] 

	sample size: 2

	s : N N N N N N N N N N N N N N N N 4 N N N -> action:  V18
	s': N N N N N N N N N N N N N N N N 4 N 0 N -> reward:  0.0

	s : N N N N N N N N N N N N N N N N 4 N 0 N -> action:  E
	s': None -> reward:  0.0

finished epoch 38000
average loss: 0.03833239554588352

epoch: 38999 row: 13 exploration: 0.10000
	 ['V17', 'V4', 'V15', 'V16', 'V19', 'V0', 'V18', 'V13', 'V11', 'V3', 'V8', 'V7', 'V2', 'V14', 'V12', 'V6', 'V9', 'V5', 'E'] 

	sample size: 5

	s : 6 N N 0 0 N N N 0 N N 0 N 6 N 6 0 6 0 6 -> action:  V7
	s': 6 N N 0 0 N N 6 0 N N 0 N 6 N 6 0 6 0 6 -> reward:  0.0

	s : 6 N 6 0 0 N N 6 0 N N 0 N 6 6 6 0 6 0 6 -> action:  V12
	s': 6 N 6 0 0 N N 6 0 N N 0 6 6 6 6 0 6 0 6 -> reward:  0.0

	s : 6 N 6 0 0 N N 6 0 N N 0 N 6 6 6 0 6 0 6 -> action:  V12
	s': 6 N 6 0 0 N N 6 0 N N 0 6 6 6 6 0 6 0 6 -> reward:  0.0

	s : 6 N 6 0 0 N 6 6 0 6 N 0 6 6 6 6 0 6 0 6 -> action:  V5
	s': 6 N 6 0 0 6 6 6 0 6 N 0 6 6 6 6 0 6 0 6 -> reward:  0.0

	s : 6 N 6 0 0 6 6 6 0 6 N 0 6 6 6 6 0 6 0 6 -> action:  E
	s': None -> reward:  1.0

finished epoch 39000
average loss: 0.03127434367788282

epoch: 39999 row: 3 exploration: 0.10000
	 ['V16', 'V4', 'V18', 'V15', 'V19', 'V17', 'V10', 'V11', 'V3', 'V14', 'V2', 'V12', 'V13', 'E'] 

	sample size: 4

	s : N N N N 0 N N N N N N N N N N 10 0 0 0 0 -> action:  V10
	s': N N N N 0 N N N N N 0 N N N N 10 0 0 0 0 -> reward:  0.0

	s : N N N N 0 N N N N N 0 0 N N N 10 0 0 0 0 -> action:  V3
	s': N N N 0 0 N N N N N 0 0 N N N 10 0 0 0 0 -> reward:  0.0

	s : N N N 0 0 N N N N N 0 0 N N 0 10 0 0 0 0 -> action:  V2
	s': N N 0 0 0 N N N N N 0 0 N N 0 10 0 0 0 0 -> reward:  0.0

	s : N N 0 0 0 N N N N N 0 0 0 0 0 10 0 0 0 0 -> action:  E
	s': None -> reward:  1.0

finished epoch 40000
average loss: 0.035575582532203956

epoch: 40999 row: 94 exploration: 0.10000
	 ['V16', 'V4', 'V7', 'V12', 'V19', 'V18', 'V15', 'V11', 'V14', 'V17', 'V13', 'V0', 'V3', 'E'] 

	sample size: 4

	s : N N N N 5 N N 5 N N N 5 5 N 5 5 5 N 5 5 -> action:  V17
	s': N N N N 5 N N 5 N N N 5 5 N 5 5 5 5 5 5 -> reward:  0.0

	s : N N N N 5 N N 5 N N N 5 5 N 5 5 5 N 5 5 -> action:  V17
	s': N N N N 5 N N 5 N N N 5 5 N 5 5 5 5 5 5 -> reward:  0.0

	s : N N N N 5 N N 5 N N N N 5 N N N 5 N 5 5 -> action:  V15
	s': N N N N 5 N N 5 N N N N 5 N N 5 5 N 5 5 -> reward:  0.0

	s : 5 N N 5 5 N N 5 N N N 5 5 5 5 5 5 5 5 5 -> action:  E
	s': None -> reward:  1.0

finished epoch 41000
average loss: 0.031123686687463077

epoch: 41999 row: 84 exploration: 0.10000
	 ['V17', 'V18', 'V19', 'V3', 'V16', 'V14', 'E'] 

	sample size: 3

	s : N N N N N N N N N N N N N N N N N N N N -> action:  V17
	s': N N N N N N N N N N N N N N N N N 13 N N -> reward:  0.0

	s : N N N N N N N N N N N N N N N N N N N N -> action:  V17
	s': N N N N N N N N N N N N N N N N N 13 N N -> reward:  0.0

	s : N N N 0 N N N N N N N N N N 12 N 13 13 0 0 -> action:  E
	s': None -> reward:  0.0

finished epoch 42000
average loss: 0.028631532771025377

epoch: 42999 row: 74 exploration: 0.10000
	 ['V4', 'V18', 'V19', 'V15', 'V5', 'E'] 

	sample size: 3

	s : N N N N N N N N N N N N N N N N N N N N -> action:  V4
	s': N N N N 11 N N N N N N N N N N N N N N N -> reward:  0.0

	s : N N N N 11 N N N N N N N N N N N N N 0 4 -> action:  V15
	s': N N N N 11 N N N N N N N N N N 11 N N 0 4 -> reward:  0.0

	s : N N N N 11 4 N N N N N N N N N 11 N N 0 4 -> action:  E
	s': None -> reward:  0.0

finished epoch 43000
average loss: 0.029838307519750286

epoch: 43999 row: 64 exploration: 0.10000
	 ['V3', 'V4', 'V13', 'V12', 'E'] 

	sample size: 2

	s : N N N 5 5 N N N N N N N N 5 N N N N N N -> action:  V12
	s': N N N 5 5 N N N N N N N 5 5 N N N N N N -> reward:  0.0

	s : N N N 5 5 N N N N N N N 5 5 N N N N N N -> action:  E
	s': None -> reward:  1.0

finished epoch 44000
average loss: 0.030954992775899883

epoch: 44999 row: 54 exploration: 0.10000
	 ['V4', 'V3', 'V19', 'V12', 'V18', 'V15', 'V11', 'V16', 'V0', 'V6', 'V10', 'V17', 'V7', 'V2', 'V1', 'V5', 'E'] 

	sample size: 5

	s : 6 N N 6 6 N N N N N N 6 6 N N 6 6 N 6 6 -> action:  V6
	s': 6 N N 6 6 N 6 N N N N 6 6 N N 6 6 N 6 6 -> reward:  0.0

	s : 6 N N 6 6 N 6 6 N N 6 6 6 N N 6 6 6 6 6 -> action:  V2
	s': 6 N 6 6 6 N 6 6 N N 6 6 6 N N 6 6 6 6 6 -> reward:  0.0

	s : N N N 6 6 N N N N N N N 6 N N 6 N N 6 6 -> action:  V11
	s': N N N 6 6 N N N N N N 6 6 N N 6 N N 6 6 -> reward:  0.0

	s : N N N N 6 N N N N N N N N N N N N N N N -> action:  V3
	s': N N N 6 6 N N N N N N N N N N N N N N N -> reward:  0.0

	s : 6 6 6 6 6 6 6 6 N N 6 6 6 N N 6 6 6 6 6 -> action:  E
	s': None -> reward:  1.0

finished epoch 45000
average loss: 0.03151769809863708

epoch: 45999 row: 44 exploration: 0.10000
	 ['V4', 'V3', 'E'] 

	sample size: 2

	s : N N N N 5 N N N N N N N N N N N N N N N -> action:  V3
	s': N N N 5 5 N N N N N N N N N N N N N N N -> reward:  0.0

	s : N N N 5 5 N N N N N N N N N N N N N N N -> action:  E
	s': None -> reward:  1.0

finished epoch 46000
average loss: 0.035672901732607724

epoch: 46999 row: 34 exploration: 0.10000
	 ['V19', 'V4', 'V18', 'V3', 'E'] 

	sample size: 2

	s : N N N N N N N N N N N N N N N N N N N 12 -> action:  V4
	s': N N N N 0 N N N N N N N N N N N N N N 12 -> reward:  0.0

	s : N N N 12 0 N N N N N N N N N N N N N 11 12 -> action:  E
	s': None -> reward:  0.0

finished epoch 47000
average loss: 0.03229001949032016

epoch: 47999 row: 24 exploration: 0.10000
	 ['V19', 'V15', 'V18', 'V11', 'V4', 'V17', 'V13', 'V3', 'V12', 'V1', 'V16', 'V14', 'E'] 

	sample size: 4

	s : N N N N N N N N N N N N N N N N N N N N -> action:  V19
	s': N N N N N N N N N N N N N N N N N N N 0 -> reward:  0.0

	s : N N N N N N N N N N N N N N N N N N N N -> action:  V19
	s': N N N N N N N N N N N N N N N N N N N 0 -> reward:  0.0

	s : N N N N N N N N N N N N N N N 0 N N 0 0 -> action:  V11
	s': N N N N N N N N N N N 0 N N N 0 N N 0 0 -> reward:  0.0

	s : N 0 N 0 0 N N N N N N 0 0 0 0 0 0 0 0 0 -> action:  E
	s': None -> reward:  1.0

finished epoch 48000
average loss: 0.025132770230833556

epoch: 48999 row: 14 exploration: 0.10000
	 ['V15', 'V18', 'V19', 'V11', 'V10', 'V9', 'V1', 'V4', 'V17', 'V13', 'V16', 'V5', 'E'] 

	sample size: 4

	s : N N N N N N N N N N N N N N N 0 N N N N -> action:  V18
	s': N N N N N N N N N N N N N N N 0 N N 0 N -> reward:  0.0

	s : N 0 N N 0 N N N N 12 0 14 N N N 0 N N 0 0 -> action:  V17
	s': N 0 N N 0 N N N N 12 0 14 N N N 0 N 12 0 0 -> reward:  0.0

	s : N 0 N N 0 N N N N 12 0 14 N 0 N 0 N 12 0 0 -> action:  V16
	s': N 0 N N 0 N N N N 12 0 14 N 0 N 0 12 12 0 0 -> reward:  0.0

	s : N 0 N N 0 0 N N N 12 0 14 N 0 N 0 12 12 0 0 -> action:  E
	s': None -> reward:  1.0

finished epoch 49000
average loss: 0.028654883763520957

epoch: 49999 row: 4 exploration: 0.10000
	 ['V11', 'V15', 'V2', 'V4', 'V19', 'V9', 'V17', 'V10', 'V14', 'E'] 

	sample size: 3

	s : N N 2 N 2 N N N N 2 N 2 N N N 2 N 2 N 2 -> action:  V10
	s': N N 2 N 2 N N N N 2 2 2 N N N 2 N 2 N 2 -> reward:  0.0

	s : N N N N N N N N N N N 2 N N N 2 N N N N -> action:  V2
	s': N N 2 N N N N N N N N 2 N N N 2 N N N N -> reward:  0.0

	s : N N 2 N 2 N N N N 2 2 2 N N 2 2 N 2 N 2 -> action:  E
	s': None -> reward:  1.0

finished epoch 50000
average loss: 0.026324941900383692

test case 0
	 ['V11', 'V15', 'V17', 'V19', 'V10', 'V4', 'V14', 'V13', 'E'] 
	# trees: 8 , real: 5 , pred: 5

test case 1
	 ['V11', 'V15', 'V17', 'V19', 'V10', 'V4', 'V14', 'V13', 'E'] 
	# trees: 8 , real: 5 , pred: 5

test case 2
	 ['V11', 'V15', 'V19', 'V17', 'E'] 
	# trees: 4 , real: 2 , pred: 2

test case 3
	 ['V11', 'V18', 'V15', 'V17', 'V19', 'V10', 'V4', 'V14', 'V3', 'E'] 
	# trees: 9 , real: 10 , pred: 10

test case 4
	 ['V11', 'V15', 'V17', 'V19', 'V10', 'V18', 'V13', 'V4', 'V3', 'V14', 'V7', 'V1', 'V16', 'E'] 
	# trees: 13 , real: 6 , pred: 0

test case 5
	 ['V11', 'V15', 'V17', 'V19', 'V10', 'V4', 'V14', 'V13', 'E'] 
	# trees: 8 , real: 5 , pred: 5

test case 6
	 ['V11', 'V15', 'V17', 'V19', 'V10', 'V4', 'V14', 'V13', 'E'] 
	# trees: 8 , real: 6 , pred: 5

test case 7
	 ['V11', 'V15', 'V17', 'V19', 'V10', 'V4', 'V14', 'V13', 'E'] 
	# trees: 8 , real: 5 , pred: 5

test case 8
	 ['V11', 'V18', 'E'] 
	# trees: 2 , real: 16 , pred: 16

test case 9
	 ['V11', 'V15', 'V17', 'V19', 'V10', 'V4', 'V13', 'V3', 'V14', 'E'] 
	# trees: 9 , real: 0 , pred: 0

test case 10
	 ['V11', 'V18', 'V17', 'E'] 
	# trees: 3 , real: 6 , pred: 20

test case 11
	 ['V11', 'V15', 'V17', 'V19', 'V10', 'V4', 'E'] 
	# trees: 6 , real: 2 , pred: 2

test case 12
	 ['V11', 'V15', 'V18', 'V4', 'V12', 'V6', 'V14', 'V5', 'V2', 'V19', 'E'] 
	# trees: 10 , real: 2 , pred: 2

test case 13
	 ['V11', 'V15', 'V17', 'V19', 'V10', 'V4', 'V14', 'V18', 'V13', 'V7', 'V1', 'V3', 'V16', 'V2', 'V0', 'V5', 'V9', 'V12', 'V8', 'E'] 
	# trees: 19 , real: 3 , pred: 3

test case 14
	 ['V11', 'V15', 'V17', 'E'] 
	# trees: 3 , real: 0 , pred: 0

test case 15
	 ['V11', 'V15', 'V17', 'V19', 'V10', 'V18', 'V13', 'V4', 'V7', 'V14', 'V1', 'V3', 'V16', 'V9', 'V2', 'V0', 'E'] 
	# trees: 16 , real: 0 , pred: 0

test case 16
	 ['V11', 'V15', 'V17', 'V19', 'V10', 'V18', 'V13', 'V4', 'V3', 'V14', 'V7', 'V1', 'V16', 'E'] 
	# trees: 13 , real: 0 , pred: 0

test case 17
	 ['V11', 'V15', 'V17', 'V19', 'V10', 'V4', 'V14', 'V13', 'E'] 
	# trees: 8 , real: 5 , pred: 5

test case 18
	 ['V11', 'V15', 'V17', 'V19', 'V4', 'V10', 'V13', 'V14', 'E'] 
	# trees: 8 , real: 0 , pred: 0

test case 19
	 ['V11', 'V15', 'V17', 'V19', 'V10', 'V4', 'E'] 
	# trees: 6 , real: 2 , pred: 2

test case 20
	 ['V11', 'V18', 'V17', 'V15', 'V19', 'V10', 'V14', 'V13', 'V4', 'V3', 'V1', 'V7', 'V16', 'V5', 'V0', 'V9', 'V2', 'V12', 'V8', 'V6', 'E'] 
	# trees: 20 , real: 11 , pred: 0

test case 21
	 ['V11', 'V15', 'V17', 'V19', 'V10', 'V4', 'E'] 
	# trees: 6 , real: 2 , pred: 2

test case 22
	 ['V11', 'V15', 'V17', 'V19', 'V4', 'V10', 'V14', 'E'] 
	# trees: 7 , real: 1 , pred: 1
               accuracy, precision, recall, f_score
majority vote: 0.739130, 0.226042, 0.213889, 0.211218
weighted vote: 0.695652, 0.178819, 0.200000, 0.187354
reinforcement: 0.826087, 0.272817, 0.291667, 0.280934
