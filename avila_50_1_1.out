{'dataset': 'avila', 'algorithm': 'ptdqn', 'num_clf': 50, 'num_training': 500000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 3884, 'portion': 0.5, 'sequential': False}
(20867, 11)
reading data takes 0.064 sec
number of labels: 12

Running iteration 1 of 10 fold...
[11, 0, 28, 4, 25, 24, 20, 22, 44, 3, 18]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.982215, 0.982293, 0.971378, 0.979153

    accuracy, precision, recall, f_score
max3: 0.981896, 0.982044, 0.975283, 0.981657

    accuracy, precision, recall, f_score
max1: 0.988979, 0.989003, 0.986947, 0.989591


min loss: 0.009, episode: 257000
max accu: 0.989, episode: 370000

44.42 classifiers used
    accuracy, precision, recall, f_score
mv: 0.994250, 0.994305, 0.994165, 0.994862
wv: 0.994250, 0.994305, 0.994165, 0.994862
fs: 0.984188, 0.984213, 0.986446, 0.987950
rl: 0.988979, 0.989003, 0.986947, 0.989591

0.8493993610223644
0.81, 0.81, 0.84, 0.87, 0.89, 0.87, 0.85, 0.84, 0.84, 0.87, 0.77, 0.90, 0.80, 0.85, 0.86, 0.81, 0.79, 0.80, 0.87, 0.82, 0.88, 0.86, 0.9, 0.84, 0.88, 0.87, 0.87, 0.85, 0.90, 0.84, 0.81, 0.87, 0.87, 0.88, 0.79, 0.86, 0.84, 0.85, 0.81, 0.81, 0.83, 0.82, 0.79, 0.85, 0.87, 0.85, 0.84, 0.85, 0.87, 0.83

0.8488860489882853
0.80, 0.81, 0.85, 0.87, 0.88, 0.86, 0.85, 0.84, 0.84, 0.88, 0.77, 0.90, 0.80, 0.86, 0.86, 0.80, 0.78, 0.80, 0.87, 0.83, 0.88, 0.86, 0.89, 0.84, 0.88, 0.87, 0.87, 0.85, 0.90, 0.84, 0.81, 0.86, 0.87, 0.88, 0.79, 0.86, 0.83, 0.85, 0.81, 0.81, 0.83, 0.81, 0.79, 0.85, 0.87, 0.85, 0.84, 0.85, 0.87, 0.83

0.85126018207954
0.81, 0.82, 0.84, 0.88, 0.89, 0.86, 0.84, 0.82, 0.84, 0.87, 0.77, 0.91, 0.82, 0.86, 0.84, 0.81, 0.79, 0.79, 0.86, 0.82, 0.88, 0.88, 0.89, 0.85, 0.89, 0.86, 0.87, 0.84, 0.90, 0.83, 0.83, 0.88, 0.86, 0.88, 0.80, 0.85, 0.85, 0.85, 0.81, 0.80, 0.84, 0.82, 0.79, 0.87, 0.89, 0.85, 0.84, 0.85, 0.87, 0.83

0.902759942501198
0.94, 0.92, 0.94, 0.86, 0.90, 0.93, 0.87, 0.92, 0.89, 0.88, 0.90, 0.89, 0.84, 0.90, 0.94, 0.90, 0.91, 0.90, 0.87, 0.91, 0.93, 0.90, 0.89, 0.87, 0.90, 0.87, 0.83, 0.88, 0.87, 0.90, 0.87, 0.92, 0.95, 0.89, 0.90, 0.89, 0.93, 0.89, 0.89, 0.90, 0.89, 0.89, 0.90, 0.91, 0.89, 0.90, 0.88, 0.92, 0.90, 0.88


Running iteration 2 of 10 fold...
[46, 0, 39, 2, 11, 25, 42, 48, 18, 45, 7, 3, 15, 10, 49, 36]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.980085, 0.980226, 0.965912, 0.976306

    accuracy, precision, recall, f_score
max3: 0.979766, 0.979882, 0.969009, 0.977506

    accuracy, precision, recall, f_score
max1: 0.977480, 0.977749, 0.960499, 0.973009


min loss: 0.006, episode: 270000
max accu: 0.977, episode: 400000

47.66 classifiers used
    accuracy, precision, recall, f_score
mv: 0.995688, 0.995697, 0.992916, 0.995091
wv: 0.995208, 0.995219, 0.991959, 0.994494
fs: 0.987063, 0.987124, 0.980911, 0.986597
rl: 0.977480, 0.977749, 0.960499, 0.973009

0.843891373801917
0.80, 0.86, 0.89, 0.85, 0.81, 0.78, 0.75, 0.88, 0.86, 0.85, 0.86, 0.88, 0.82, 0.80, 0.78, 0.86, 0.81, 0.85, 0.87, 0.86, 0.87, 0.81, 0.83, 0.82, 0.84, 0.88, 0.80, 0.80, 0.83, 0.87, 0.79, 0.80, 0.84, 0.83, 0.78, 0.80, 0.88, 0.81, 0.81, 0.89, 0.84, 0.82, 0.89, 0.81, 0.85, 0.89, 0.90, 0.86, 0.89, 0.87

0.8421767838125667
0.80, 0.85, 0.89, 0.85, 0.80, 0.77, 0.75, 0.89, 0.86, 0.85, 0.86, 0.88, 0.82, 0.80, 0.78, 0.86, 0.81, 0.85, 0.87, 0.86, 0.87, 0.82, 0.82, 0.82, 0.84, 0.88, 0.80, 0.80, 0.83, 0.87, 0.79, 0.80, 0.84, 0.83, 0.77, 0.80, 0.88, 0.80, 0.82, 0.89, 0.84, 0.82, 0.88, 0.80, 0.85, 0.89, 0.90, 0.86, 0.89, 0.87

0.8411212266411119
0.81, 0.86, 0.90, 0.84, 0.80, 0.77, 0.76, 0.88, 0.85, 0.85, 0.85, 0.88, 0.82, 0.79, 0.75, 0.87, 0.81, 0.85, 0.86, 0.86, 0.88, 0.81, 0.83, 0.82, 0.84, 0.88, 0.80, 0.81, 0.83, 0.87, 0.79, 0.79, 0.84, 0.83, 0.77, 0.79, 0.88, 0.82, 0.81, 0.88, 0.84, 0.81, 0.88, 0.82, 0.84, 0.89, 0.89, 0.86, 0.89, 0.88

0.8997220891231433
0.95, 0.90, 0.89, 0.90, 0.91, 0.88, 0.90, 0.88, 0.91, 0.91, 0.91, 0.91, 0.92, 0.90, 0.91, 0.84, 0.89, 0.90, 0.90, 0.85, 0.85, 0.95, 0.89, 0.90, 0.87, 0.90, 0.89, 0.89, 0.92, 0.82, 0.86, 0.91, 0.88, 0.89, 0.95, 0.87, 0.87, 0.93, 0.88, 0.89, 0.91, 0.84, 0.92, 0.84, 0.91, 0.87, 0.89, 0.94, 0.91, 0.90


Running iteration 3 of 10 fold...
[20, 0, 16, 32, 45, 37, 38, 22, 39, 33, 35]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.982854, 0.982999, 0.975380, 0.981759

    accuracy, precision, recall, f_score
max3: 0.981896, 0.982004, 0.978129, 0.982921

    accuracy, precision, recall, f_score
max1: 0.983709, 0.983814, 0.971791, 0.979583


min loss: 0.005, episode: 252000
max accu: 0.984, episode: 390000

47.92 classifiers used
    accuracy, precision, recall, f_score
mv: 0.994250, 0.994248, 0.988984, 0.990659
wv: 0.994250, 0.994248, 0.988984, 0.990659
fs: 0.985146, 0.985117, 0.983380, 0.983999
rl: 0.983709, 0.983814, 0.971791, 0.979583

0.8447050053248136
0.86, 0.78, 0.85, 0.84, 0.85, 0.80, 0.82, 0.84, 0.81, 0.87, 0.84, 0.83, 0.83, 0.79, 0.83, 0.85, 0.89, 0.83, 0.81, 0.87, 0.91, 0.82, 0.84, 0.81, 0.85, 0.79, 0.81, 0.86, 0.87, 0.85, 0.79, 0.86, 0.89, 0.88, 0.83, 0.88, 0.85, 0.85, 0.88, 0.85, 0.86, 0.83, 0.79, 0.83, 0.86, 0.87, 0.82, 0.82, 0.81, 0.82

0.8431182108626197
0.85, 0.78, 0.84, 0.83, 0.85, 0.79, 0.82, 0.84, 0.81, 0.87, 0.84, 0.83, 0.83, 0.79, 0.83, 0.85, 0.89, 0.82, 0.81, 0.87, 0.91, 0.83, 0.84, 0.81, 0.85, 0.80, 0.80, 0.87, 0.87, 0.86, 0.78, 0.86, 0.89, 0.88, 0.82, 0.88, 0.84, 0.85, 0.88, 0.85, 0.86, 0.83, 0.78, 0.82, 0.86, 0.87, 0.82, 0.82, 0.80, 0.82

0.8451269765213226
0.85, 0.79, 0.85, 0.85, 0.85, 0.80, 0.81, 0.86, 0.82, 0.86, 0.84, 0.82, 0.84, 0.80, 0.84, 0.85, 0.89, 0.82, 0.81, 0.87, 0.91, 0.82, 0.86, 0.82, 0.86, 0.77, 0.82, 0.88, 0.87, 0.84, 0.79, 0.86, 0.89, 0.88, 0.83, 0.88, 0.83, 0.85, 0.87, 0.85, 0.88, 0.83, 0.77, 0.82, 0.86, 0.88, 0.82, 0.82, 0.82, 0.81

0.9135026353617632
0.90, 0.90, 0.93, 0.88, 0.92, 0.92, 0.92, 0.91, 0.91, 0.90, 0.93, 0.92, 0.92, 0.85, 0.92, 0.90, 0.93, 0.91, 0.90, 0.90, 0.90, 0.88, 0.93, 0.91, 0.91, 0.88, 0.89, 0.90, 0.90, 0.95, 0.93, 0.91, 0.90, 0.94, 0.91, 0.88, 0.92, 0.94, 0.91, 0.88, 0.92, 0.94, 0.93, 0.86, 0.96, 0.90, 0.91, 0.90, 0.84, 0.90


Running iteration 4 of 10 fold...
[37, 0, 8, 24, 3, 10, 28, 12, 46, 47, 21, 49, 45, 36, 6, 19]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.982748, 0.982918, 0.977335, 0.982848

    accuracy, precision, recall, f_score
max3: 0.980405, 0.980631, 0.979937, 0.983740

    accuracy, precision, recall, f_score
max1: 0.983230, 0.983221, 0.982788, 0.985645


min loss: 0.006, episode: 264000
max accu: 0.983, episode: 400000

26.11 classifiers used
    accuracy, precision, recall, f_score
mv: 0.995688, 0.995712, 0.994075, 0.995921
wv: 0.995688, 0.995712, 0.994075, 0.995921
fs: 0.986584, 0.986613, 0.987290, 0.988392
rl: 0.983230, 0.983221, 0.982788, 0.985645

0.8519339723109689
0.89, 0.85, 0.85, 0.87, 0.87, 0.84, 0.86, 0.84, 0.90, 0.80, 0.89, 0.84, 0.88, 0.81, 0.83, 0.87, 0.86, 0.77, 0.80, 0.86, 0.86, 0.82, 0.84, 0.86, 0.9, 0.87, 0.78, 0.80, 0.88, 0.82, 0.84, 0.82, 0.86, 0.86, 0.86, 0.83, 0.87, 0.91, 0.83, 0.82, 0.84, 0.81, 0.84, 0.77, 0.83, 0.89, 0.85, 0.87, 0.88, 0.85

0.8488604898828541
0.89, 0.85, 0.85, 0.86, 0.86, 0.83, 0.86, 0.84, 0.90, 0.79, 0.89, 0.84, 0.87, 0.80, 0.83, 0.87, 0.85, 0.76, 0.80, 0.86, 0.85, 0.82, 0.84, 0.85, 0.90, 0.87, 0.78, 0.80, 0.88, 0.82, 0.85, 0.81, 0.86, 0.85, 0.85, 0.82, 0.87, 0.90, 0.83, 0.82, 0.84, 0.81, 0.84, 0.77, 0.83, 0.89, 0.84, 0.86, 0.88, 0.84

0.8503114518447533
0.90, 0.86, 0.86, 0.87, 0.87, 0.84, 0.86, 0.83, 0.89, 0.80, 0.88, 0.83, 0.88, 0.80, 0.84, 0.87, 0.84, 0.76, 0.79, 0.86, 0.85, 0.82, 0.85, 0.85, 0.90, 0.86, 0.77, 0.80, 0.89, 0.81, 0.86, 0.83, 0.86, 0.85, 0.86, 0.83, 0.86, 0.90, 0.82, 0.83, 0.84, 0.81, 0.85, 0.75, 0.84, 0.89, 0.85, 0.85, 0.89, 0.85

0.9107714422616194
0.91, 0.89, 0.93, 0.94, 0.89, 0.89, 0.95, 0.93, 0.89, 0.90, 0.92, 0.85, 0.91, 0.89, 0.88, 0.89, 0.90, 0.93, 0.84, 0.95, 0.95, 0.92, 0.86, 0.91, 0.90, 0.92, 0.89, 0.89, 0.94, 0.90, 0.91, 0.93, 0.86, 0.93, 0.87, 0.90, 0.88, 0.92, 0.92, 0.89, 0.92, 0.92, 0.90, 0.92, 0.87, 0.90, 0.90, 0.92, 0.95, 0.89


Running iteration 5 of 10 fold...
[24, 0, 9, 31, 11, 23, 48, 30, 32, 4, 35, 38, 25, 46, 14, 2]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.975825, 0.976062, 0.972602, 0.979500

    accuracy, precision, recall, f_score
max3: 0.974228, 0.974552, 0.973766, 0.979453

    accuracy, precision, recall, f_score
max1: 0.975084, 0.975530, 0.954334, 0.966771


min loss: 0.004, episode: 500000
max accu: 0.975, episode: 450000

44.52 classifiers used
    accuracy, precision, recall, f_score
mv: 0.994729, 0.994785, 0.984353, 0.990136
wv: 0.994729, 0.994785, 0.984353, 0.990136
fs: 0.978438, 0.978697, 0.962602, 0.967859
rl: 0.975084, 0.975530, 0.954334, 0.966771

0.8363642172523962
0.83, 0.82, 0.86, 0.82, 0.85, 0.80, 0.82, 0.86, 0.83, 0.90, 0.73, 0.86, 0.83, 0.78, 0.83, 0.83, 0.82, 0.81, 0.83, 0.85, 0.84, 0.83, 0.84, 0.88, 0.90, 0.85, 0.83, 0.80, 0.83, 0.84, 0.87, 0.87, 0.83, 0.85, 0.82, 0.83, 0.83, 0.84, 0.87, 0.80, 0.76, 0.79, 0.84, 0.79, 0.86, 0.78, 0.82, 0.80, 0.83, 0.83

0.8329329073482428
0.83, 0.82, 0.86, 0.81, 0.85, 0.8, 0.82, 0.86, 0.83, 0.90, 0.74, 0.86, 0.83, 0.78, 0.83, 0.82, 0.82, 0.81, 0.82, 0.85, 0.84, 0.83, 0.84, 0.88, 0.90, 0.85, 0.82, 0.80, 0.83, 0.84, 0.87, 0.86, 0.83, 0.85, 0.82, 0.83, 0.83, 0.83, 0.87, 0.80, 0.75, 0.78, 0.84, 0.79, 0.85, 0.77, 0.82, 0.80, 0.83, 0.82

0.8328030666027791
0.82, 0.84, 0.86, 0.80, 0.85, 0.80, 0.80, 0.86, 0.83, 0.90, 0.74, 0.86, 0.83, 0.78, 0.82, 0.83, 0.81, 0.81, 0.82, 0.83, 0.85, 0.82, 0.83, 0.88, 0.90, 0.86, 0.83, 0.79, 0.83, 0.84, 0.86, 0.86, 0.83, 0.84, 0.83, 0.82, 0.82, 0.85, 0.87, 0.80, 0.76, 0.79, 0.85, 0.79, 0.86, 0.77, 0.82, 0.79, 0.82, 0.82

0.9137038811691423
0.91, 0.89, 0.91, 0.91, 0.96, 0.92, 0.88, 0.91, 0.93, 0.95, 0.92, 0.91, 0.90, 0.89, 0.91, 0.93, 0.92, 0.94, 0.87, 0.84, 0.90, 0.93, 0.86, 0.88, 0.93, 0.88, 0.90, 0.86, 0.88, 0.94, 0.89, 0.90, 0.91, 0.91, 0.89, 0.92, 0.92, 0.92, 0.89, 0.89, 0.92, 0.95, 0.92, 0.92, 0.93, 0.95, 0.92, 0.92, 0.90, 0.90


Running iteration 6 of 10 fold...
[49, 0, 30, 44, 20, 38, 48, 29, 13, 46, 24]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.984771, 0.984840, 0.979950, 0.984591

    accuracy, precision, recall, f_score
max3: 0.981683, 0.981748, 0.977949, 0.981526

    accuracy, precision, recall, f_score
max1: 0.982750, 0.982887, 0.973974, 0.980420


min loss: 0.007, episode: 252000
max accu: 0.983, episode: 350000

50.00 classifiers used
    accuracy, precision, recall, f_score
mv: 0.994250, 0.994297, 0.991923, 0.992496
wv: 0.993771, 0.993820, 0.991017, 0.991982
fs: 0.991854, 0.991934, 0.989908, 0.986376
rl: 0.982750, 0.982887, 0.973974, 0.980420

0.8525197018104368
0.79, 0.86, 0.78, 0.88, 0.79, 0.83, 0.82, 0.87, 0.85, 0.84, 0.80, 0.81, 0.83, 0.89, 0.83, 0.84, 0.83, 0.87, 0.81, 0.86, 0.90, 0.83, 0.82, 0.80, 0.86, 0.83, 0.87, 0.83, 0.82, 0.87, 0.91, 0.85, 0.88, 0.87, 0.83, 0.84, 0.88, 0.81, 0.89, 0.84, 0.83, 0.82, 0.87, 0.86, 0.91, 0.83, 0.90, 0.82, 0.90, 0.93

0.8486474973375933
0.79, 0.85, 0.77, 0.88, 0.78, 0.82, 0.81, 0.87, 0.86, 0.84, 0.80, 0.80, 0.83, 0.89, 0.83, 0.84, 0.82, 0.87, 0.81, 0.85, 0.90, 0.84, 0.81, 0.80, 0.86, 0.82, 0.87, 0.82, 0.82, 0.86, 0.91, 0.84, 0.88, 0.86, 0.83, 0.83, 0.88, 0.81, 0.90, 0.83, 0.83, 0.82, 0.86, 0.86, 0.91, 0.83, 0.89, 0.81, 0.90, 0.92

0.8562146621945377
0.80, 0.86, 0.79, 0.89, 0.80, 0.85, 0.82, 0.88, 0.87, 0.84, 0.80, 0.81, 0.85, 0.88, 0.85, 0.84, 0.83, 0.87, 0.83, 0.85, 0.90, 0.84, 0.82, 0.81, 0.87, 0.83, 0.88, 0.84, 0.83, 0.86, 0.92, 0.85, 0.90, 0.86, 0.83, 0.84, 0.87, 0.82, 0.90, 0.84, 0.82, 0.82, 0.86, 0.87, 0.91, 0.84, 0.88, 0.82, 0.90, 0.93

0.9144801149976043
0.94, 0.92, 0.93, 0.94, 0.92, 0.91, 0.92, 0.89, 0.87, 0.88, 0.93, 0.90, 0.93, 0.91, 0.87, 0.94, 0.91, 0.84, 0.94, 0.92, 0.93, 0.92, 0.91, 0.95, 0.88, 0.89, 0.91, 0.89, 0.95, 0.95, 0.88, 0.92, 0.90, 0.90, 0.84, 0.91, 0.93, 0.92, 0.92, 0.91, 0.94, 0.87, 0.93, 0.91, 0.88, 0.87, 0.91, 0.91, 0.91, 0.94


Running iteration 7 of 10 fold...
[14, 0, 39, 12, 31, 40, 5, 32, 2, 29, 24, 7]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.982428, 0.982581, 0.975510, 0.981509

    accuracy, precision, recall, f_score
max3: 0.979340, 0.979645, 0.973071, 0.979280

    accuracy, precision, recall, f_score
max1: 0.982271, 0.982420, 0.968224, 0.977425


min loss: 0.007, episode: 269000
max accu: 0.982, episode: 380000

49.54 classifiers used
    accuracy, precision, recall, f_score
mv: 0.995688, 0.995728, 0.992992, 0.994186
wv: 0.995688, 0.995715, 0.992867, 0.994419
fs: 0.987542, 0.987651, 0.982970, 0.985007
rl: 0.982271, 0.982420, 0.968224, 0.977425

0.8481533546325878
0.87, 0.83, 0.87, 0.87, 0.86, 0.87, 0.84, 0.81, 0.83, 0.80, 0.78, 0.89, 0.89, 0.81, 0.92, 0.79, 0.87, 0.82, 0.83, 0.85, 0.80, 0.85, 0.87, 0.87, 0.88, 0.86, 0.82, 0.82, 0.85, 0.89, 0.86, 0.88, 0.82, 0.79, 0.76, 0.83, 0.78, 0.86, 0.85, 0.91, 0.90, 0.81, 0.81, 0.84, 0.84, 0.87, 0.86, 0.87, 0.76, 0.85

0.8446389776357828
0.87, 0.82, 0.87, 0.87, 0.86, 0.87, 0.84, 0.81, 0.82, 0.80, 0.77, 0.88, 0.89, 0.81, 0.92, 0.79, 0.87, 0.83, 0.83, 0.85, 0.79, 0.84, 0.87, 0.87, 0.88, 0.86, 0.82, 0.82, 0.84, 0.88, 0.85, 0.87, 0.81, 0.79, 0.75, 0.82, 0.78, 0.85, 0.84, 0.91, 0.90, 0.81, 0.80, 0.84, 0.84, 0.87, 0.86, 0.87, 0.76, 0.85

0.8520076665069477
0.88, 0.82, 0.87, 0.87, 0.87, 0.88, 0.84, 0.82, 0.82, 0.80, 0.78, 0.89, 0.90, 0.81, 0.93, 0.81, 0.88, 0.81, 0.84, 0.86, 0.81, 0.85, 0.86, 0.88, 0.88, 0.85, 0.83, 0.83, 0.85, 0.88, 0.86, 0.87, 0.83, 0.81, 0.76, 0.83, 0.79, 0.86, 0.85, 0.91, 0.90, 0.82, 0.80, 0.85, 0.85, 0.89, 0.86, 0.88, 0.76, 0.86

0.9120459990416867
0.90, 0.92, 0.94, 0.91, 0.91, 0.92, 0.90, 0.91, 0.90, 0.89, 0.93, 0.93, 0.93, 0.89, 0.90, 0.93, 0.95, 0.91, 0.95, 0.87, 0.93, 0.88, 0.92, 0.87, 0.91, 0.89, 0.91, 0.92, 0.94, 0.90, 0.85, 0.88, 0.91, 0.90, 0.94, 0.91, 0.90, 0.86, 0.95, 0.90, 0.94, 0.96, 0.93, 0.85, 0.90, 0.91, 0.85, 0.89, 0.88, 0.89


Running iteration 8 of 10 fold...
[48, 0, 43, 13, 30, 26, 45, 24, 29, 16, 20, 18, 23, 5]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.977958, 0.978100, 0.973009, 0.977476

    accuracy, precision, recall, f_score
max3: 0.975506, 0.975598, 0.972071, 0.977840

    accuracy, precision, recall, f_score
max1: 0.980345, 0.980770, 0.965696, 0.977849


min loss: 0.006, episode: 265000
max accu: 0.980, episode: 380000

45.70 classifiers used
    accuracy, precision, recall, f_score
mv: 0.995686, 0.995726, 0.992199, 0.995166
wv: 0.995686, 0.995726, 0.992199, 0.995166
fs: 0.983221, 0.983559, 0.970411, 0.981238
rl: 0.980345, 0.980770, 0.965696, 0.977849

0.8455350867852199
0.80, 0.81, 0.86, 0.85, 0.83, 0.85, 0.83, 0.78, 0.82, 0.87, 0.83, 0.85, 0.79, 0.89, 0.79, 0.87, 0.87, 0.85, 0.87, 0.85, 0.86, 0.75, 0.84, 0.84, 0.88, 0.88, 0.88, 0.85, 0.81, 0.89, 0.88, 0.84, 0.84, 0.80, 0.85, 0.80, 0.83, 0.83, 0.80, 0.81, 0.87, 0.85, 0.84, 0.88, 0.79, 0.87, 0.81, 0.87, 0.90, 0.84

0.8442726304579341
0.80, 0.81, 0.86, 0.85, 0.83, 0.85, 0.83, 0.77, 0.82, 0.87, 0.83, 0.85, 0.79, 0.88, 0.79, 0.86, 0.86, 0.84, 0.87, 0.85, 0.86, 0.75, 0.84, 0.84, 0.88, 0.88, 0.89, 0.84, 0.81, 0.89, 0.88, 0.84, 0.84, 0.81, 0.84, 0.80, 0.83, 0.83, 0.79, 0.81, 0.86, 0.85, 0.83, 0.88, 0.79, 0.87, 0.82, 0.87, 0.90, 0.84

0.8503163950143816
0.81, 0.82, 0.87, 0.85, 0.82, 0.85, 0.82, 0.78, 0.82, 0.87, 0.84, 0.86, 0.80, 0.89, 0.80, 0.89, 0.88, 0.86, 0.88, 0.85, 0.87, 0.76, 0.85, 0.85, 0.88, 0.90, 0.88, 0.85, 0.83, 0.90, 0.89, 0.84, 0.83, 0.81, 0.85, 0.80, 0.84, 0.83, 0.80, 0.78, 0.88, 0.86, 0.85, 0.88, 0.80, 0.87, 0.81, 0.88, 0.90, 0.85

0.9080057526366252
0.88, 0.87, 0.90, 0.93, 0.89, 0.87, 0.94, 0.93, 0.90, 0.92, 0.89, 0.93, 0.90, 0.91, 0.87, 0.89, 0.92, 0.88, 0.85, 0.86, 0.92, 0.93, 0.93, 0.94, 0.86, 0.84, 0.92, 0.86, 0.92, 0.92, 0.94, 0.89, 0.89, 0.85, 0.89, 0.96, 0.90, 0.88, 0.96, 0.90, 0.95, 0.89, 0.94, 0.89, 0.93, 0.91, 0.93, 0.88, 0.89, 0.89


Running iteration 9 of 10 fold...
[16, 0, 36, 39, 32, 13, 49, 40, 38, 37, 7, 30, 48]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.979768, 0.979950, 0.940760, 0.958395

    accuracy, precision, recall, f_score
max3: 0.979553, 0.979676, 0.974819, 0.981151

    accuracy, precision, recall, f_score
max1: 0.982742, 0.982868, 0.950671, 0.964441


min loss: 0.008, episode: 247000
max accu: 0.983, episode: 390000

44.69 classifiers used
    accuracy, precision, recall, f_score
mv: 0.996644, 0.996688, 0.996226, 0.995170
wv: 0.996165, 0.996213, 0.996010, 0.995015
fs: 0.985139, 0.985232, 0.975892, 0.980380
rl: 0.982742, 0.982868, 0.950671, 0.964441

0.843925034607603
0.78, 0.81, 0.83, 0.85, 0.83, 0.86, 0.78, 0.87, 0.84, 0.86, 0.85, 0.85, 0.84, 0.88, 0.78, 0.78, 0.89, 0.83, 0.80, 0.85, 0.86, 0.81, 0.84, 0.84, 0.79, 0.81, 0.87, 0.85, 0.85, 0.86, 0.85, 0.83, 0.88, 0.86, 0.86, 0.85, 0.88, 0.85, 0.87, 0.88, 0.88, 0.81, 0.80, 0.83, 0.76, 0.78, 0.86, 0.85, 0.84, 0.89

0.8432161874334398
0.78, 0.81, 0.83, 0.85, 0.83, 0.86, 0.79, 0.87, 0.84, 0.85, 0.85, 0.85, 0.84, 0.88, 0.77, 0.78, 0.89, 0.83, 0.80, 0.85, 0.87, 0.81, 0.84, 0.84, 0.78, 0.81, 0.87, 0.84, 0.85, 0.86, 0.84, 0.83, 0.89, 0.86, 0.85, 0.85, 0.87, 0.85, 0.87, 0.87, 0.88, 0.81, 0.79, 0.83, 0.76, 0.77, 0.86, 0.84, 0.84, 0.90

0.8479194630872482
0.79, 0.83, 0.83, 0.86, 0.83, 0.88, 0.79, 0.86, 0.84, 0.87, 0.85, 0.86, 0.84, 0.87, 0.80, 0.79, 0.90, 0.84, 0.80, 0.85, 0.86, 0.81, 0.84, 0.83, 0.79, 0.81, 0.87, 0.85, 0.86, 0.87, 0.84, 0.83, 0.89, 0.88, 0.86, 0.86, 0.87, 0.85, 0.88, 0.87, 0.90, 0.82, 0.79, 0.83, 0.76, 0.79, 0.87, 0.86, 0.83, 0.89

0.9152253116011505
0.94, 0.93, 0.91, 0.91, 0.92, 0.92, 0.90, 0.92, 0.90, 0.90, 0.95, 0.93, 0.89, 0.90, 0.88, 0.83, 0.87, 0.88, 0.89, 0.92, 0.92, 0.91, 0.85, 0.91, 0.90, 0.94, 0.95, 0.92, 0.95, 0.91, 0.94, 0.89, 0.91, 0.93, 0.90, 0.90, 0.92, 0.89, 0.93, 0.93, 0.95, 0.91, 0.94, 0.96, 0.90, 0.84, 0.90, 0.91, 0.89, 0.92


Running iteration 10 of 10 fold...
[13, 0, 35, 28, 33, 39, 41, 10, 23, 36, 9]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.976467, 0.976701, 0.966739, 0.975999

    accuracy, precision, recall, f_score
max3: 0.975506, 0.975757, 0.966519, 0.976761

    accuracy, precision, recall, f_score
max1: 0.969319, 0.969449, 0.971064, 0.973759


min loss: 0.007, episode: 269000
max accu: 0.969, episode: 460000

44.34 classifiers used
    accuracy, precision, recall, f_score
mv: 0.990412, 0.990451, 0.990463, 0.988665
wv: 0.990412, 0.990451, 0.990463, 0.988665
fs: 0.977469, 0.977583, 0.972580, 0.976075
rl: 0.969319, 0.969449, 0.971064, 0.973759

0.8363646044084763
0.84, 0.84, 0.87, 0.84, 0.84, 0.81, 0.79, 0.84, 0.84, 0.86, 0.84, 0.75, 0.83, 0.90, 0.76, 0.78, 0.82, 0.82, 0.86, 0.88, 0.84, 0.77, 0.84, 0.86, 0.85, 0.82, 0.79, 0.75, 0.88, 0.86, 0.82, 0.86, 0.86, 0.89, 0.84, 0.87, 0.89, 0.81, 0.79, 0.87, 0.80, 0.86, 0.80, 0.83, 0.82, 0.82, 0.85, 0.84, 0.81, 0.81

0.8361576144834933
0.84, 0.84, 0.87, 0.84, 0.84, 0.82, 0.78, 0.85, 0.84, 0.87, 0.83, 0.75, 0.83, 0.90, 0.76, 0.77, 0.81, 0.82, 0.86, 0.88, 0.84, 0.77, 0.84, 0.86, 0.85, 0.83, 0.79, 0.75, 0.87, 0.86, 0.82, 0.86, 0.86, 0.89, 0.84, 0.87, 0.89, 0.80, 0.79, 0.87, 0.80, 0.86, 0.79, 0.83, 0.82, 0.82, 0.85, 0.84, 0.80, 0.81

0.8288494726749761
0.84, 0.82, 0.85, 0.83, 0.84, 0.81, 0.78, 0.83, 0.85, 0.85, 0.82, 0.75, 0.82, 0.90, 0.75, 0.77, 0.83, 0.81, 0.85, 0.87, 0.84, 0.77, 0.83, 0.85, 0.83, 0.82, 0.78, 0.74, 0.88, 0.86, 0.81, 0.84, 0.84, 0.88, 0.84, 0.85, 0.88, 0.81, 0.79, 0.88, 0.78, 0.85, 0.79, 0.81, 0.80, 0.82, 0.83, 0.82, 0.79, 0.80

0.9030105465004793
0.88, 0.89, 0.88, 0.90, 0.87, 0.91, 0.88, 0.89, 0.93, 0.89, 0.89, 0.91, 0.90, 0.88, 0.90, 0.90, 0.85, 0.93, 0.93, 0.88, 0.94, 0.93, 0.93, 0.92, 0.92, 0.92, 0.89, 0.91, 0.92, 0.90, 0.90, 0.92, 0.91, 0.86, 0.94, 0.88, 0.92, 0.90, 0.87, 0.88, 0.89, 0.89, 0.91, 0.92, 0.89, 0.84, 0.93, 0.87, 0.84, 0.89

    accuracy, precision, recall, f_score
mv: 0.994728, 0.994764, 0.991830, 0.993235
wv: 0.994585, 0.994619, 0.991609, 0.993132
fs: 0.984664, 0.984772, 0.979239, 0.982387
rl: 0.980591, 0.980771, 0.968599, 0.976849

fs avg size: 13.10000, rl avg size: 44.48858
full test avg accu: 0.90932, test avg accu: 0.84559

training takes 105829.299 sec
