{'dataset': 'avila', 'algorithm': 'ptdqn', 'num_clf': 50, 'num_training': 500000, 'learning_rate': 0.1, 'discount_factor': 1.0, 'epsilon': 0.1, 'random_state': 3884, 'portion': 0.5, 'sequential': False}
(20867, 11)
reading data takes 0.064 sec
number of labels: 12

Running iteration 1 of 10 fold...
[11, 0, 28, 4, 25, 24, 20, 22, 44, 3, 18]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.982215, 0.982293, 0.971378, 0.979153

    accuracy, precision, recall, f_score
max3: 0.981896, 0.982044, 0.975283, 0.981657

    accuracy, precision, recall, f_score
max1: 0.988979, 0.989003, 0.986947, 0.989591


min loss: 0.009, episode: 257000
max accu: 0.989, episode: 370000

44.42 classifiers used
    accuracy, precision, recall, f_score
mv: 0.994250, 0.994305, 0.994165, 0.994862
wv: 0.994250, 0.994305, 0.994165, 0.994862
fs: 0.984188, 0.984213, 0.986446, 0.987950
rl: 0.988979, 0.989003, 0.986947, 0.989591

0.8493993610223644
0.81, 0.81, 0.84, 0.87, 0.89, 0.87, 0.85, 0.84, 0.84, 0.87, 0.77, 0.90, 0.80, 0.85, 0.86, 0.81, 0.79, 0.80, 0.87, 0.82, 0.88, 0.86, 0.9, 0.84, 0.88, 0.87, 0.87, 0.85, 0.90, 0.84, 0.81, 0.87, 0.87, 0.88, 0.79, 0.86, 0.84, 0.85, 0.81, 0.81, 0.83, 0.82, 0.79, 0.85, 0.87, 0.85, 0.84, 0.85, 0.87, 0.83

0.8488860489882853
0.80, 0.81, 0.85, 0.87, 0.88, 0.86, 0.85, 0.84, 0.84, 0.88, 0.77, 0.90, 0.80, 0.86, 0.86, 0.80, 0.78, 0.80, 0.87, 0.83, 0.88, 0.86, 0.89, 0.84, 0.88, 0.87, 0.87, 0.85, 0.90, 0.84, 0.81, 0.86, 0.87, 0.88, 0.79, 0.86, 0.83, 0.85, 0.81, 0.81, 0.83, 0.81, 0.79, 0.85, 0.87, 0.85, 0.84, 0.85, 0.87, 0.83

0.85126018207954
0.81, 0.82, 0.84, 0.88, 0.89, 0.86, 0.84, 0.82, 0.84, 0.87, 0.77, 0.91, 0.82, 0.86, 0.84, 0.81, 0.79, 0.79, 0.86, 0.82, 0.88, 0.88, 0.89, 0.85, 0.89, 0.86, 0.87, 0.84, 0.90, 0.83, 0.83, 0.88, 0.86, 0.88, 0.80, 0.85, 0.85, 0.85, 0.81, 0.80, 0.84, 0.82, 0.79, 0.87, 0.89, 0.85, 0.84, 0.85, 0.87, 0.83

0.902759942501198
0.94, 0.92, 0.94, 0.86, 0.90, 0.93, 0.87, 0.92, 0.89, 0.88, 0.90, 0.89, 0.84, 0.90, 0.94, 0.90, 0.91, 0.90, 0.87, 0.91, 0.93, 0.90, 0.89, 0.87, 0.90, 0.87, 0.83, 0.88, 0.87, 0.90, 0.87, 0.92, 0.95, 0.89, 0.90, 0.89, 0.93, 0.89, 0.89, 0.90, 0.89, 0.89, 0.90, 0.91, 0.89, 0.90, 0.88, 0.92, 0.90, 0.88


Running iteration 2 of 10 fold...
[46, 0, 39, 2, 11, 25, 42, 48, 18, 45, 7, 3, 15, 10, 49, 36]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.980085, 0.980226, 0.965912, 0.976306

    accuracy, precision, recall, f_score
max3: 0.979766, 0.979882, 0.969009, 0.977506

    accuracy, precision, recall, f_score
max1: 0.977480, 0.977749, 0.960499, 0.973009


min loss: 0.006, episode: 270000
max accu: 0.977, episode: 400000

47.66 classifiers used
    accuracy, precision, recall, f_score
mv: 0.995688, 0.995697, 0.992916, 0.995091
wv: 0.995208, 0.995219, 0.991959, 0.994494
fs: 0.987063, 0.987124, 0.980911, 0.986597
rl: 0.977480, 0.977749, 0.960499, 0.973009

0.843891373801917
0.80, 0.86, 0.89, 0.85, 0.81, 0.78, 0.75, 0.88, 0.86, 0.85, 0.86, 0.88, 0.82, 0.80, 0.78, 0.86, 0.81, 0.85, 0.87, 0.86, 0.87, 0.81, 0.83, 0.82, 0.84, 0.88, 0.80, 0.80, 0.83, 0.87, 0.79, 0.80, 0.84, 0.83, 0.78, 0.80, 0.88, 0.81, 0.81, 0.89, 0.84, 0.82, 0.89, 0.81, 0.85, 0.89, 0.90, 0.86, 0.89, 0.87

0.8421767838125667
0.80, 0.85, 0.89, 0.85, 0.80, 0.77, 0.75, 0.89, 0.86, 0.85, 0.86, 0.88, 0.82, 0.80, 0.78, 0.86, 0.81, 0.85, 0.87, 0.86, 0.87, 0.82, 0.82, 0.82, 0.84, 0.88, 0.80, 0.80, 0.83, 0.87, 0.79, 0.80, 0.84, 0.83, 0.77, 0.80, 0.88, 0.80, 0.82, 0.89, 0.84, 0.82, 0.88, 0.80, 0.85, 0.89, 0.90, 0.86, 0.89, 0.87

0.8411212266411119
0.81, 0.86, 0.90, 0.84, 0.80, 0.77, 0.76, 0.88, 0.85, 0.85, 0.85, 0.88, 0.82, 0.79, 0.75, 0.87, 0.81, 0.85, 0.86, 0.86, 0.88, 0.81, 0.83, 0.82, 0.84, 0.88, 0.80, 0.81, 0.83, 0.87, 0.79, 0.79, 0.84, 0.83, 0.77, 0.79, 0.88, 0.82, 0.81, 0.88, 0.84, 0.81, 0.88, 0.82, 0.84, 0.89, 0.89, 0.86, 0.89, 0.88

0.8997220891231433
0.95, 0.90, 0.89, 0.90, 0.91, 0.88, 0.90, 0.88, 0.91, 0.91, 0.91, 0.91, 0.92, 0.90, 0.91, 0.84, 0.89, 0.90, 0.90, 0.85, 0.85, 0.95, 0.89, 0.90, 0.87, 0.90, 0.89, 0.89, 0.92, 0.82, 0.86, 0.91, 0.88, 0.89, 0.95, 0.87, 0.87, 0.93, 0.88, 0.89, 0.91, 0.84, 0.92, 0.84, 0.91, 0.87, 0.89, 0.94, 0.91, 0.90


Running iteration 3 of 10 fold...
[20, 0, 16, 32, 45, 37, 38, 22, 39, 33, 35]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.982854, 0.982999, 0.975380, 0.981759

    accuracy, precision, recall, f_score
max3: 0.981896, 0.982004, 0.978129, 0.982921

    accuracy, precision, recall, f_score
max1: 0.983709, 0.983814, 0.971791, 0.979583


min loss: 0.005, episode: 252000
max accu: 0.984, episode: 390000

47.92 classifiers used
    accuracy, precision, recall, f_score
mv: 0.994250, 0.994248, 0.988984, 0.990659
wv: 0.994250, 0.994248, 0.988984, 0.990659
fs: 0.985146, 0.985117, 0.983380, 0.983999
rl: 0.983709, 0.983814, 0.971791, 0.979583

0.8447050053248136
0.86, 0.78, 0.85, 0.84, 0.85, 0.80, 0.82, 0.84, 0.81, 0.87, 0.84, 0.83, 0.83, 0.79, 0.83, 0.85, 0.89, 0.83, 0.81, 0.87, 0.91, 0.82, 0.84, 0.81, 0.85, 0.79, 0.81, 0.86, 0.87, 0.85, 0.79, 0.86, 0.89, 0.88, 0.83, 0.88, 0.85, 0.85, 0.88, 0.85, 0.86, 0.83, 0.79, 0.83, 0.86, 0.87, 0.82, 0.82, 0.81, 0.82

0.8431182108626197
0.85, 0.78, 0.84, 0.83, 0.85, 0.79, 0.82, 0.84, 0.81, 0.87, 0.84, 0.83, 0.83, 0.79, 0.83, 0.85, 0.89, 0.82, 0.81, 0.87, 0.91, 0.83, 0.84, 0.81, 0.85, 0.80, 0.80, 0.87, 0.87, 0.86, 0.78, 0.86, 0.89, 0.88, 0.82, 0.88, 0.84, 0.85, 0.88, 0.85, 0.86, 0.83, 0.78, 0.82, 0.86, 0.87, 0.82, 0.82, 0.80, 0.82

0.8451269765213226
0.85, 0.79, 0.85, 0.85, 0.85, 0.80, 0.81, 0.86, 0.82, 0.86, 0.84, 0.82, 0.84, 0.80, 0.84, 0.85, 0.89, 0.82, 0.81, 0.87, 0.91, 0.82, 0.86, 0.82, 0.86, 0.77, 0.82, 0.88, 0.87, 0.84, 0.79, 0.86, 0.89, 0.88, 0.83, 0.88, 0.83, 0.85, 0.87, 0.85, 0.88, 0.83, 0.77, 0.82, 0.86, 0.88, 0.82, 0.82, 0.82, 0.81

0.9135026353617632
0.90, 0.90, 0.93, 0.88, 0.92, 0.92, 0.92, 0.91, 0.91, 0.90, 0.93, 0.92, 0.92, 0.85, 0.92, 0.90, 0.93, 0.91, 0.90, 0.90, 0.90, 0.88, 0.93, 0.91, 0.91, 0.88, 0.89, 0.90, 0.90, 0.95, 0.93, 0.91, 0.90, 0.94, 0.91, 0.88, 0.92, 0.94, 0.91, 0.88, 0.92, 0.94, 0.93, 0.86, 0.96, 0.90, 0.91, 0.90, 0.84, 0.90


Running iteration 4 of 10 fold...
[37, 0, 8, 24, 3, 10, 28, 12, 46, 47, 21, 49, 45, 36, 6, 19]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.982748, 0.982918, 0.977335, 0.982848

    accuracy, precision, recall, f_score
max3: 0.980405, 0.980631, 0.979937, 0.983740

    accuracy, precision, recall, f_score
max1: 0.983230, 0.983221, 0.982788, 0.985645


min loss: 0.006, episode: 264000
max accu: 0.983, episode: 400000

26.11 classifiers used
    accuracy, precision, recall, f_score
mv: 0.995688, 0.995712, 0.994075, 0.995921
wv: 0.995688, 0.995712, 0.994075, 0.995921
fs: 0.986584, 0.986613, 0.987290, 0.988392
rl: 0.983230, 0.983221, 0.982788, 0.985645

0.8519339723109689
0.89, 0.85, 0.85, 0.87, 0.87, 0.84, 0.86, 0.84, 0.90, 0.80, 0.89, 0.84, 0.88, 0.81, 0.83, 0.87, 0.86, 0.77, 0.80, 0.86, 0.86, 0.82, 0.84, 0.86, 0.9, 0.87, 0.78, 0.80, 0.88, 0.82, 0.84, 0.82, 0.86, 0.86, 0.86, 0.83, 0.87, 0.91, 0.83, 0.82, 0.84, 0.81, 0.84, 0.77, 0.83, 0.89, 0.85, 0.87, 0.88, 0.85

0.8488604898828541
0.89, 0.85, 0.85, 0.86, 0.86, 0.83, 0.86, 0.84, 0.90, 0.79, 0.89, 0.84, 0.87, 0.80, 0.83, 0.87, 0.85, 0.76, 0.80, 0.86, 0.85, 0.82, 0.84, 0.85, 0.90, 0.87, 0.78, 0.80, 0.88, 0.82, 0.85, 0.81, 0.86, 0.85, 0.85, 0.82, 0.87, 0.90, 0.83, 0.82, 0.84, 0.81, 0.84, 0.77, 0.83, 0.89, 0.84, 0.86, 0.88, 0.84

0.8503114518447533
0.90, 0.86, 0.86, 0.87, 0.87, 0.84, 0.86, 0.83, 0.89, 0.80, 0.88, 0.83, 0.88, 0.80, 0.84, 0.87, 0.84, 0.76, 0.79, 0.86, 0.85, 0.82, 0.85, 0.85, 0.90, 0.86, 0.77, 0.80, 0.89, 0.81, 0.86, 0.83, 0.86, 0.85, 0.86, 0.83, 0.86, 0.90, 0.82, 0.83, 0.84, 0.81, 0.85, 0.75, 0.84, 0.89, 0.85, 0.85, 0.89, 0.85

0.9107714422616194
0.91, 0.89, 0.93, 0.94, 0.89, 0.89, 0.95, 0.93, 0.89, 0.90, 0.92, 0.85, 0.91, 0.89, 0.88, 0.89, 0.90, 0.93, 0.84, 0.95, 0.95, 0.92, 0.86, 0.91, 0.90, 0.92, 0.89, 0.89, 0.94, 0.90, 0.91, 0.93, 0.86, 0.93, 0.87, 0.90, 0.88, 0.92, 0.92, 0.89, 0.92, 0.92, 0.90, 0.92, 0.87, 0.90, 0.90, 0.92, 0.95, 0.89


Running iteration 5 of 10 fold...
[24, 0, 9, 31, 11, 23, 48, 30, 32, 4, 35, 38, 25, 46, 14, 2]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.975825, 0.976062, 0.972602, 0.979500

    accuracy, precision, recall, f_score
max3: 0.974228, 0.974552, 0.973766, 0.979453

    accuracy, precision, recall, f_score
max1: 0.975084, 0.975530, 0.954334, 0.966771


min loss: 0.004, episode: 500000
max accu: 0.975, episode: 450000

44.52 classifiers used
    accuracy, precision, recall, f_score
mv: 0.994729, 0.994785, 0.984353, 0.990136
wv: 0.994729, 0.994785, 0.984353, 0.990136
fs: 0.978438, 0.978697, 0.962602, 0.967859
rl: 0.975084, 0.975530, 0.954334, 0.966771

0.8363642172523962
0.83, 0.82, 0.86, 0.82, 0.85, 0.80, 0.82, 0.86, 0.83, 0.90, 0.73, 0.86, 0.83, 0.78, 0.83, 0.83, 0.82, 0.81, 0.83, 0.85, 0.84, 0.83, 0.84, 0.88, 0.90, 0.85, 0.83, 0.80, 0.83, 0.84, 0.87, 0.87, 0.83, 0.85, 0.82, 0.83, 0.83, 0.84, 0.87, 0.80, 0.76, 0.79, 0.84, 0.79, 0.86, 0.78, 0.82, 0.80, 0.83, 0.83

0.8329329073482428
0.83, 0.82, 0.86, 0.81, 0.85, 0.8, 0.82, 0.86, 0.83, 0.90, 0.74, 0.86, 0.83, 0.78, 0.83, 0.82, 0.82, 0.81, 0.82, 0.85, 0.84, 0.83, 0.84, 0.88, 0.90, 0.85, 0.82, 0.80, 0.83, 0.84, 0.87, 0.86, 0.83, 0.85, 0.82, 0.83, 0.83, 0.83, 0.87, 0.80, 0.75, 0.78, 0.84, 0.79, 0.85, 0.77, 0.82, 0.80, 0.83, 0.82

0.8328030666027791
0.82, 0.84, 0.86, 0.80, 0.85, 0.80, 0.80, 0.86, 0.83, 0.90, 0.74, 0.86, 0.83, 0.78, 0.82, 0.83, 0.81, 0.81, 0.82, 0.83, 0.85, 0.82, 0.83, 0.88, 0.90, 0.86, 0.83, 0.79, 0.83, 0.84, 0.86, 0.86, 0.83, 0.84, 0.83, 0.82, 0.82, 0.85, 0.87, 0.80, 0.76, 0.79, 0.85, 0.79, 0.86, 0.77, 0.82, 0.79, 0.82, 0.82

0.9137038811691423
0.91, 0.89, 0.91, 0.91, 0.96, 0.92, 0.88, 0.91, 0.93, 0.95, 0.92, 0.91, 0.90, 0.89, 0.91, 0.93, 0.92, 0.94, 0.87, 0.84, 0.90, 0.93, 0.86, 0.88, 0.93, 0.88, 0.90, 0.86, 0.88, 0.94, 0.89, 0.90, 0.91, 0.91, 0.89, 0.92, 0.92, 0.92, 0.89, 0.89, 0.92, 0.95, 0.92, 0.92, 0.93, 0.95, 0.92, 0.92, 0.90, 0.90


Running iteration 6 of 10 fold...
[49, 0, 30, 44, 20, 38, 48, 29, 13, 46, 24]
using cpu
using cpu
    accuracy, precision, recall, f_score
max0: 0.984771, 0.984840, 0.979950, 0.984591

    accuracy, precision, recall, f_score
max3: 0.981683, 0.981748, 0.977949, 0.981526

    accuracy, precision, recall, f_score
max1: 0.982750, 0.982887, 0.973974, 0.980420


min loss: 0.007, episode: 252000
max accu: 0.983, episode: 350000

50.00 classifiers used
    accuracy, precision, recall, f_score
mv: 0.994250, 0.994297, 0.991923, 0.992496
wv: 0.993771, 0.993820, 0.991017, 0.991982
fs: 0.991854, 0.991934, 0.989908, 0.986376
rl: 0.982750, 0.982887, 0.973974, 0.980420

0.8525197018104368
0.79, 0.86, 0.78, 0.88, 0.79, 0.83, 0.82, 0.87, 0.85, 0.84, 0.80, 0.81, 0.83, 0.89, 0.83, 0.84, 0.83, 0.87, 0.81, 0.86, 0.90, 0.83, 0.82, 0.80, 0.86, 0.83, 0.87, 0.83, 0.82, 0.87, 0.91, 0.85, 0.88, 0.87, 0.83, 0.84, 0.88, 0.81, 0.89, 0.84, 0.83, 0.82, 0.87, 0.86, 0.91, 0.83, 0.90, 0.82, 0.90, 0.93

0.8486474973375933
0.79, 0.85, 0.77, 0.88, 0.78, 0.82, 0.81, 0.87, 0.86, 0.84, 0.80, 0.80, 0.83, 0.89, 0.83, 0.84, 0.82, 0.87, 0.81, 0.85, 0.90, 0.84, 0.81, 0.80, 0.86, 0.82, 0.87, 0.82, 0.82, 0.86, 0.91, 0.84, 0.88, 0.86, 0.83, 0.83, 0.88, 0.81, 0.90, 0.83, 0.83, 0.82, 0.86, 0.86, 0.91, 0.83, 0.89, 0.81, 0.90, 0.92

0.8562146621945377
0.80, 0.86, 0.79, 0.89, 0.80, 0.85, 0.82, 0.88, 0.87, 0.84, 0.80, 0.81, 0.85, 0.88, 0.85, 0.84, 0.83, 0.87, 0.83, 0.85, 0.90, 0.84, 0.82, 0.81, 0.87, 0.83, 0.88, 0.84, 0.83, 0.86, 0.92, 0.85, 0.90, 0.86, 0.83, 0.84, 0.87, 0.82, 0.90, 0.84, 0.82, 0.82, 0.86, 0.87, 0.91, 0.84, 0.88, 0.82, 0.90, 0.93

0.9144801149976043
0.94, 0.92, 0.93, 0.94, 0.92, 0.91, 0.92, 0.89, 0.87, 0.88, 0.93, 0.90, 0.93, 0.91, 0.87, 0.94, 0.91, 0.84, 0.94, 0.92, 0.93, 0.92, 0.91, 0.95, 0.88, 0.89, 0.91, 0.89, 0.95, 0.95, 0.88, 0.92, 0.90, 0.90, 0.84, 0.91, 0.93, 0.92, 0.92, 0.91, 0.94, 0.87, 0.93, 0.91, 0.88, 0.87, 0.91, 0.91, 0.91, 0.94


Running iteration 7 of 10 fold...
